#####################################################
## OpsMx Enterprise for Spinnaker configuration
#####################################################
# Default values for OES chart.
## This is a YAML-formatted file.
## Declare variables to be passed into your templates.

## Name of the secret for pulling image from docker registry.
## Change it only if you want to create a secret with
## different name before installing oes chart and use it.
imagePullSecret: opsmxdev-secret

## Quay container image registry credentials to create imagePullSecret
##
imageCredentials:
  registry: https://quay.io/
  username: quayID  # Quay username
  password: quayPassword # Quay password
  email: info@opsmx.com   # email corresponding to quay registry ID

rbac:
  create: true

####################################################
## Option to skip installation of OpsMx Spinnaker
## Setting this to true, will ensure custom ubi8 images of Spinnaker
installSpinnaker: true

####################################################
## Redis configuration
####################################################
## Set it to false only if OES needs to be configured with external redis
installRedis: true

## Installation mode
## Available installation modes OES-AP, None
installationMode: OES-AP
oesAutoConfiguration: true # Attempt to configure OES with some basic integrations based on best guess
secretStore: db # Valid values: db, Vault: Used for storing account and integration secrets. Vault, if used, needs to be installed and configured separately
vault:
  address: https://server.vaultint.opsmx.net # Vault Address URL
  token: 123132 # Vault Root token

## OES UI, OES Gate, Spinnaker Deck and Spinnaker Gate service type
##
k8sServiceType: ClusterIP

## Declare all the global variables under this
## Global variables can be accessed across all the charts including sub-charts
global:
  ## Custom Images registry where all the OSS and customized images used in the helm chart are stored
  ## List of images: busybox:1.28, bitnami-kubectl:1.18, postgres:9.6.5, oes-pre-configure:v2, create-secret:v10
  ## awsgit:v2, k8s-decoder:hal, bitnami-kubectl:1.18.5
  customImages:
    registry: quay.io/opsmxpublic

  ## Set this to false if cert-manager is not installed
  ## If cert-manager is installed, an issuer will be created
  ## by OES helm chart which generates certs for tls automatically
  ## If cert-manager is not installed, specify secrets with
  ## certificates under oesUI.tls.secretName & oesGate.tls.secretName
  certManager:
    installed: true

  # common gate for both spin and oes
  commonGate:
    enabled: true
    spinnakerRBAC: false

  customCerts:
    enabled: false
    secretName: oes-cacerts #TODO: Document procedure for creating this one and enhance scripts to merge cacerts created by controller and this

  # Below flag is used to setup tls termination at ingress
  # when this flag is set to false; spinnaker and oes endpoints
  # will be accessible over http instead of https
  ssl:
    enabled: true

  ## Set to true to expose oes-ui, oes-gate services over ingress
  ##
  createIngress: true

  # Spinnaker Deck URL configuration; url overwhich spinnaker deck will be accessed
  spinDeck:
    protocol: https
    host: spin.example.ops.com
    #port: 9000

    serviceAnnotations: {}

    ingress:
      annotations:
        ingress.kubernetes.io/ssl-redirect: "true"
        kubernetes.io/ingress.class: nginx
      tls:
        secretName: deck-authtls

  # Spinnaker Gate URL configuration; url overwhich spinnaker gate will be accessed
  spinGate:
    protocol: https
    host: spin-gate.example.ops.com
    #port: 8084

    serviceAnnotations: {}

    ingress:
      annotations:
        ingress.kubernetes.io/ssl-redirect: "true"
        kubernetes.io/ingress.class: nginx

      tls:
        secretName: gate-authtls

  ## OES-UI url configuration
  oesUI:
    protocol: https
    host: oes.example.ops.com
    # Use below port when hostname above is an external IP instead of a hostname
    #port: 80

    ingress:
      annotations:
        kubernetes.io/ingress.class: nginx

      tls:
        secretName: oes-ui-authtls

  ## OES-Gate url configuration
  oesGate:
    protocol: https
    host: oes-gate.example.ops.com
    # Use below port when hostname above is an external IP instead of a hostname
    #port: 8084

    ingress:
      annotations:
        kubernetes.io/ingress.class: nginx

      tls:
        secretName: oes-gate-authtls

  ## Set it to false if own LDAP is to be configured
  ## ldap configuration used in oes-gate, oes-platform and spinnaker gate for authentication
  ## and authorization

  installOpenLdap: true
  ldap:
    enabled: true
    url: ldap://{{ .Release.Name }}-openldap:389
    managerDn: cn=admin,dc=example,dc=org
    managerPassword: opsmxadmin123
    groupSearchBase: ou=groups,dc=example,dc=org
    groupSearchFilter: member={0}
    groupRoleAttributes: cn
    userDnPattern: cn={0},dc=example,dc=org

  ## Use the below flag to exclude pre-delete helm hooks to the
  ## rendered manifests
  preDeleteHelmHooks: true

  ###############################################################################
  ## This option enables OES to be configured automatically
  ## Load Balancer IPs will be automatically replaced in the
  ## configuration files of oes-gate, oes-ui
  autoConfiguration:
    # Set it to false if OES is being installed on restricted evnironment;
    # Autoconfiguration assumes Load Balancer is available for oes-gate, oes-ui
    # and spind-deck and configures accordingly
    enabled: false

    initContainer:
      # Image for init container to automatically configure oes components
      # during startup
      image: quay.io/opsmxpublic/oes-init:v4
      pullPolicy: IfNotPresent

      # Max time(in secs) that an init container of oes-ui should wait
      # to fetch External Load Balancer IP of oes-gate and vice versa
      externalIpCheckDelay: 180

###############################################################################
## Details of redis-master image for OES
##
redis:
  ## Redis endpoint that is used by oes-gate and oes-platform for caching;
  ## Change this to custom URL if installRedis is set to false
  ## url: redis://{{ .Release.Name }}-redis-master:6379
  ##
  url: redis://:password@{{ .Release.Name }}-redis-master
  port: 6379
  image:
    registry: quay.io/opsmxpublic
    repository: bitnami-redis
  password: password
  cluster:
    enabled: false

  # External Redis option will be enabled if in-cluster redis is disabled
  external:
    host: "<EXTERNAL-REDIS-HOST-NAME>"
    port: 6379
    # password: ""
  nodeSelector: {}

  ## Redis config file
  ## ref: https://redis.io/topics/config
  ##
  configmap: |-
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 60 1000

  # Uncomment if you don't want to create a PVC for redis
  #  master:
  #    persistence:
  #      enabled: false

###############################################################################
##
## Values of OES Database
##
db:
  ## Set it to false if any external database is to be used
  ##
  enabled: true

  ## Change the default configuration when above option is set to false
  ## Below url and credentials are used by Autopilot & Sapor
  url: jdbc:postgresql://oes-db:5432
  username: postgres
  password: networks123

  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-oes-db
    tag: v2.0.0
    pullPolicy: IfNotPresent

  ## Strategy to rollout statefulset pods
  ##
  podManagementPolicy: OrderedReady

  ## Default group to which the default user of a pod belongs
  ##
  securityContext:
    fsGroup: 1000

  ## storageMountSize is the size with which a PVC is to be created
  ##
  storageMountSize: 8Gi

  ## storageClass for DB persistent volume claim (PVC)
  ##
  #storageClassName: default
###############################################################################
## Use this SAPOR GATE Configuration to Enable Basic Authentication for OES SAPOR to communitcate 
## with spinnaker instead of x509
## Values of SAPOR OES Gate
##
saporgate:
  ## Image specific details
  ##
  enabled: true
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-spin-gate
    tag: 1.20.0
    pullPolicy: IfNotPresent

  resources: {}
  #  requests:
  #    memory: 500Mi
  #    cpu: 500m
  #  limits:
  #    memory: 1500Mi
  #    cpu: 1500m

  config:
    username: admin      # User name with admin permissions and belonging to admin groups defined in platform service
    password: saporadmin # Any generic String, need not be the real password

###############################################################################
##
## Values of OES Autopilot
##
autopilot:
  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-oes-autopilot
    tag: v3.9.1.2
    pullPolicy: IfNotPresent

  annotations:
    prometheus_io_path: /mgmt/prometheus
    prometheus_io_port: "8090"
    prometheus.io/scrape: "true"
  resources: {}
  #  requests:
  #    memory: 2Gi
  #    cpu: 1
  #  limits:
  #    memory: 8Gi
  #    cpu: 2

  config:
    ## Build Analysis
    ##
    buildAnalysis:
      enabled: false

    ## DB configuration; change it any other external DB is to be used
    ## Refer it above, under DB configuration section
    ##

    ## SSL configuration
    ##
    ssl:
      enabled: false # Set it to true if SSL is to be enabled
      keyStore: keystore.p12
      keyStorePassword: dummypwd # Provide keystore password
      keyStoreType: PKCS12
      keyAlias: tomcat

    ## server.host.dns.name is fetched from oesUI.host
    ##
    ## gate.url is fetched from oesGate.host
    ##

###############################################################################
##
## Values of OES Dashboard
##
dashboard:
  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-oes-dashboard
    tag: v3.9.1.2
    pullPolicy: IfNotPresent

  annotations:
    prometheus_io_path: /mgmt/prometheus
    prometheus_io_port: "8094"
    prometheus.io/scrape: "true"
  resources: {}
  #  requests:
  #    memory: 500Mi
  #    cpu: 500m
  #  limits:
  #    memory: 1000Mi
  #    cpu: 1500m

  config:
    ## Installation mode
    ## OES supports three modes of installation,
    ## Uses the mode configured above, under Installation mode
    ##
    app:
      sync:
        enabled: true
    ## By default spinnakerLink is {{ .Values.global.spinDeck.protocol }}://{{ .Values.global.spinDeck.host }}
    ## If spinnaker is exposed on Load balancer instead of ingress, set this value to external IP of spinnaker UI
    #spinnakerLink: http://spinnaker.domain.com

#####################################################
##
## Values of Forwarder/Controller
##
forwarder:
  enabled: true
  agent:
    image: quay.io/opsmxpublic/forwarder-agent:v20210722T133815
    serviceType: LoadBalancer
    # Value is also used in sapor configuration for kubernetes.agent.serverHostName
    host: opsmx-controller-controller1
  externalName: controller.exampleopsmx.net
  image:
    repository: quay.io/opsmxpublic/forwarder-controller
    tag: v20210722T133815
    pullPolicy: IfNotPresent
  serviceAnnotations: {}
###############################################################################
##
## Values of OES Gate
##
gate:
  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-gate
    tag: v3.9.1.2
    pullPolicy: IfNotPresent

  serviceAnnotations: {}

  annotations:
    prometheus_io_path: /prometheus
    prometheus_io_port: "8084"
    prometheus.io/scrape: "true"
  resources: {}
  #  requests:
  #    memory: 500Mi
  #    cpu: 500m
  #  limits:
  #    memory: 1500Mi
  #    cpu: 1500m

  config:
    ## LDAP Configuration
    ## Refer above, under LDAP configuration section
    ##

    ## Redis Endpoint
    ## Uses the URL specified under redis.url above,
    ## under Redis Configuration section
    ##

    ## Regex of OES-UI URL to allow cross origin requests; this is framed using oesUI.host
     
    ## Set it to true to disable LDAP authentication and enable file based authentication
    ## Reach out over support@opsmx.com for pre-configured user credentials
    fileBasedAuthentication:
      enabled: false
    server:
      session:
        timeoutInSeconds: 7200

    #####################################################
    # SAML AUthentication
    #####################################################
    # keytool -genkey -v -keystore oessaml.jks -alias saml -keyalg RSA -keysize 2048 -validity 10000
    # oessaml.jks and oesmetadata.xml are mounted as secrets, create them as follows
    # kubectl create secret generic oesmetadataxml --from-file=oesmetadata.xml
    # kubectl create secret generic oessamljks --from-file=oessaml.jks
    # kubectl create secret generic samljks-password --from-literal password=changeit 
    saml:
      enabled: false
      userSource: gate  # Groups will be obtained from SAML
      keyStore: /opt/spinnaker/saml/oessaml.jks  # The key in this secret must be oessaml.jks
      keyStorePassword: changeit
      keyStoreAliasName: saml
      metadataUrl: /opt/spinnaker/saml/oesmetadata.xml # The key in this secret must be oesmetadata.xml
      redirectProtocol: https
      redirectHostname: oes-gate.ryzon7-gitops.opsmx.org  # OES gate host name
      redirectBasePath: /
      issuerId: ryzonoesgate
      jksSecretName: oessamljks
      metadataSecretName: oesmetadataxml

    #####################################################
    #OAUTH2 Authentication for GitHub
    #####################################################
    oauth2:
      enabled: false
      client:
        clientId: #CLIENT_ID
        clientSecret: #CLIENT_SECRET_ID
        accessTokenUri: https://github.com/login/oauth/access_token
        userAuthorizationUri: https://github.com/login/oauth/authorize
        scope: user-email
      resource:
        userInfoUri: https://api.github.com/user
      userInfoMapping:
        email: email
        firstName: firstname
        lastName: name
        username: login
      provider: GITHUB

###############################################################################
##
## Values of OES Platform
##
platform:
  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-oes-platform
    tag: v3.9.1.3
    pullPolicy: IfNotPresent

  annotations:
    prometheus_io_path: /mgmt/prometheus
    prometheus_io_port: "8095"
    prometheus.io/scrape: "true"
  resources: {}
  #  requests:
  #    memory: 500Mi
  #    cpu: 500m
  #  limits:
  #    memory: 1500Mi
  #    cpu: 1500m

  config:
    ## DB configuration; change it any other external DB is to be used
    ## Refer it above, under DB configuration section
    ##

    ## RBAC Configuration
    ## Refer the RBAC create option at the top
    ##

    ## Admin Groups available in ldap
    ##
    adminGroups: admin

    ## Source of Users for authorization
    ## Supported sources:- ldap, file, gate
    userSource: ldap

    ## LDAP Configuration will be used if above userSource is set to ldap
    ## Refer above, under LDAP configuration section
    ##

    ## Redis Endpoint
    ## Uses the URL specified under redis.url above,
    ## under Redis Configuration section
    ##

    ## List of features to be supported by OES
    ##
    supportedFeatures:
      - deployment_verification
      - sapor
      - visibility

###############################################################################
##
## Values of OES Sapor (Security Audit Policy Onboarding & Release)
##
sapor:
  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-oes-sapor
    tag: v3.9.1.2
    pullPolicy: IfNotPresent

  annotations:
    prometheus_io_path: /mgmt/prometheus
    prometheus_io_port: "8085"
    prometheus.io/scrape: "true"
  resources: {}
  #  requests:
  #    memory: 100Mi
  #    cpu: 500m
  #  limits:
  #    memory: 2000Mi
  #    cpu: 1500m

  config:
    ## RBAC Configuration
    ## Refer the RBAC create option at the top
    ##

    ## Spinnaker Configuration
    spinnaker:
      ## Spinnaker configuration
      ## Necessary details needed by Sapor to
      ## integrate with Spinnaker
      ##
      ## Set it to true if authentication is enabled in Spinnaker
      ##
      authnEnabled: true

      ## URL of Spinnaker Gate
      ## FQDN of spin-gate if Spinnaker is installed in same K8s cluster, else
      ## set the url with the external IP address of spin-gate
      ## Note: Don't put a trailing /
      ##
      spinGateURL: http://spin-gate:8084

      ## By default spinExternalGateURL is {{ .Values.global.spinGate.protocol }}://{{ .Values.global.spinGate.host }}
      ## If spinExternalGateURL is an external IP address instead of ingress, Set the external IP address of spin-gate, this is used to redirect to
      ## the spinnaker pipelines from OES-UI.
      ## Note: Trailing / is not required
      ##
      #spinExternalGateURL: http://spinnaker-api.domain.com

      ## Spinnaker admin credentials
      ## When provided, will override above credentials and operate spinnaker
      ## as an admin user
      ##

      ## LDAP
      ldap:
        ldapEnabled: true
        ldapUsername: admin
        ldapPassword: opsmxadmin123
        ldapAdminLoginEnabled: false
        ldapAdminUsername: admin
        ldapAdminPassword: admin

      ## X509
      x509:
        enabled: false
        client:
          password: changeit
          
    #encryption key needed for sapor to startup from 3.9
    encrypt:
      enabled: true
      # This key shall match the encryption key specified in the spinnakerConfig.yaml configuration
      # #encryption key needed for sapor to startup from 3.9
      key: Q7udUkHPuA3VnNlOtksSgQ
    ## Set the below field to true if datasource configurations from platform
    datasources:
      platform: true

###############################################################################
##
## Values of OES UI
##
ui:
  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-oes-ui
    tag: v3.9.1.2
    pullPolicy: IfNotPresent
  serviceAnnotations: {}

  config:
    ## Interval at which UI refreshes application dashboard
    setApplicationRefreshInterval: 300000

###################################################################################
##
#
## Values of OES Visibility
##
visibility:
  ## Image specific details
  ##
  image:
    registry: quay.io/opsmxpublic
    repository: ubi8-oes-visibility
    tag: v3.9.1.2
    pullPolicy: IfNotPresent

  annotations:
    prometheus_io_path: /mgmt/prometheus
    prometheus_io_port: "8096"
    prometheus.io/scrape: "true"
  resources: {}
  #  requests:
  #    memory: 500Mi
  #    cpu: 500m
  #  limits:
  #    memory: 1000Mi
  #    cpu: 1500m

  config:
    ## DB configuration; change it any other external DB is to be used
    ## Refer it above, under DB configuration section
    ##

    ## Autopilot integration options
    configuredConnectors: JIRA,GIT,AUTOPILOT,SONARQUBE,JENKINS,AQUAWAVE

    ## Logger level
    logLevel: ERROR

#####################################################
## OPA configuration
#####################################################
opa:
  enabled: true
  image:
    repository: openpolicyagent/opa
    tag: edge-rootless
    pullPolicy: IfNotPresent

####################################################
## OPENLDAP configuration
####################################################

## OpenLDAP custom configuration; will override default configuration of
## openldap helm chart
##
openldap:
  # Password for the admin user; by default it is set to admin
  adminPassword: opsmxadmin123
  configPassword: opsmxconfig123
  omitClusterIP: true
  persistence:
    enabled: false
  env:
    LDAP_REMOVE_CONFIG_AFTER_SETUP: "false"

  customLdifFiles:
    01-memberof.ldif: |-
      dn: cn=module,cn=config
      cn: module
      objectClass: olcModuleList
      olcModuleLoad: memberof.la
      olcModulePath: /usr/lib/ldap

      dn: olcOverlay={0}memberof,olcDatabase={1}hdb,cn=config
      objectClass: olcConfig
      objectClass: olcMemberOf
      objectClass: olcOverlayConfig
      objectClass: top
      olcOverlay: memberof
      olcMemberOfDangling: ignore
      olcMemberOfRefInt: TRUE
      olcMemberOfGroupOC: groupOfNames
      olcMemberOfMemberAD: member
      olcMemberOfMemberOfAD: memberOf
    02-refint1.ldif: |-
      dn: cn=module{1},cn=config
      changetype: modify
      add: olcmoduleload
      olcmoduleload: refint.la
    03-refint2.ldif: |-
      dn: olcOverlay={1}refint,olcDatabase={1}hdb,cn=config
      objectClass: olcConfig
      objectClass: olcOverlayConfig
      objectClass: olcRefintConfig
      objectClass: top
      olcOverlay: {1}refint
      olcRefintAttribute: memberof member manager owner
    04-add_ou.ldif: |-
      dn: ou=groups,dc=example,dc=org
      objectClass: organizationalUnit
      ou: Groups
    05-admin.ldif: |-
      dn: cn=admin,ou=groups,dc=example,dc=org
      objectClass: groupofnames
      cn: admin
      description: read write and execute group
      member: cn=admin,dc=example,dc=org
    06-developer.ldif: |-
      dn: cn=developers,ou=groups,dc=example,dc=org
      objectClass: groupofnames
      cn: developers
      description: read only users
      member: cn=admin,dc=example,dc=org
      member: cn=developer,dc=example,dc=org
    07-qa.ldif: |-
      dn: cn=QA,ou=groups,dc=example,dc=org
      objectClass: groupofnames
      cn: QA
      description: read only users
      member: cn=admin,dc=example,dc=org
      member: cn=qa,dc=example,dc=org
    08-manager.ldif: |-
      dn: cn=managers,ou=groups,dc=example,dc=org
      objectClass: groupofnames
      cn: managers
      description: read and execute group
      member: cn=admin,dc=example,dc=org
      member: cn=manager,dc=example,dc=org
    09-IT-manager.ldif: |-
      dn: cn=ITManagers,ou=groups,dc=example,dc=org
      objectClass: groupofnames
      cn: ITManagers
      description: read and execute group
      member: cn=admin,dc=example,dc=org
      member: cn=ITManager,dc=example,dc=org
    10-users.ldif: |-
      dn: cn=user1,dc=example,dc=org
      objectClass: simpleSecurityObject
      objectClass: organizationalRole
      cn: user1
      userpassword: {SSHA}Y9L4AsYL16WLK10qDZ62pTScFnaWb0nz

      dn: cn=user2,dc=example,dc=org
      objectClass: simpleSecurityObject
      objectClass: organizationalRole
      cn: user2
      userpassword: {SSHA}DasTBI0eut1F83Bh1F1HXmDT8juJj3pY

      dn: cn=user3,dc=example,dc=org
      objectClass: simpleSecurityObject
      objectClass: organizationalRole
      cn: user3
      userpassword: {SSHA}Qu1FW7BdLMndwM/Gf+zc3a8VIMAymbuv

      dn: cn=developers,ou=groups,dc=example,dc=org
      changetype: modify
      add: member
      member: cn=user1,dc=example,dc=org
      member: cn=user3,dc=example,dc=org

      dn: cn=QA,ou=groups,dc=example,dc=org
      changetype: modify
      add: member
      member: cn=user2,dc=example,dc=org
      member: cn=user3,dc=example,dc=org

## ldap configuration used in oes-gate, oes-platform and spinnaker gate for authentication
## and authorization

#####################################################
# Centralized Logging Configuration
#####################################################
enableCentralLogging: false
elasticsearch:
  replicas: 1
  minimumMasterNodes: 1
  resources:
    requests:
      cpu: "100m"
      memory: "1Gi"

kibana:
  service:
    type: LoadBalancer
  resources:
    requests:
      cpu: "100m"
      memory: "250Mi"
  lifecycle:
    postStart:
      exec:
        command:
          - bash
          - -c
          - >
            until curl localhost:5601; do echo "Waiting for Kibana to be available..."; sleep 5; done;
            until curl elasticsearch-master:9200; do echo "Waiting for Elasticsearch to be available..."; sleep 5; done;
            sleep 60;
            curl https://raw.githubusercontent.com/OpsMx/enterprise-spinnaker/master/scripts/kibana/kibana_objects.ndjson > /tmp/kibana_objects.ndjson;
            curl -X POST "localhost:5601/api/saved_objects/_import?overwrite=true" -H "kbn-xsrf: true" --form file=@/tmp/kibana_objects.ndjson 2>&1 1> /tmp/postStart.out;

#####################################################
# Spinnaker instance configuration
#####################################################
spinnaker:
  halyard:
    spinnakerVersion: 1.26.6
    image:
      repository: quay.io/opsmxpublic/ubi8-spin-halyard
      tag: opsmx-1.40.0
    # Set to false to disable persistence data volume for halyard
    persistence:
      enabled: true
    # Provide a config map with Hal commands that will be run the core config (storage)
    # The config map should contain a script in the config.sh key
    additionalScripts:
      enabled: false
      configMapName: my-halyard-config
      configMapKey: config.sh
      # If you'd rather do an inline script, set create to true and put the content in the data dict like you would a configmap
      # The content will be passed through `tpl`, so value interpolation is supported.
      create: false
      data: {}
    additionalSecrets:
      create: false
      data: {}
      ## Uncomment if you want to use a pre-created secret rather than feeding data in via helm.
      # name:
    additionalConfigMaps:
      create: false
      data: {}
      ## Uncomment if you want to use a pre-created ConfigMap rather than feeding data in via helm.
      # name:
    additionalProfileConfigMaps:
      data:
        ## if you're running spinnaker behind a reverse proxy such as a GCE ingress
        ## you may need the following profile settings for the gate profile.
        ## see https://github.com/spinnaker/spinnaker/issues/1630
        ## otherwise its harmless and will likely become default behavior in the future
        ## According to the linked github issue.
        gate-local.yml:
          server:
            tomcat:
              protocolHeader: X-Forwarded-Proto
              remoteIpHeader: X-Forwarded-For
              internalProxies: .*
              httpsServerPort: X-Forwarded-Port

        ##If opa is installed and enabled  and spinnaker is installed,
        ##Then you can enable policy in spinnaker through front50-local yaml.
        ##If you don't want to configure make it as false or
        ## If you have your different opa server you can mention that url here
        front50-local.yml:
          policy:
            opa:
              enabled: true
              url: http://oes-sapor.{{ .Release.Namespace }}:8085

    ## Define custom settings for Spinnaker services. Read more for details:
    ## https://www.spinnaker.io/reference/halyard/custom/#custom-service-settings
    ## You can use it to add annotations for pods, override the image, etc.
    additionalServiceSettings:
      ## artifactId to override Spinnaker components images with OpsMx custom images
      gate.yml:
        healthEndpoint: /health
        kubernetes:
          useExecHealthCheck: false
        artifactId: quay.io/opsmxpublic/ubi8-oes-spin-gate:1.22.1
      deck.yml:
        artifactId: quay.io/opsmxpublic/ubi8-oes-deck:3.5.1
      clouddriver.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4
      clouddriver-caching.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4
      clouddriver-rw.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4
      clouddriver-ro.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4
      clouddriver-ro-deck.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4
      echo.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1
      echo-scheduler.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1
      echo-worker.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1
      fiat.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-fiat:1.16.0
      front50.yml:
        artifactId: quay.io/opsmxpublic/ubi8-oes-front50:0.27.1
      igor.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-igor:1.16.0
      kayenta.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-kayenta:0.21.0
      orca.yml:
        artifactId: quay.io/opsmxpublic/ubi8-oes-orca:2.20.3
      rosco.yml:
        artifactId: quay.io/opsmxpublic/ubi8-spin-rosco:0.25.0
    ## Uncomment if you want to add extra commands to the init script
    ## run by the init container before halyard is started.
    ## The content will be passed through `tpl`, so value interpolation is supported.
    # additionalInitScript: |-

    ## Uncomment if you want to add annotations on halyard and install-using-hal pods
    # annotations:
    #   iam.amazonaws.com/role: <role_arn>

    ## Uncomment the following resources definitions to control the cpu and memory
    # resources allocated for the halyard pod
    resources:
      {}
      # requests:
      #   memory: "1Gi"
      #   cpu: "100m"
      # limits:
      #   memory: "2Gi"
      #   cpu: "200m"

    ## Uncomment if you want to set environment variables on the Halyard pod.
    # env:
    #   - name: JAVA_OPTS
    #     value: -Dhttp.proxyHost=proxy.example.com
    customCerts:
      ## Enable to override the default cacerts with your own one
      enabled: false
      secretName: custom-cacerts

  # Define which registries and repositories you want available in your
  # Spinnaker pipeline definitions
  # For more info visit:
  #   https://www.spinnaker.io/setup/providers/docker-registry/

  # Configure your Docker registries here
  dockerRegistries:
    - name: dockerhub
      address: index.docker.io
      repositories:
        - library/alpine
        - library/ubuntu
        - library/centos
        - library/nginx
  # - name: gcr
  #   address: https://gcr.io
  #   username: _json_key
  #   password: '<INSERT YOUR SERVICE ACCOUNT JSON HERE>'
  #   email: 1234@5678.com

  # If you don't want to put your passwords into a values file
  # you can use a pre-created secret instead of putting passwords
  # (specify secret name in below `dockerRegistryAccountSecret`)
  # per account above with data in the format:
  # <name>: <password>

  # dockerRegistryAccountSecret: myregistry-secrets

  kubeConfig:
    # Use this when you want to register arbitrary clusters with Spinnaker
    # Upload your ~/kube/.config to a secret
    enabled: false
    secretName: my-kubeconfig
    secretKey: config
    # List of contexts from the kubeconfig to make available to Spinnaker
    contexts:
      - default
    deploymentContext: default
    omittedNameSpaces:
      - kube-system
      - kube-public
    onlySpinnakerManaged:
      enabled: true

  # spinnakerFeatureFlags is a list of Spinnaker feature flags to enable
  # Ref: https://www.spinnaker.io/reference/halyard/commands/#hal-config-features-edit
  # spinnakerFeatureFlags:
  #   - artifacts
  #   - pipeline-templates
  spinnakerFeatureFlags: []

  # Node labels for pod assignment
  # Ref: https://kubernetes.io/docs/user-guide/node-selection/
  # nodeSelector to provide to each of the Spinnaker components
  nodeSelector: {}

  # Minio access/secret keys for the in-cluster S3 usage
  # Minio is not exposed publically
  minio:
    enabled: true
    image:
      repository: quay.io/opsmxpublic/minio
      tag: RELEASE.2020-01-03T19-12-21Z

    mcImage:
      repository: quay.io/opsmxpublic/minio-mc
      tag: RELEASE.2020-11-25T23-04-07Z
    serviceType: ClusterIP
    accessKey: spinnakeradmin
    secretKey: spinnakeradmin
    bucket: "spinnaker"
    nodeSelector: {}
    persistence:
      enabled: true
      size: 10Gi

  # Google Cloud Storage
  gcs:
    enabled: false
    project: my-project-name
    bucket: "<GCS-BUCKET-NAME>"
    ## if jsonKey is set, will create a secret containing it
    jsonKey: "<INSERT CLOUD STORAGE JSON HERE>"
    ## override the name of the secret to use for jsonKey, if `jsonKey`
    ## is empty, it will not create a secret assuming you are creating one
    ## external to the chart. the key for that secret should be `key.json`.
    secretName:

  # AWS Simple Storage Service
  s3:
    enabled: false
    bucket: "<S3-BUCKET-NAME>"
    # rootFolder: "front50"
    # region: "us-east-1"
    # endpoint: ""
    # accessKey: ""
    # secretKey: ""

  # Azure Storage Account
  azs:
    enabled: false
  #   storageAccountName: ""
  #   accessKey: ""
  #   containerName: "spinnaker"

  rbac:
    # Specifies whether RBAC resources should be created
    create: true

  serviceAccount:
    # Specifies whether a ServiceAccount should be created
    create: true
    # The name of the ServiceAccounts to use.
    # If left blank it is auto-generated from the fullname of the release
    halyardName:
    spinnakerName:
  securityContext:
    # Specifies permissions to write for user/group
    runAsUser: 1000
    fsGroup: 1000

  ## Option to enable HA in Spinnaker; Enabled by default
  enableHA: true

  ## Centralized Monitoring enable for Prometheus
  enableCentralMonitoring: false
  autoInstallSampleApps: true   # Set this to FALSE if upgrading

  # Initialize gitOps style Halyard
  gitopsHalyard:
    enabled: true
    repo:
      type: git # git, s3, stash(bitbucket server) use a different sample values file for s3/bitbuck-stash
      configArgs: "http.sslVerify=true"
      ## Configure below fields only if repo type is git/stash. Skip to s3 section if type is s3
      baseUrlHostName: github.com    # Specify the Base FQDN of your repository without the protocol, without any directories, and without any project name here (example: github.com)
      organization: OpsMx
      # Specify project name only if repo is under a project
      projectName: ""
      repository: standard-gitops-repo # repo name for GitOps Halyard (Sample Reference: https://github.com/OpsMx/sample-gitops-repo.git).
      dynamicAccRepository: standard-gitops-repo # Please provide the repo name of the GitOps Dynamic Accounts Directory. Can be same as Hal repo. 
      halConfigPath: / #relative path from repository root folder
      dynAccntConfigPath: dynaccount/ #relative path from repository root folder
      username: git/stash_username  # Username to authenticate with git/stash repo
      token: git/stash_token  # Token corresponding to above username
      ## Configure below fields only if repo type is s3
      s3accesskey: AWS_ACCESS_KEY_ID
      s3secretkey: AWS_SECRET_ACCESS_KEY
      s3bucket: bucket name.e.g-testbucket 
      s3region: regionofbucket
    secretName: opsmx-gitops-auth
    # Promote applications and pipelines from one environment to another or take backup
    pipelinePromotion:  # GitHub only,  Not supportd on S3 or Stash
      enabled: true
      type: git  # git, s3, stash
      gitConfig: "git config --global http.sslVerify false"
      organization: project_name  # Also called "project" in some repos
      repository: repo_name  # bucket name in case of S3
      rootFolder: pipeline/
      ##### ONLY In case of S3
      AWS_ACCESS_KEY_ID: access_key
      AWS_SECRET_ACCESS_KEY: secret_key
      ##### S3 config for pipelinePromotion is complete
      ##### For non-S3 repos
      baseUrl: example.repo.com  #  "git_url"
      username: username
      token: token
      branch: samplerepo
      usermail: krish@company.com
      #password="K438"   ### Token is preferred, Password also might work, try your luck
      # Instead of username, token/password, sshkey can be provided
      #API
      #api_url="https://api.bitbucket.org/2.0/repositories/"   # bitbucket
      apiUrl: "https://api.github.com/repos"                  # guthub
      #api_url="https://api.gitlab.com/repos"                  # gitLAB
      #api_url="https://bbq.opsmx.com/api"                      # bitbucket-server(stash)

      createPR: false
      autoApprovePR: false
      targetBranch: master # can be any branch to which PR to be raised
      approvingUser: approver_user  ### user who is going to auto-merge
      approverToken: token ## Token for the user to auto-merge

    ## x509 authentication for Spinnaker Gate
    gatex509:
      enabled: false
      host: spingate-x509.domain.com
    # Max time(in secs) that an init container of halyard should wait
    # to fetch External Load Balancer IP of spin-deck and spin-gate
    spinnakerLBCheckDelay: 1 # This is only used if not using ingress
    mTLS:
      enabled: false # Enable mTLS for Spinnaker Services and SSL for Deck and Gate

  ## Auth mechanism and credentials to be used by spin-cli for creating the sample pipelines
  ## Here basic ldap auth is used by default; everything under spinCli will be pasted in ~/.spin/config
  spinCli:
    gate:
      endpoint: http://sapor-gate:8084 # URL that needs to be used to talk to spinnaker gate and create sample pipelines
    auth:
      enabled: true
      basic:
        username: admin          # Use credentials corresponding to spinCli.gate.endpoint
        password: saporadmin  # Use credentials corresponding to spinCli.gate.endpoint
