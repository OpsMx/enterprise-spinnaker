---
# Source: oes/charts/spinnaker/templates/rbac/halyard-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-spinnaker-halyard
  namespace: default
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
---
# Source: oes/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-redis
  labels:
    app: redis
    chart: redis-10.5.3
    release: "release-name"
    heritage: "Helm"
type: Opaque
data:
  redis-password: "ZW5jcnlwdGVkOnJlZGlzcGFzc3dvcmQ6cmVkaXNwYXNzd29yZA=="
---
# Source: oes/charts/spinnaker/templates/secrets/registry.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-spinnaker-registry
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
    component: clouddriver
type: Opaque
data:
  dockerhub: ""
---
# Source: oes/charts/spinnaker/templates/secrets/spin-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-spinnaker-spin-config
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
stringData:
  config: |
    auth:
      basic:
        password: encrypted:saporpassword:saporpassword
        username: hanumesh.kumar@zendesk.com
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
---
# Source: oes/templates/customstages/ansible-secrets.yaml
apiVersion: v1
stringData:
  gitpassword: 4fmschdd3455
  gitusername: opsmxuser2
  nodeuser: ubuntu
  userpassword: ubuntupassword
kind: Secret
metadata:
  name: ansible-secrets
type: Opaque
---
# Source: oes/templates/customstages/customnotification-ssmtp-secrets.yaml
apiVersion: v1
stringData:
  emailpassword: passowrdmail
  ssmtpemail: opsmxuser@opsmx.io
kind: Secret
metadata:
  name: ssmtp-secrets
type: Opaque
---
# Source: oes/templates/customstages/terraspinbackendconfig.yaml
apiVersion: v1
stringData:
  artifactaccounts.json: |
         {
            "artifactaccounts": [
               {
                 "accountname": "OpsMx-artifact-Github-account",
                 "artifacttype": "Github",
                 "host": "https://github.com",
                 "username": "opsmx",
                 "password": "wtwetr4543534"
                }
               ]
         }
kind: Secret
metadata:
  name: terraspinbackendconfig
---
# Source: oes/templates/customstages/updatepr-secrets.yaml
apiVersion: v1
stringData:
  accesstoken: dfvjkbv346jsd93os0skw0
kind: Secret
metadata:
  name: updatepr-secrets
type: Opaque
---
# Source: oes/templates/pipeline-promotion/git-token-secret.yaml
apiVersion: v1
stringData:
  # Git token to access repo where pipeline stuff is stored
  git_secret_token: encrypted:gittoken:gittoken
  git_secret_sshkey: ""
  git_pr_token: encrypted:gittoken:gittoken
kind: Secret
metadata:
  name: git-token
type: Opaque
---
# Source: oes/templates/pipeline-promotion/local-spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToSpinnaker stage
  # It is placed under ~/.spin/config
  # endpoint should be the spinnaker gate where pipelines are created/updated
  config: |-
    auth:
      basic:
        password: encrypted:saporpassword:saporpassword
        username: hanumesh.kumar@zendesk.com
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: local-spin-cli-config
---
# Source: oes/templates/pipeline-promotion/spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToGit stage
  # It is placed under ~/.spin/config
  # custom job stage runs a spin cli and fetches the application/pipeline data
  # gate endpoint should point to the spinnaker from where application/pipeline data is fetched
  config: |-
    auth:
      basic:
        password: encrypted:saporpassword:saporpassword
        username: hanumesh.kumar@zendesk.com
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: spin-cli-config
---
# Source: oes/templates/sapor-gate/sapor-gate-secret.yaml
apiVersion: v1
data:
  gate-local.yml: |
    c2VydmVyOgogIHRvbWNhdDoKICAgIGh0dHBzU2VydmVyUG9ydDogWC1Gb3J3YXJkZWQtUG9ydAogICAgaW50ZXJuYWxQcm94aWVzOiAuKgogICAgcHJvdG9jb2xIZWFkZXI6IFgtRm9yd2FyZGVkLVByb3RvCiAgICByZW1vdGVJcEhlYWRlcjogWC1Gb3J3YXJkZWQtRm9yCnNlY3VyaXR5OgogIGJhc2ljZm9ybToKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOgogICAgbmFtZTogaGFudW1lc2gua3VtYXJAemVuZGVzay5jb20KICAgIHBhc3N3b3JkOiBlbmNyeXB0ZWQ6c2Fwb3JwYXNzd29yZDpzYXBvcnBhc3N3b3JkCiAgICByb2xlczogb2t0YTpyb2xlOnNwaW5uYWtlci1zdXBlcmFkbWluCg==
  gate-overrides.yml: |
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzZXJ2aWNlczoKICBjbG91ZGRyaXZlcjoKICAgIGJhc2VVcmw6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvOjcwMDIKICAgIGVuYWJsZWQ6IHRydWUKICBlY2hvOgogICAgYmFzZVVybDogaHR0cDovL3NwaW4tZWNoby13b3JrZXI6ODA4OQogICAgZW5hYmxlZDogdHJ1ZQoKZ2xvYmFsLnNwaW5uYWtlci50aW1lem9uZTogQW1lcmljYS9Mb3NfQW5nZWxlcw==
  gate.yml: |
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzcGVjdGF0b3I6CiAgYXBwbGljYXRpb25OYW1lOiAke3NwcmluZy5hcHBsaWNhdGlvbi5uYW1lfQogIHdlYkVuZHBvaW50OgogICAgZW5hYmxlZDogZmFsc2UKCnNwaW5uYWtlcjoKICBleHRlbnNpYmlsaXR5OgogICAgcGx1Z2luczoge30KICAgIHJlcG9zaXRvcmllczoge30KICAgIHBsdWdpbnMtcm9vdC1wYXRoOiAvb3B0L2dhdGUvcGx1Z2lucwogICAgc3RyaWN0LXBsdWdpbi1sb2FkaW5nOiBmYWxzZQoKc2VydmVyOgogIHNzbDoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgcG9ydDogJzgwODQnCiAgYWRkcmVzczogMC4wLjAuMApzZWN1cml0eToKICBiYXNpYzoKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOiB7fQpjb3JzOiB7fQpnb29nbGU6IHt9CgppbnRlZ3JhdGlvbnM6CiAgZ3JlbWxpbjoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgICBiYXNlVXJsOiBodHRwczovL2FwaS5ncmVtbGluLmNvbS92MQoKIyBoYWxjb25maWcKCnNlcnZpY2VzOgogIGNsb3VkZHJpdmVyOgogICAgY29uZmlnOgogICAgICBkeW5hbWljRW5kcG9pbnRzOgogICAgICAgIGRlY2s6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvLWRlY2s6NzAwMgogIHBsYXRmb3JtOgogICAgYmFzZVVybDogaHR0cDovL29lcy1wbGF0Zm9ybTo4MDk1CiAgICB1c2VyR3JvdXBBcGlQYXRoOiAvcGxhdGZvcm1zZXJ2aWNlL3YxL3VzZXJzL3t1c2VybmFtZX0vdXNlcmdyb3Vwcy9pbXBvcnRBbmRDYWNoZQogICAgZW5hYmxlZDogdHJ1ZQo=
  spinnaker.yml: |
    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
  spinnakerconfig.yml: |
    I0VtcHR5IGZpbGUK
kind: Secret
metadata:
  labels:
    app: oes
    component: sapor-gate
  name: sapor-gate-files
type: Opaque
---
# Source: oes/templates/secrets/bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
    datasource:
      secretManagement:
        source: db
kind: Secret
metadata:
  name: bootstrap
  labels:
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/secrets/oes-audit-client-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com:5432/auditdb
        username: 'spinnaker'
        password: 'encrypted:postgresql-admin-password:postgresql-admin-password'
    logging:
      level:
        com.opsmx.auditclientservice: INFO
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    oes:
      admin:
        user: admin
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        visibilityservice:
          name: visibilityservice
          url: http://oes-visibility:8096
    
    active:
      session: 30  # Session timeout in minutes
      noDays: 30  # Users not logged in for this duration (in days) are shown with status INACTIVE
    
    fixedDelay:
      in:
        milliseconds: 120000
    initialDelay:
      in:
        milliseconds: 300000
    scheduler:
      threads: 16
kind: Secret
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-audit-client-config
---
# Source: oes/templates/secrets/oes-audit-service-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com:5432/auditdb
        username: 'spinnaker'
        password: 'encrypted:postgresql-admin-password:postgresql-admin-password'
    logging:
        level:
          com.opsmx.auditservice: INFO
    message-broker:
      enabled: true
      username: 'rabbitmq'
      password: 'encrypted:rabbitmqpassword:rabbitmqpassword'
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        auditclientservice:
          name: auditclientservice
          url: http://oes-audit-client:8098
        oes:
          url: http://oes-sapor:8085
        autopilot:
          url: http://oes-autopilot:8090
        visibilityservice:
          url: http://oes-visibility:8096
        dashboard:
          url: http://oes-dashboard:8094
    open-telemetry:
      enabled: false
      baseUrl: https://isd-staging.zende.sk
      saporUrl: http://sapor-gate:8084
    db:
      migration:
        enabled: false
        version:
          from: 4.0.4
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-audit-service-config
---
# Source: oes/templates/secrets/oes-autopilot-secret.yaml
apiVersion: v1
stringData:
  autopilot.properties: |
    # Enable Build Analysis
    build.analysis=false
    # DB configuration
    secret.datasource.username=spinnaker
    secret.datasource.password=encrypted:postgresql-admin-password:postgresql-admin-password
    secret.datasource.url=jdbc:postgresql://opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com:5432/opsmx
    secret.platform.url=http://oes-platform:8095
    secret.ds.protocol=http://
    secret.ds.url=localhost:5005
    
    server.host.dns.name=/ui
    
    gate.url=http://oes-gate:8084
    #gate.url=https://isd-staging.zende.sk/gate
    
    #datascience configuration
    oes.datascience.baseUrl=http://oes-datascience:5005
    #build.analysis=false
    ds.async.flow=true
    
    #audit services
    auditservice.enabled=true
    auditservice.name=auditservice
    auditservice.url=http://oes-audit-service:8097
    auditclientservice.name=auditclientservice
    auditclientservice.url=http://oes-audit-client:8098
    
    # Standard-error-path
    standardErrorCodes.filePath=/opsmx/conf/standard-error-code.csv
    
    #storage configuration
    storage.type =db_storage
    #storage.type =object_storage
    #storage.endpoint=http://release-name-minio:9000
    #storage.accesskey = encrypted:minio-access-key:minio-access-key
    #storage.secretkey = encrypted:minio-secret-key:minio-secret-key
    #storage.region= us-east-1
    ds.seperate.service=true
    
    
    # Logging Level
    logging.level.com.opsmx.analytics=ERROR
    datasource.secretManagement.source = db
    
kind: Secret
metadata:
  name: oes-autopilot-config
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/secrets/oes-datascience-secret.yaml
apiVersion: v1
stringData:
  app-config.yml: |
    # Enable Build Analysis
    APP:
       ENVIRONMENT: dev
       DEBUG: True
       # Only accept True or False
       BIND: 0.0.0.0:5005
       WORKERS: 1
       PROTOCOL: http://
       TIMEOUT: 3600
       CELERY_ENABLED: True
       # Only accept True or False
    
    OBJECT_STORAGE:
          ENDPOINT: http://release-name-minio:9000
          BUCKET_NAME: autopilot
    POSTGRES:
          USERNAME: 'spinnaker'
          PASSWORD: 'encrypted:postgresql-admin-password:postgresql-admin-password'
          HOST: opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com
          PORT: 5432
          DB: autopilotqueue
    
    RABBITMQ:
          USERNAME: 'rabbitmq'
          PASSWORD: 'encrypted:rabbitmqpassword:rabbitmqpassword'
          HOST: rabbitmq-service
          PORT: 5672
    
  minio-credentials: |
    [default]
        aws_access_key_id = encrypted:minio-access-key:minio-access-key
        aws_secret_access_key = encrypted:minio-secret-key:minio-secret-key
    
    
kind: Secret
metadata:
  labels:
    app: oes
    component: datascience
  name: oes-datascience-config
---
# Source: oes/templates/secrets/oes-gate-configmap.yaml
apiVersion: v1
stringData:
  gate.yml: |
    ok-http-client:
      interceptor:
        skipHeaderCheck: true
    retrofit:
      connectTimeout: 60000
      readTimeout: 60000
      callTimeout: 60000
      writeTimeout: 60000
      retryOnConnectionFailure: true
    services:
      opsmx:
        baseUrl: http://oes-sapor:8085
        enabled: true
      autopilot:
        baseUrl: http://oes-autopilot:8090
        enabled: true
      platform:
        baseUrl: http://oes-platform:8095
        userGroupApiPath: /platformservice/v1/users/{username}/usergroups/importAndCache
        enabled: true
      dashboard:
        baseUrl: http://oes-dashboard:8094
        enabled: true
      visibility:
        baseUrl: http://oes-visibility:8096
        enabled: true
      auditservice:
         baseUrl: "http://oes-audit-service:8097"
         enabled: true
      auditclient:
         baseUrl: "http://oes-audit-client:8098"
         enabled: true
      oesui:
        externalUrl: /ui/
      keel:
        enabled: false
      clouddriver:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverCaching:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-caching:7002
        enabled: true
      clouddriverRo:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverRoDeck:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro-deck:7002
        enabled: true
      clouddriverRw:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-rw:7002
        enabled: true
      deck:
        enabled: true
        host: 0.0.0.0
        port: 9000
        redirect-host-pattern: '(?:deploy-companion|spinnaker)-staging(-api)?.zende.sk'
      echo:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      echoScheduler:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-scheduler:8089
        enabled: true
      echoWorker:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      fiat:
        host: 0.0.0.0
        port: 7003
        baseUrl: http://spin-fiat:7003
        enabled: true
      front50:
        host: 0.0.0.0
        port: 8080
        baseUrl: http://spin-front50:8080
        enabled: true
      gate:
        host: 0.0.0.0
        port: 8084
        baseUrl: http://oes-gate.example.ops.com
        enabled: true
      igor:
        host: 0.0.0.0
        port: 8088
        baseUrl: http://spin-igor:8088
        enabled: true
      kayenta:
        host: 0.0.0.0
        port: 8090
        baseUrl: http://spin-kayenta:8090
        enabled: false
      orca:
        host: 0.0.0.0
        port: 8083
        baseUrl: http://spin-orca:8083
        enabled: true
      redis:
        host: 0.0.0.0
        port: 6379
        baseUrl: redis://:encrypted:redispassword:redispassword@release-name-redis-master:6379
        enabled: true
      rosco:
        host: 0.0.0.0
        port: 8087
        baseUrl: http://spin-rosco:8087
        enabled: true
    user: {}
    cors:
      allowed-origins-pattern: '^https?://(?:localhost|isd-staging.zende.sk|spinnaker-staging.zende.sk|spinnaker-staging-api.zende.sk|deploy-companion-staging.zende.sk)?/?'
    ldap:
      enabled: false
    pipeline:
      rbac: false
    security:
      contentSecurityPolicy: "object-src 'none'; script-src 'unsafe-eval' 'unsafe-inline' https: http:;"
      basic:
        enabled: true
    
    saml:
      enabled: true
      issuerId: io.zendesk.isd.staging
      jksSecretName: oessamljks
      keyStore: encryptedFile:oessamljks:oessaml.jks
      keyStoreAliasName: saml
      keyStorePassword: encrypted:keystorepassword:keystorepassword
      metadataSecretName: oesmetadataxml
      metadataUrl: encryptedFile:oesmetadataxml:oesmetadata.xml
      redirectBasePath: /
      redirectHostname: isd-staging.zende.sk
      redirectProtocol: https
      userSource: gate
    file:
      enabled: false
      url: /platformservice/v1/users/authenticate
    authn:
      mode: session
    google: {}
    redis:
      connection: redis://:encrypted:redispassword:redispassword@release-name-redis-master:6379
    server:
      session:
        timeoutInSeconds: 7200
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    gate:
      installation:
        mode: common    #Allowed values are --> oes,common
    rbac:
      feature:
        application:
          enabled: true
    spinnaker:
      extensibility:
        deck-proxy:
          enabled: true
          plugins:
            Armory.ObservabilityPlugin:
              config.metrics:
                additionalTags:
                  envName: <ENV_NAME>
                  spinnakerInstance: <INSTANCE_NAME>
                  svcName: <SVC_NAME>
                  vendorName: <VENDOR_NAME>
                datadog:
                  apiKey: encrypted:datadog-api-key:datadog-api-key
                  applicationKey: encrypted:datadog-app-key:datadog-app-key
                  enabled: true
                  meterRegistryConfig.armoryRecommendedFiltersEnabled: true
              enabled: true
            Opsmx.CustomStagePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
            Zendesk.BuddyPlugin:
              enabled: true
              version: 8.16.0
            Zendesk.CustomBannerPlugin:
              enabled: true
              version: 8.16.0
            Zendesk.OnDemandJenkinsPlugin:
              enabled: true
              version: 8.16.0
            Zendesk.SmokeTestPlugin:
              enabled: true
              version: 8.16.0
            Zendesk.WebhooksPlugin:
              enabled: true
              version: 8.16.0
        plugins:
          Armory.ObservabilityPlugin:
            config.metrics:
              additionalTags:
                customerEnvName: staging
                envName: staging
                svcName: gate
                vendorName: opsmx
              datadog:
                apiKey: encrypted:datadog-api-key:datadog-api-key
                applicationKey: encrypted:datadog-app-key:datadog-app-key
                enabled: true
                meterRegistryConfig.armoryRecommendedFiltersEnabled: true
                meterRegistryConfig.defaultTagsDisabled: false
            enabled: true
        plugins-root-path: /opt/gate/plugins
        repositories:
          armory-observability-plugin-releases:
            url: https://raw.githubusercontent.com/opsmx-public/newspinplugin/oes-gate-datadog/oes-gate/plugins.json
          buddy:
            url: https://zendesk-spinnaker-plugins-production.s3.amazonaws.com/monorepo-plugins/buddy/plugins.json
          custom-banner:
            url: https://zendesk-spinnaker-plugins-production.s3.amazonaws.com/monorepo-plugins/custom-banner/plugins.json
          jenkins:
            url: https://zendesk-spinnaker-plugins-production.s3.amazonaws.com/monorepo-plugins/on-demand-jenkins/plugins.json
          opsmx-repo:
            url: file:///opt/spinnaker/plugins/plugins.json
          spinnaker-smoke-test:
            url: https://zendesk-spinnaker-plugins-production.s3.amazonaws.com/monorepo-plugins/smoke-test/plugins.json
          webhooks:
            url: https://zendesk-spinnaker-plugins-production.s3.amazonaws.com/monorepo-plugins/webhooks/plugins.json
    spring.cloud.vault.enabled: false
    allowUnauthenticatedAccess:
      agentAPI: false
      webhooks: true
    
    message-broker:
      enabled: true
      username: rabbitmq
      password: encrypted:rabbitmqpassword:rabbitmqpassword
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    
    logging:
      level:
        com.netflix.spinnaker.gate.security: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
        #com.netflix.spinnaker.gate.security: DEBUG
        #org.springframework.security: DEBUG
        #org.springframework.web: DEBUG
kind: Secret
metadata:
  name: oes-gate-config
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/secrets/oes-gate-secret.yaml
apiVersion: v1
stringData:
  GATEURL: http://sapor-gate:8084
  GATEUSER: hanumesh.kumar@zendesk.com
  GATEPASS: encrypted:saporpassword:saporpassword
kind: Secret
metadata:
  name: oes-gate-secret
  labels:
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/secrets/oes-platform-configmap.yaml
apiVersion: v1
stringData:
  platform-local.yml: |
    
    spring:
      datasource:
        url: jdbc:postgresql://opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com:5432/platformdb
        username: 'spinnaker'
        password: 'encrypted:postgresql-admin-password:postgresql-admin-password'
    ldap.managerPassword: 'encrypted:ldappassword:ldappassword'
    redis:
        connection: redis://:encrypted:redispassword:redispassword@release-name-redis-master:6379
    #datasource.url: jdbc:postgresql://opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com:5432/visibilitydb
    #postgres.password: 'encrypted:postgresql-admin-password:postgresql-admin-password'
    #postgres.username: 'spinnaker'
    
    datasource:
      secretManagement:
        source: db
      httpClient:
        connectTimeout: 10000
        connectionRequestTimeout: 10000
        socketTimeout: 10000
    rbacEnabled: true
    supportedFeatures:
      - deployment_verification
      - sapor
      - visibility
    userGroup:
      superAdminGroups: okta:role:spinnaker-superadmin
    user:
      source: gate
    ldap:
      enabled: false
      url: ldap://release-name-openldap:389
      managerDn: cn=admin,dc=example,dc=org
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      groupRoleAttributes: cn
      userDnPattern: cn={0},dc=example,dc=org
    dashboard:
      scheduler:
        enable: false
        fixedDelay:
          in:
            milliseconds: 120000
        initialDelay:
          in:
            milliseconds: 300000
        workerThreads: 50
    database:
      cleanup:
        scheduler:
          enabled: true
          daysInterval: 275
          cron: 0 0 0 * * *
    oes:
      sapor:
        url: http://oes-sapor:8085
      autopilot:
        url: http://oes-autopilot:8090
      dashboard:
        url: http://oes-dashboard:8094
      visibility:
        url: http://oes-visibility:8096
      auditclient:
        url: http://oes-audit-client:8098
      policyGate:
        url: http://oes-gate:8084
        path: /v1/data/
      auditservice:
        url: "http://oes-audit-service:8097"
      ui:
      # Ex: "https://oes-poc.dev.opsmx.org/"
        url: "https://isd-staging.zende.sk/ui"
      gate:
        url: http://oes-gate:8084
      approvalGate:
        apiUrl: http://oes-gate:8084/visibilityservice/v5/approvalGates/{id}/trigger
    
      verificationGate:
        apiUrl: http://oes-gate:8084/autopilot/api/v3/registerCanary
    
    logging:
      level:
        com.opsmx.platformservice: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
kind: Secret
metadata:
  name: oes-platform-config
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/secrets/oes-sapor-configmap.yaml
apiVersion: v1
stringData:
  application.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com:5432/oesdb
        username: 'spinnaker'
        password: 'encrypted:postgresql-admin-password:postgresql-admin-password'
    
    message-broker:
      enabled: true
      username: rabbitmq
      password: encrypted:rabbitmqpassword:rabbitmqpassword
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    secretManagement:
      source:
        config: db
      encryption: true
    oes:
      rbac:
        enabled: true
      admin:
        user: admin
      platform:
        url: http://oes-platform:8095
      visibility:
        url: http://oes-visibility:8096
      auditservice:
        enabled: true
        url: "http://oes-audit-service:8097"
      auditclientservice:
        name: auditclient
        url: "http://oes-audit-client:8098"
      dashboard:
        url: http://oes-dashboard:8094
      commongateurl: http://oes-gate:8084
    pipeline-promotion:
      github:
        
        enabled: true
        
        username:  zd-svc-spinnaker-staging
        token: encrypted:gittoken:gittoken
        branch: main
        cloneUrl: https://zd-svc-spinnaker-staging:encrypted:gittoken:gittoken@github.com/zendesk/spin-staging
      bitbucket:
        
        enabled: false
        
        username:  zd-svc-spinnaker-staging
        token: encrypted:gittoken:gittoken
        branch: main
        cloneUrl: https://zd-svc-spinnaker-staging:encrypted:gittoken:gittoken@github.com/zendesk//spin-staging
      amazonS3:
        
        enabled: false
        
        accessKeyId: AWS_ACCESS_KEY_ID
        secretAccessKey: AWS_SECRET_ACCESS_KEY
        region: regionofbucket
        bucketName: bucket name.e.g-testbucket
    spinnaker:
      restart:
        endPoint: /webhooks/webhook/restartSpinnaker
      encrypt:
        enabled: false
      sync:
        permission:
          enabled: true
    
    datasources:
      platform: true
    
    ## Set the below field to true if agent for kubernetes
    kubernetes:
      kinds:
      omitKinds:
      - podPreset
      agent:
        enabled: false
        serverInternalHostName: opsmx-controller-controller1
        serverPort: 9003
        caCertfile: /opt/opsmx/controller/ca.crt
        certFile: /opt/opsmx/controller/cert/tls.crt
        keyFile: /opt/opsmx/controller/cert/tls.key
        image: quay.io/opsmxpublic/forwarder-agent:v3.5.7
      template:
        path: /opt/opsmx/controller
        kubectlTemplateFileName: kubeconfig.template
        manifestTemplateFileName: deploy-agent.template
    
  client.p12: |
    
kind: Secret
metadata:
  name: oes-sapor-config
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/secrets/oes-visibility-secret.yaml
apiVersion: v1
stringData:
  visibility-local.yml: |
    message-broker:
      enabled: true
      username: 'rabbitmq'
      password: 'encrypted:rabbitmqpassword:rabbitmqpassword'
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    spring:
      datasource:
        url: jdbc:postgresql://opsmx-spinnaker-postgres-1.cdswufymuxfo.us-east-1.rds.amazonaws.com:5432/visibilitydb
        username: 'spinnaker'
        password: 'encrypted:postgresql-admin-password:postgresql-admin-password'
        #sslmode: require
    logging:
      level:
        io:
          swagger:
            models:
              parameters:
                AbstractSerializableParameter: ERROR
    visiblity:
      connectors:
        configured:
          - name: "JIRA"
            displayName: "Jira"
          - name: "GITHUB"
            displayName: "GitHub"
          - name: "AUTOPILOT"
            displayName: "Verification"
          - name: "SONARQUBE"
            displayName: "SonarQube"
          - name: "JENKINS"
            displayName: "Jenkins"
          - name: "AQUAWAVE"
            displayName: "Aqua Wave"
          - name: "APPSCAN"
            displayName: "HCL AppScan"
    management:
      endpoints:
        web:
          base-path: /mgmt
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          show-details: always
          show-components: always
      health:
        elasticsearch:
          enabled: false
        ldap:
          enabled: false
    
    ui:
      approval:
        url: /ui/plugin-isd/approval/{applicationId}/{serviceId}/{approvalGateId}
    
    gate:
      url: http://oes-gate:8084
    
    jira:
      api:
        url: /rest/api/2/search
      navigate:
        url: hosturl/browse/{issue_Id}
    
    git:
      apiurl: /repos/{account}/{repo}/commits/{commitId}
      userurl: /user
      navigate.url: https://github.com/{account}/{repo_name}/commit/{commit_Id}
    
    jenkins:
      api:
        url: /job/{jobname}/{buildId}/api/json
      navigate:
        url: hosturl/job/{jobname}/{buildId}
    
    sonar:
      navigate:
        Url: hosturl/dashboard?id={projectKey}
    
    aquawave:
      api:
        url: https://api.aquasec.com/v2/images/{id}
      navigate:
        url: https://cloud.aquasec.com/vs/#/images/{id}
    
    autopilot:
      api:
        url: http://oes-autopilot:8090
    
    platform:
      service:
        url: http://oes-platform:8095
    auditservice:
      enabled: true
      name: auditservice
      url: "http://oes-audit-service:8097"
    auditclientservice:
      name: auditclientservice
      url: "http://oes-audit-client:8098"
    
    datasource:
      secretManagement:
        source: db
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    
kind: Secret
metadata:
  name: oes-visibility-config
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/secrets/opsmx-gitops-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  gitcloneparam: https://zd-svc-spinnaker-staging:encrypted%3Agittoken%3Agittoken@github.com/zendesk/spin-staging.git

  # Repo details to fetch dynamic configuration
  dynamicaccountsgituri: https://github.com/zendesk/spin-staging.git
  gituser: zd-svc-spinnaker-staging
  gittoken: encrypted:gittoken:gittoken
  dynamicAccRepository: spin-staging

kind: Secret
metadata:
  name: opsmx-gitops-auth
type: Opaque
---
# Source: oes/templates/secrets/sapor-bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        config:
          server:
            composite:
              - type: native
                search-locations: ${user.home}/config
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
kind: Secret
metadata:
  name: sapor-bootstrap
  labels:
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: release-name
data:
  redis.conf: |-
    # User-supplied configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 60 1000
  master.conf: |-
    dir /data
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
  replica.conf: |-
    dir /data
    slave-read-only yes
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
---
# Source: oes/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-health
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: release-name
data:
  ping_readiness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: oes/charts/spinnaker/templates/configmap/additional-profile-configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-spinnaker-additional-profile-config-maps
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
data:
  echo-local.yml: |-
    microsoftteams:
      enabled: true
    rest:
      enabled: true
      endpoints:
      - url: http://oes-audit-service:8097/auditservice/v1/echo/events/data
        wrap: false
      - url: http://oes-sapor:8085/oes/echo
        wrap: false
  fiat-local.yml: |-
    auth:
      groupMembership:
        ldap:
          groupRoleAttributes: cn
          groupSearchBase: ou=groups,dc=example,dc=org
          groupSearchFilter: member={0}
          managerDn: cn=admin,dc=example,dc=org
          managerPassword: opsmxadmin123
          url: ldap://RELEASE_NAME-openldap:389
          userDnPattern: cn={0},dc=example,dc=org
        service: ldap
  front50-local.yml: |-
    policy:
      opa:
        enabled: true
        url: http://oes-sapor.default:8085
  gate-local.yml: |-
    server:
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    spinnaker:
      extensibility:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.CustomStagePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        plugins: null
        repositories:
          opsmx-repo:
            url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.9.0/plugins.json
  # Custom stage for pipeline promotion;
  # same configuration can be put in a repo for gitops style
  orca-local.yml: |-
    
    policy:
      opa:
        enabled: true
        url: http://oes-sapor:8085
    pollers:
      oldPipelineCleanup:
        enabled: true                  # This enables old pipeline execution cleanup (default: false)
        intervalMs: 3600000            # How many milliseconds between pipeline cleanup runs (default: 1hr or 3600000)
        thresholdDays: 30              # How old a pipeline execution must be to be deleted (default: 30)
        minimumPipelineExecutions: 5   # How many executions to keep around (default: 5)
    
    tasks:
      daysOfExecutionHistory: 180      # How many days to keep old task executions around.
    
    job:
      preconfigured:
        kubernetes:
          - label: pipelineSyncToGit
            cloudProvider: kubernetes
            credentials: default
            description: Update git with pipelines in Spinnaker
            account: default
            application: sampleapp
            type: pipelineSyncToGit
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'upload'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
          - label: pipelineSyncToSpinnaker
            cloudProvider: kubernetes
            credentials: default
            description: Sync Spinnaker pipelines from git
            account: default
            application: sampleapp
            type: pipelineSyncToSpinnaker
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'download'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: local-spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
    webhook:
      preconfigured:
      - label: "JIRA: Wait for state"
        type: waitJiraState
        enabled: true
        description: Custom stage that waits for a specific state on a Jira Issue
        method: GET
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        failPipeline: true
        progressJsonPath: "fields.status.name"
        payload: ""
        retryStatusCodes:
          - 200
        statusJsonPath: "fields.status.name"
        statusUrlResolution: "getMethod"
        successStatuses: ${parameterValues['success']}
        retryStatuses: ${parameterValue['retry']}
        terminalStatuses: ${parameterValues['terminate']}
        canceledStatuses: ${parameterValues['cancel']}
        waitBeforeMonitor: "1"
        waitForCompletion: true
        parameters:
        - label: JIRA Issue ID
          name: issue
          description: "The JIRA issue, the default relies on JIRA issue ID extraction"
          type: string
          defaultValue: ${jira_issue}
        - label: JIRA Retry States
          name: retry
          description: "JIRA issue states that Retry the stage e.g,: To Do, In Progress, etc."
          type: string
          defaultValue: To Do, In Progress
        - label: JIRA Success States
          name: success
          description: "JIRA issue States that progress the pipeline, e.g,: In Verificaiton etc."
          type: string
          defaultValue: In Verification
        - label: JIRA Temination States
          name: terminate
          description: "JIRA issue states that terminates the pipeline, e.g,: PR Raised etc."
          type: string
          defaultValue: PR Raised
        - label: JIRA Canceled States
          name: cancel
          description: "JIRA issue states that cancel the pipeline e.g,: Done, etc."
          type: string
          defaultValue: Done
      - label: "JIRA: Create Issue"
        type: addJiraIss
        enabled: true
        description: Custom stage that add an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/2/issue/
        customHeaders:
         ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
         Authorization: Basic base64{<<USER>>:<<Jira-token>>}
         Content-Type: application/json
        payload: |-
          {
            "fields": {
               "project":
                {
                  "key": "${parameterValues['projectid']}"
                },
                "summary": "${parameterValues['summary']}",
                "description": "${parameterValues['description']}",
                "issuetype": {
                  "name": "${parameterValues['issuetype']}"
                },
                "components": [
                    {
                  "id": "${parameterValues['components']}"
                }
                ],
                "priority": {
                  "name": "${parameterValues['priority']}"
                }
            }
          }
        parameters:
        - label: Project ID ("ENG" or "DOCS")
          name: projectid
          description: Which JIRA project do you want to create an item in?
          type: string
        - label: Issue Type ("Improvement", "Task", "New Feature", or "Bug")
          name: issuetype
          description: issuetype
          type: string
        - label: Priority ("Low", "Medium", or "High")
          name: priority
          description: priority
          type: string
        - label: Components ("10103")
          name: components
          description: component of the project
        - label: Issue Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
          type: string
      - label: "JIRA: Comment on Issue"
        type: comJiraIss
        enabled: true
        description: Custom stage that posts a comment in a Jira Issue
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/comment
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "body": "${parameterValues['message']}"
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Message
          name: message
          description: message
          type: string
      - label: "JIRA: Update Issue"
        type: updJiraIss
        enabled: true
        description: Custom stage that updates an Issue in Jira
        method: PUT
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "update": {
                "summary": [
                    {
                        "set": "${parameterValues['summary']}"
                    }
                ],
                "description": [
                    {
                       "set": "${parameterValues['description']}"
                    }
                ]
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
      - label: "JIRA: Transition Issue"
        type: transJiraIss
        enabled: true
        description: Custom stage that transitions an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/transitions
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "transition": {
              "id": "${parameterValues['targetStageID']}"
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Target Stage ID
          name: targetStageID
          description: Target Stage ID (11 is "To Do", 21 is "In Progress", 31 is "In Review", 41 is "Done")
          type: string
    spinnaker:
      extensibility:
        plugins-root-path: /tmp/plugins
        plugins:
          Opsmx.VerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.VisibilityApprovalPlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.TestVerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.PolicyGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.RbacPlugin:
            enabled: true
            version: 1.0.1
            config:
        repositories:
          opsmx-repo:
            id: opsmx-repo
            url: file:///opt/spinnaker/plugins/plugins.json
            #url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.10.0/plugins.json
    

  echo-local.yml: |-
    rest:
      enabled: true
      endpoints:
       -
        wrap: false
        url: http://oes-sapor.default:8085/oes/echo
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-spinnaker-halyard-config
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
data:
  install.sh: |
    #!/bin/bash

    # Wait for the Hal daemon to be ready
    export DAEMON_ENDPOINT='curl http://release-name-spinnaker-halyard:8064/health'
    export HAL_COMMAND="$DAEMON_ENDPOINT"
    until $HAL_COMMAND ; do sleep 10 ; done # end of if not gitops

    # This is performed by post-start script in halyard pod
    # in case gitopsHalyard is enabled
  clean.sh: |
    export HAL_COMMAND='hal --daemon-endpoint http://release-name-spinnaker-halyard:8064'
    if $HAL_COMMAND --ready; then
      $HAL_COMMAND deploy clean -q
    fi
  config.sh: |
    # Spinnaker version
    
    $HAL_COMMAND config version edit --version 1.30.1
    

    # Storage
    
    
    
    

    # Docker Registry
    $HAL_COMMAND config provider docker-registry enable

    if $HAL_COMMAND config provider docker-registry account get dockerhub; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider docker-registry account $PROVIDER_COMMAND dockerhub --address index.docker.io \
       \
      --repositories library/alpine,library/ubuntu,library/centos,library/nginx

    $HAL_COMMAND config provider kubernetes enable

    if $HAL_COMMAND config provider kubernetes account get default; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider kubernetes account $PROVIDER_COMMAND default --docker-registries dockerhub \
                --context default --service-account true \
                 \
                --only-spinnaker-managed true \
                 \
                 \
                --omit-namespaces=kube-system,kube-public \
                 \
                 \
                 \
                --provider-version v2
    $HAL_COMMAND config deploy edit --account-name default --type distributed \
                           --location default
    $HAL_COMMAND config deploy ha clouddriver enable
    $HAL_COMMAND config deploy ha echo enable

    # Enable Authentication by default
    $HAL_COMMAND config security authn ldap disable

    # Enable Authorization
    $HAL_COMMAND config security authz enable


    # Use Deck to route to Gate
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-init-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-spinnaker-halyard-init-script
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
data:
  init.sh: |
    #!/bin/bash -x
    rm -rf /tmp/spinnaker/.hal
    GIT_USER=`echo $GIT_USER | sed 's/ *$//g'`
    GIT_TOKEN=`echo $GIT_TOKEN | sed 's/ *$//g'`
    git -c http.sslVerify=false clone $GIT_CLONE_PARAM -b main /tmp/spinnaker/test 2>/tmp/tmp.log
    if [[ $? != 0 ]]; then
       echo "ERROR: Failed while trying to execute:"
       echo "git -c http.sslVerify=false clone $GIT_CLONE_PARAM -b main /tmp/spinnaker/test" | sed s/$GIT_TOKEN/\<TOKEN_REDACTED\>/g
       sed s/$GIT_TOKEN/\<TOKEN_REDACTED\>/g /tmp/tmp.log
       echo "####"
       echo "Correct baseUrlHostName, organization, username, token and repository in values.yaml and re-execute 'helm upgrade --install ....' command"
       echo "   It is possible that you need to use repoType as stash instead of git. Please check the documentation."
       echo "To expedite the restart, wait for 60 seconds and delete the spinnaker-halyard-0 pod from another window"
       exit 4
    fi
    cp -r /tmp/spinnaker/test// /tmp/spinnaker/.hal
    if [ -d "/tmp/spinnaker/test/pipeline-promotion/" ]
    then
       cp -r /tmp/spinnaker/test/pipeline-promotion /tmp/spinnaker/pipeline-promotion
    fi
    if [ -d "/tmp/spinnaker/test/clusterconfig/" ]
    then
       cp -r /tmp/spinnaker/test/clusterconfig /tmp/spinnaker/clusterconfig
    fi
    ## If BOM file present in gitops repo consider bom file and replace images in the service-setting folder to the respective services
    if [ -r "/tmp/spinnaker/test/bom" ]
    then
      cp -r /tmp/spinnaker/test/bom /tmp/spinnaker/bom
      rm -rf /tmp/spinnaker/.hal/bom
      ## Updated the halyard config version
      crthalversion=$(yq e '.deploymentConfigurations.[].version' /tmp/spinnaker/.hal/config)
      halversion=$(yq e '.version' /tmp/spinnaker/bom)
      echo "INFO: Updating the halyard version from VERSION $crthalversion to VERSION $halversion"
      yq -i e '.deploymentConfigurations.[].version = "'$halversion'"' /tmp/spinnaker/.hal/config
      ## Read service  as asingle line comma saperated
      echo "INFO: Updating the spinnaker images of service-settings folder using bom file in gitops"
      halservices=$(yq e '(.services | keys)[]' /tmp/spinnaker/bom | xargs | sed -e 's/ /,/g')
      IFS=","
      for i in $halservices
      do
        svcimg=$(yq e '.services.'$i'.image' /tmp/spinnaker/bom)
        svcn=$(find /tmp/spinnaker/.hal/default/service-settings/ -name "$i"* | awk -F"/" '{print $NF}' | xargs | sed -e 's/ /,/g')
        if [[ "$svcn" != "" ]];
        then
          IFS=","
          for svcfile in $svcn
          do
            yq -i e '.artifactId = "'$svcimg'"' /tmp/spinnaker/.hal/default/service-settings/$svcfile
          done
        else
          echo "WARNING: Service file $i is not located in default/service-settings/ to override the artifact image from bom"
        fi
      done
    else
      echo "WARNING: Not specified bom in gitops repo overidden images will be  taken from default/service-settings"
    fi
    rm -rf /tmp/spinnaker/test
    DYNAMIC_ACCOUNTS_REPO=`echo $DYNAMIC_ACCOUNTS_REPO | sed 's/ *$//g'`
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/config
    sed -i  s/RELEASE_NAME/release-name/g /tmp/spinnaker/.hal/config
    BRANCH=main
    sed -i s/BRANCH/${BRANCH}/ /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    KEY=Q7udUkHPuA3VnNlOtksSgQ
    sed -i s/KEY/${KEY}/ /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    CDName=preview-saas
    sed -i s/CDName/${CDName}/ /tmp/spinnaker/.hal/default/profiles/echo-local.yml
    sed -i  s/GIT_USER/${GIT_USER}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/GIT_TOKEN/${GIT_TOKEN}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  's|DYNAMIC_ACCOUNTS_REPO|'"${DYNAMIC_ACCOUNTS_REPO}"'|' /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s%DYN_ACCNT_CONFG_PATH%/%g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/RELEASE_NAME/release-name/g /tmp/spinnaker/.hal/default/profiles/rosco-local.yml
    sed -i  s/RELEASE_NAME/release-name/g /tmp/spinnaker/.hal/default/service-settings/redis.yml
    yq -i e '.deploymentConfigurations.[].security.authn.ldap.enabled = "false"' /tmp/spinnaker/.hal/config
    yq -i e '.deploymentConfigurations.[].security.authz.enabled = "true"' /tmp/spinnaker/.hal/config
    yq -i e '.tasks.useManagedServiceAccounts = "true"' /tmp/spinnaker/.hal/default/profiles/orca-local.yml
    sed -i s/false/true/ /tmp/spinnaker/.hal/default/profiles/settings-local.js
    yq -i e '.migrations.migrateToManagedServiceAccounts = "true"' /tmp/spinnaker/.hal/default/profiles/front50-local.yml
    readfiat=$(yq e '.fiat' /tmp/spinnaker/.hal/default/profiles/fiat-local.yml)
    if [[ "$readfiat" == "null" ]];
    then
      yq -i e '.fiat.admin.roles += ["okta:role:spinnaker-superadmin"]' /tmp/spinnaker/.hal/default/profiles/fiat-local.yml
    else
      echo "INFO: Admin groups already present in fiat-local.yml file"
    fi
    if [ -f /tmp/spinnaker/.hal/default/profiles/fiat-local.yml ]; then
    sed -i  s/RELEASE_NAME/release-name/g /tmp/spinnaker/.hal/default/profiles/fiat-local.yml
    fi
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/default/profiles/orca-local.yml
    printf 'server.address: 0.0.0.0\n' > /tmp/config/halyard-local.yml
    if [ -f /tmp/spinnaker/.hal/halyard.yaml ]; then
    cp /tmp/spinnaker/.hal/halyard.yaml /tmp/config
    fi
    yq -i e '.deploymentConfigurations.[].security.authn.saml.enabled = "true"' /tmp/spinnaker/.hal/config
    yq -i e '.deploymentConfigurations.[].security.apiSecurity.overrideBaseUrl = "https://isd-staging.zende.sk/gate"' /tmp/spinnaker/.hal/config
    yq -i e '.deploymentConfigurations.[].security.uiSecurity.overrideBaseUrl = "https://spinnaker-staging.zende.sk"' /tmp/spinnaker/.hal/config
    if [ -f /tmp/spinnaker/.hal/default/profiles/settings-local.js ]; then
       cat /tmp/spinnaker/.hal/default/profiles/settings-local.js | grep -o uiUrl
       if [ $? != 0 ]; then
         echo "Updating the ISD URL in settings-local.js file"
         echo 'var uiUrl = "https://isd-staging.zende.sk";' >> /tmp/spinnaker/.hal/default/profiles/settings-local.js
       fi
    else
       touch /tmp/spinnaker/.hal/default/profiles/settings-local.js
       cat /tmp/spinnaker/.hal/default/profiles/settings-local.js | grep -o uiUrl
       if [ $? != 0 ]; then
         echo "Created and Updated the ISD UI Url in settings-local.js file"
         echo 'var uiUrl = "https://isd-staging.zende.sk";' >> /tmp/spinnaker/.hal/default/profiles/settings-local.js
       fi
    fi
    rm -rf /tmp/spinnaker/.hal/default/profiles/orca-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/fiat-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/gate-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/spinnaker.yml  # git or stash  # Enabled  # End of S3

    # The decrypt token extract
    kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d > /tmp/decryptkry.txt
    decrypt_key=$(yq e '.jasypt.encryptor.password' /tmp/decryptkry.txt)

    # pipeline promotion configuration setup
    #
    ls -lart /home/spinnaker/java-lib/
    if [ -d "/tmp/spinnaker/pipeline-promotion/" ]
    then
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/pipeline-promotion/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/pipeline-decrypted/
      mv /tmp/spinnaker/pipeline-promotion/*decrypted.yaml /tmp/spinnaker/pipeline-decrypted/
      kubectl apply -f /tmp/spinnaker/pipeline-promotion/pipe-promot-config-cm.yaml -n ${SPINNAKER_NAMESPACE}
      kubectl apply -f /tmp/spinnaker/pipeline-decrypted/ -n ${SPINNAKER_NAMESPACE}
     fi
    fi
    # decrypt json files for integrations

    ls /tmp/spinnaker/.hal -1 | grep .enc > /tmp/jsonfiles
    if [ -s /tmp/jsonfiles ];
    then
      if [[ $decrypt_key != "" ]];
      then
        echo "Data is available in jsonfiles"
        while read -r line;
        do
         echo "$line" ;
         java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "/tmp/spinnaker/.hal/$line" json
        done < /tmp/jsonfiles
        rm -rf /tmp/spinnaker/.hal/*.enc
        cp /tmp/spinnaker/.hal/decrypted/* /tmp/spinnaker/.hal/
        rm -rf /tmp/spinnaker/.hal/decrypted/
      fi
    fi
    ############# Auto Configuration for Custom Stages in ORCA #############

    if [ -d "/tmp/spinnaker/clusterconfig/" ]
    then
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/clusterconfig/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/clusterconfig-decrypted/
      mv /tmp/spinnaker/clusterconfig/*decrypted.yaml /tmp/spinnaker/clusterconfig-decrypted/
      kubectl apply -f /tmp/spinnaker/clusterconfig-decrypted/ -n ${SPINNAKER_NAMESPACE}
        if [ -r "/tmp/spinnaker/clusterconfig/servicenow-secret.yaml" ]
        then
           #### Extracting the Service NOW information from secret ####
           SERVICENOW_USER=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_DNS=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_PASSWD=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_PASSWORD}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_BASE64_USR_PASSWD=$(echo -n "$SERVICENOW_USER:$SERVICENOW_PASSWD" | base64)
           sed -i s%SERVICENOW_URL%${SERVICENOW_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           sed -i  s/SERVICENOW_BASE64_USR_PASSWD/${SERVICENOW_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
        else
           echo "Not able to find the ServiceNow secret file"
        fi
        if [ -r "/tmp/spinnaker/clusterconfig/jira-secret.yaml" ]
        then
           #### Extracting the JIRA information from secret ####
           JIRA_TYPE=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_TYPE}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           if [ "$JIRA_TYPE" == "onPremJira" ];then
             echo "Using the Jira On Prem Details"
             JIRA_USER=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
             JIRA_DNS=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
             JIRA_TOKN=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_TOKEN}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
             JIRA_BASE64_USR_PASSWD=$JIRA_TOKN
             sed -i s%JIRA_URL%${JIRA_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
             sed -i 's/Basic JIRA_BASE64_USR_PASSWD/Bearer TOKEN/g' /tmp/spinnaker/.hal/default/profiles/orca-local.yml
             sed -i s/TOKEN/${JIRA_TOKN}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           else
             if [ "$JIRA_TYPE" == "cloudJira" ];then
               echo "Using the Jira Cloud Details"
               JIRA_USER=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
               JIRA_DNS=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
               JIRA_TOKN=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_TOKEN}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
               JIRA_BASE64_USR_PASSWD=$(echo -n "$JIRA_USER:$JIRA_TOKN" | base64 )
               sed -i s%JIRA_URL%${JIRA_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
               sed -i s/JIRA_BASE64_USR_PASSWD/${JIRA_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
             fi
           fi
        else
          echo "Not able to find the JIRA secret file"
        fi
      fi
    fi
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-overrideurl.yaml
apiVersion: v1
data:
  call_overrides.sh: |
    echo $SPINNAKER_NAMESPACE
    sh /tmp/autoconfig/config_overrideurl.sh spin-gate-overrideurl-gitops
    sh /tmp/autoconfig/config_overrideurl.sh spin-deck-overrideurl-gitops
  config_overrideurl.sh: |
    #!/bin/bash -x

    if [ $# -gt 1 ]
    then
       echo "Invalid input, only one argument expected"
       exit
    fi

    COMPONENT=$1
    EXTERNAL_IP_CHECK_DELAY=1

    check_for_loadBalancer()
    {
        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        iter=0
        lapsedTime=0
        while [ $iter -lt 100 ]
        do
          ENDPOINT_IP=$(kubectl get svc $1 -o jsonpath="{.status.loadBalancer.ingress[].ip}")
          if [ ! -z "$ENDPOINT_IP" ];
          then
            echo "Found LoadBalancer IP for" $1
            break
          fi
          sleep 5
          lapsedTime=`expr $lapsedTime + 5`
          if [ $lapsedTime -gt $EXTERNAL_IP_CHECK_DELAY ];
          then
    	echo "Time Lapsed" $lapsedTime
            echo "Timeout! Fetching nodeport IP alternatively"
            break
          fi
          echo "Time Lapsed" $lapsedTime
          iter=`expr $iter + 1`
        done
    }

    case "$COMPONENT" in
      spin-gate)
        ENDPOINT_IP=""
        PORT=8084

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-gate external IP in hal config
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;

      spin-deck)
        ENDPOINT_IP=""
        PORT=9000

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-deck external IP in hal config
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;
      override-gate-url)
        ENDPOINT_IP=""
        PORT=8084

        export DAEMON_ENDPOINT=http://release-name-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override gate url
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      override-deck-url)
        ENDPOINT_IP=""
        PORT=9000

        export DAEMON_ENDPOINT=http://release-name-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override deck url
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      spin-gate-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting gate url"
          sed -i 's,PROTOCOL,https,g' /tmp/spinnaker/.hal/config
          sed -i 's,OVERRIDE_API_URL,isd-staging.zende.sk/gate,g' /tmp/spinnaker/.hal/config
        ;;
      spin-deck-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting deck url"
          sed -i 's,OVERRIDE_DECK_URL,isd-staging.zende.sk/deck,g' /tmp/spinnaker/.hal/config
        ;;
      *)
        echo  COMP=$COMPONENT
        echo "Invalid input:$COMPONENT"
        ;;
    esac

kind: ConfigMap
metadata:
  name: release-name-spinnaker-halyard-overrideurl
---
# Source: oes/charts/spinnaker/templates/configmap/secret-decoder.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-spinnaker-spin-secret-decoder
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
data:
  run.sh: |-
    #!/bin/bash
    echo "##########Replacing Secret#########"
    grep -ir encrypted: /tmp/spinnaker/.hal | sort -t: -u -k1,1 |cut -d : -f1 > tmp.list
    cat tmp.list | grep -v "oes\|install\|upgrade\|MISC\|SAMPLES\|values.yaml\|values-openldap.yaml" > tmp1.list
    echo "##### Following files have the encrypted secrets ########"
    cat tmp1.list
    while IFS= read -r file; do
    grep encrypted: $file > tmp2.list
    while read line ; do
    echo ${line#*encrypted:} ;
    done < tmp2.list > secret-strings.list
    while read secret ; do
    secretName=${secret%%:*}
    echo "---------$secretName---"
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "----------$keyName--"
    #echo "secret Name= $secretName and key is = $keyName"
    #kubectl get secret -o jis
    #echo kubectl --kubeconfig /home/srini/ibm-cloud/staging/ibmstaging.config -n ninja-srini get secret $secretName -o json  jq -r ".data.$keyName"
    jqParam=".data.\"$keyName\""
    value=$(kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d)
    value=$(echo $value | sed -e 's`[][\\/.*^$]`\\&`g')
    #echo "-----------$value---"
    #echo "secret Name= $secretName and key is = $keyName and value is $value"
    sed -i s/encrypted:$secretName:$keyName/$value/g $file
    done < secret-strings.list
    done < tmp1.list

    echo "########### Replacing Kubeconfigs ############"
    grep encryptedFile /tmp/spinnaker/.hal/config > tmp.list
    while read line ; do
    echo ${line#*encryptedFile:} ;
    done < tmp.list  > secret-files.list

    while read secret ; do
    secretName=${secret%%:*}
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "secret Name= $secretName and key is = $keyName"
    jqParam=".data.\"$keyName\""
    mkdir -p /tmp/spinnaker/kubeconfigdir
    kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d > /tmp/spinnaker/kubeconfigdir/$keyName
    #echo "secret Name= $secretName and key is = $keyName and value is in $keyName"
    old_value="encryptedFile:$secretName:$keyName"
    new_value="/home/spinnaker/kubeconfigdir/$keyName"
    #echo $old_value
    #echo $new_value
    sed -i "s/${old_value}/$(echo $new_value | sed 's_/_\\/_g')/g" /tmp/spinnaker/.hal/config
    done < secret-files.list
    rm -rf secret-files.list secret-strings.list tmp.list tmp1.list tmp2.list
---
# Source: oes/charts/spinnaker/templates/configmap/service-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-spinnaker-service-settings
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"

data:
  clouddriver-caching.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro-deck.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-rw.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  deck.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-deck:3.5.1
    env:
      API_HOST: http://spin-gate:8084
  echo-scheduler.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo-worker.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  fiat.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-fiat:1.16.0'
  front50.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-front50:0.27.1-opa'
  gate.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-spin-gate:1.22.1
    healthEndpoint: /health
    kubernetes:
      useExecHealthCheck: false
  igor.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-igor:1.16.0'
  kayenta.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-kayenta:0.21.0'
  orca.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-orca:2.20.4'
  redis.yml: |-
    overrideBaseUrl: redis://<EXTERNAL-REDIS-HOST-NAME>:6379
    skipLifeCycleManagement: true
  rosco.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-rosco:0.25.0'
---
# Source: oes/charts/spinnaker/templates/configmap/spin-pipeline-import.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-spinnaker-spin-pipeline-import
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
data:
  spin-pipeline-import.sh: |-
    #!/bin/bash
    echo "Waiting for all Spinnaker Services to come-up"
    wait_period=0
    while true
    do
    kubectl get po -n default -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    ## NON-HA
    CLOUDDRIVER=$(grep spin-clouddriver /tmp/inst.status |grep -v deck | awk '{print $2}')
    ECHO=$(grep spin-echo /tmp/inst.status | awk '{print $2}')
    ## HA
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    #GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    ## AUTOPILOT
    SAPORGATE=$(grep sapor-gate /tmp/inst.status | awk '{print $2}')
    OESGATE=$(grep oes-gate /tmp/inst.status | awk '{print $2}')
    wait_period=$(($wait_period+10))
    READYBASIC=$( [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$ORCA" == "true" ] && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPORGATE" == "true" ] && [ "$OESGATE" == "true" ];  echo $(($? == 0)) )
    READY=$( [ $READYBASIC == 1 ] && [ "$FIAT" == "true" ]; echo $(($? == 0)) )
    if [ $READY == 1 ];
    then
        echo "Spinnaker and OES is Installed and ready"
        echo "processing.........."
        sleep 100
        cp -r sample-pipelines/* /tmp/config/git/
        cd /tmp/config/git
        cp -p /tmp/config/spin/config .
        ### remove commected line in file
        grep -v "#" create-app.sh > removecomment.sh
        sed 's/$/ --config config/' removecomment.sh > create-app1.sh
        #### Loop begins to save the json if fails it tries for 3 times
        INPUT=$(sed -n '$=' create-app1.sh)
        for i in $(seq 1 $INPUT); do
        command=$(sed -n "$i"p create-app1.sh);
        $command > /dev/null 2>&1
        if [[ $? != 0 ]]; then
          n=0
          until [ "$n" -ge 3 ]
          do
           echo Retrying.....
           $command > /dev/null 2>&1
            if [[ $? != 0 ]]; then
              echo "ERROR: Failed to save the Application/Pipeline using the spincli. Please check the spincli configuration in release-name-spinnaker-spin-config  secret or check the pipelinejson"
              echo "$command"
              #exit 1
              if [[ "$i" == 3 ]]; then
              echo "ERROR: Failed to save the Application/Pipeline using the spincli. Please check the spincli configuration in release-name-spinnaker-spin-config  secret or check the pipelinejson"
              echo "$command"
              exit 1
              fi
            else
              echo "$command"
              echo "Saved successfully"
            fi
           n=$((n+1))
           sleep 5
         done
        else
          echo "$command"
          echo "Saved successfully"
        fi
        done
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo "Script is timed out as the Spinnaker is not ready in 30 min......."
            break
        else
            echo "Waiting for Spinnaker services to be ready"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/clouddriver-sidecar/k8sconfig-sync.yaml
apiVersion: v1
data:
  k8config-sync.sh: |
    #!/bin/bash
    export GIT_CLONE_PARAM=$(cat /tmp/secret/gitcloneparam)
    export GIT_URL=$(cat /tmp/secret/dynamicaccountsgituri)
    export DYNAMIC_ACCOUNTS_REPO=$(cat /tmp/secret/dynamicAccRepository)
    rm -rf $DYNAMIC_ACCOUNTS_REPO
    mkdir -p /opsmx
    echo " ####### Cloning the Dynamic Account Repo #################"
    git clone -c http.sslVerify=false $GIT_CLONE_PARAM
    #cd $DYNAMIC_ACCOUNTS_REPO/
    cat $DYNAMIC_ACCOUNTS_REPO///clouddriver-local.yml |grep -i opsmx |awk '{print $2}' |tr -d '"' | awk 'BEGIN{FS="/opsmx/"}{print $2}' > /opsmx/config_files.txt
    for config in $(cat /opsmx/config_files.txt)
    do
    kubectl get secrets $config -o=jsonpath='{.data.*}'|base64 -d > /opsmx/$config
    done
kind: ConfigMap
metadata:
  name: k8config-sync
---
# Source: oes/templates/configmaps/datasource-creation.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-oes-datasource-creation
  labels:
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
data:
  datasource-api.sh: |-
    #!/bin/bash
    set -x
    echo \"Waiting for all Spinnaker and OES Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n default -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    ## NON-HA
    CLOUDDRIVER=$(grep spin-clouddriver /tmp/inst.status |grep -v deck | awk '{print $2}')
    ECHO=$(grep spin-echo /tmp/inst.status | awk '{print $2}')
    ## HA
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    #GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    ## AUTOPILOT
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')
    AUTOPILOT=$(grep oes-autopilot /tmp/inst.status | awk '{print $2}')


    wait_period=$(($wait_period+10))
    READYBASIC=$([ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$ORCA" == "true" ]  && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ] && [ "$AUTOPILOT" == "true" ] && [ "$IGOR" == "true" ]; echo $(($? == 0)) )
    READY=$( [ $READYBASIC == 1 ] && [ "$FIAT" == "true" ] ; echo $(($? == 0)) )


    if [ $READY == 1 ] ;
        then
            echo \"Spinnaker and OES services are Up and Ready..\"
            sleep 5
            curl -X POST "http://sapor-gate:8084/login?username=hanumesh.kumar@zendesk.com&password=encrypted:saporpassword:saporpassword&submit=Login"
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "OPA", "name": "OPA", "configurationFields": {"endPoint": "http://opa:8181"}}'   http://oes-platform:8095/platformservice/v2/datasources
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "AUTOPILOT", "name": "Autopilot", "configurationFields": {"username": "admin"} }'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "ELASTICSEARCH", "name": "elastic-default", "configurationFields": {"endPoint": "https://newoeselastic.opsmx.com", "username": "opsmxuser", "password": "OpsMx@123", "kibanaEndPoint": "https://newoeskibana.opsmx.com", "kibanaPassword": "OpsMx@123", "kibanaUsername": "opsmxuser" }}'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "PROMETHEUS", "name": "prometheus-default", "configurationFields": {"endPoint": "http://prometheus:9090"} }'   http://oes-platform:8095/platformservice/v2/datasources
            echo "Creating OPA Policies"
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"AppMustHaveRbac","type":"Static","accountType":"OPA","accountName":"OPA","description":"Enforce Application in Spinnakr to have Roles defined.","status":"INACTIVE","rego":"# Static Policy to enforce assigning roles when creating an application\n# Once enforced, it is not possible to create an application that is visible to all\n# by mistake\n\npackage opsmx.spinnaker.authorization\n\ndeny[\"Permissions must be specified\"] {\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"updateApp\"\n }{\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"createApp\"\n}\nappHasWritePermissions {\n  count(input.new.job[0].application.permissions.WRITE) > 0\n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"StageLevelRBAC","type":"Static","accountType":"OPA","accountName":"OPA","description":"Restrict a group of users from modifying certain stages","status":"INACTIVE","rego":"package opsmx.spinnaker.stage_rbac\nimport future.keywords.in\n\n# The permissions json is to be defined to restrict some users from making changes to a specific stage\n# in the pipeline. The parameters for each stage are \"name\" of the pipeline, \"type\" of the pipeline and \"grant\" privilege\n# which can hold 2 values: allow and deny\npermissions = {\n  \"role_grants\": {\n    \"demo-users\": [\n      {\n        \"name\": \"Build\",\n        \"type\": \"jenkins\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Deploy \",\n        \"type\": \"deployManifest\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Manual Judgment \",\n        \"type\": \"manualJudgment\",\n        \"grant\": \"deny\"\n      },\n      {\n        \"name\": \"Wait\",\n        \"type\": \"wait\",\n        \"grant\": \"deny\"\n      }\n    ]\n  }\n}\n\n\n# modified_stages is the set of stages which carry \"modified\", \"new\" and \"deleted\" stageStatus. \n# only the stages with stageStatus = unmodified are excluded.\n\nmodified_stages = [input.pipeline.stages[idx] | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n#modified_stage_name = [input.pipeline.stages[idx].name | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n\n\n# The operation is denied if there is no modified/new/deleted stage in the pipeline\ndeny[\"No modified stages found\"]{\n  count(input.pipeline.stages) > 0         # only because we still have fron50 plugin; this will be removed in 3.12.x release\n  count(modified_stages) <= 0\n}\n\n# If there are modifications in the pipeline, the privileges of users to operate on a set of stages\n# is evaluated on the basis of\n\n# 1. If the user is admin, allow the user to do anything\n# 2. If the permissions json does not carry definition of privileges for any group assigned to the user,\n# then the user is to be allowed to make any changes\n# 3. If there are no denials in the permissions definition, then the user is to be allowed to make any changes\n# 4. If there are denials for some stages in any of the role assigned to user, then\n#\t4a. Checking if the same stages is allowed for any other role assigned to user\n#   4b. If a respective allow privilege is available, then allow.\n#   4c. If not then deny\n# 5. If there are any denials w.r.t. modified stages, simply deny the user from saving.\n# Rule 4 and 5 are contradicting, one of them is to be enabled. Comment line 92-100 to disable rule 4.\n\ndeny[msg]{\n  #not user_is_admin\n  \n  some i\n  role_def = permissions.role_grants[i]\n  role_def_flag = i in input.pipeline.user.groups\n  role_def_flag == true\n  \n  denial_set = user_is_denied\n  denial_size = count(denial_set) \n  to_number(denial_size) > 0\n\n# Comment rest of the statements in this rule if rule 4 is to be enabled\n  acceptance_set = user_is_allowed\n\n  some j\n  accepted_stages = [acceptance_set[j].name | acceptance_set[j].grant == \"allow\"]\n  \n  some k\n  denied_stages = [denial_set[k].name | denial_set[k].grant == \"deny\"; not denial_set[k].name in accepted_stages]\n  denial_size_after_acceptance = count(denied_stages)\n  denial_size_after_acceptance > 0\n  \n  denial_stage_msg = concat(\",\" , denied_stages)\n  msg = sprintf(\"Denied for stages: %v\", [denial_stage_msg])\n}\n\n\n# Check if user is admin\n#user_is_admin {\n # \"admin\" in input.pipeline.user.groups\n#}\n\n# Obtain list of denied and allowed stages for the groups assigned to user\nmake_grant_decision{  \n  some grant_idx\n  user_is_denied[grant_idx]\n\n  some grant_idx2\n  user_is_allowed[grant_idx2]\n}\n\nuser_is_denied[grant_idx] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx in permissions.role_grants[role]\n  \n  grant_idx.name == stage.name\n  grant_idx.type == stage.type\n  grant_idx.grant == \"deny\" \n}\n\nuser_is_allowed[grant_idx2] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx2 in permissions.role_grants[role]\n  \n  grant_idx2.name == stage.name\n  grant_idx2.type == stage.type\n  grant_idx2.grant == \"allow\" \n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"BlackOutWindow","type":"Runtime","accountType":"OPA","accountName":"OPA","description":"Policy to Prevent deployment during a specified date/time range.","status":"INACTIVE","rego":"# Sample Runtime policy\n  # This policy blocks deployments in the blackout window period\n  \n  package opsmx.blackoutwindow\n  \n  deny[\"No deploys between 25th - 31st Dec 2020\"] {\n    [year, month, day] := time.date([time.now_ns(), \"America/Los_Angeles\"])\n    year == 2020\n    month == 12\n    day >= 25\n    day <= 31\n  }"}'

            STORAGE_TYPE=git
            BASEURL_HOST=github.com
            USERNAME=hanumesh.kumar@zendesk.com
            PASSWORD=encrypted:saporpassword:saporpassword
            TOKEN=$(echo -n "$USERNAME":"$PASSWORD" | base64)
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "github.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "encrypted:gittoken:gittoken", "username": "zd-svc-spinnaker-staging", "hostUrl": "https://github.com/", "url": "https://api.github.com" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"https://github.com/zendesk/spin-staging.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://oes-gate.example.ops.com", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true","pipelinePromotionFlag": "false","syncAccountFlag": "false", "externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops", "provider": "GITHUB", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/zendesk/spin-staging.git", "sourcePath": "" }}}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "gitlab.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITLAB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "encrypted:gittoken:gittoken", "hostUrl": "https://gitlab.com/" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITLAB","config":{"bucketName":"","region":"","endPoint":"https://gitlab.com/zendesk/spin-staging.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "stash" ]];
              then
                if [[ "" ]]
                then
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "zd-svc-spinnaker-staging","token": "encrypted:gittoken:gittoken","read":"","write":"",  "hostUrl": "https://github.com/zendesk//spin-staging.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                   curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag": "false","syncAccountFlag": "false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/zendesk//spin-staging.git", "sourcePath": " " }}}'

                  break
                else
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "zd-svc-spinnaker-staging","token": "encrypted:gittoken:gittoken","read":"","write":"", "hostUrl": "https://github.com/zendesk//spin-staging.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                  curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag":"false","syncAccountFlag":"false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/zendesk//spin-staging.git", "sourcePath": "" }}}'
                  break
                fi
              fi
              if [[ "$STORAGE_TYPE"  ==  "s3" ]];
              then
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType":"AMAZONS3","name":"gitops-s3","configurationFields":{"access_id":"AWS_ACCESS_KEY_ID","secret_key":"AWS_SECRET_ACCESS_KEY"},"spinnakerNames":[""],"spinEnabled": "false"} }'
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'" , "externalAccountFlag": "true", "pipelinePromotionFlag":"false", "syncAccountFlag":"false", externalAccountConfiguration": {"accountName": "gitops-s3","config":{"bucketName":"bucket name.e.g-testbucket","region":"regionofbucket","endPoint":""},"provider": "AMAZONS3"}}'
              fi
            else
              echo "Spinnaker is already Integrated"
              break
            fi
        

    else
        if [ $wait_period -gt 2000 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready yet.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/configmaps/isd-feature-flag-config.yml
apiVersion: v1
data:
  feature.yml: |
     feature:
       auth-provider:
         flag: true
         jira: OP-18050
       db-cleanup:
         flag: true
         jira: OP-19921
kind: ConfigMap
metadata:
  labels:
    app: oes
  name: isd-feature-flag-config
---
# Source: oes/templates/configmaps/oes-dashboard-configmap.yaml
apiVersion: v1
data:
  dashboard-local.yml: |
    opsmx:
      dashboard:
        installation:
          mode: OES-AP
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    platformservice.url: http://oes-platform:8095
    autopilot.url: http://oes-autopilot:8090
    oes.sapor.url: http://oes-sapor:8085
    visibilityservice.url: http://oes-visibility:8096
    auditclientservice:
      url: "http://oes-audit-client:8098"
    gateservice:
      url: "http://oes-gate:8084"
    app:
      sync:
        enabled: true
    spinnakerLink: /deck/
    
kind: ConfigMap
metadata:
  name: oes-dashboard-config
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/configmaps/oes-ui-configmap.yaml
apiVersion: v1
data:
  app-config.json: |
    {
        "endPointUrl": "/gate/",
        "policyUrl": "http://oes-sapor:8085/",
        "setApplicationInterval": 300000,
        "triggerPipeline": false,
        "cdTool": "Spinnaker",
        "multi_cd_enabled" : false,
        "hide_accessManagement": true,
        "hide_agent" : true,
        "hide_cd_integration": false,
        "hide_cloud_targets": true,
        "hide_integrations": true,
        "hide_pipelineTemplates": true,
        "hide_policies": true,
        "hide_users": true,
        "grafana_enabled": false,
        "grafanaPipelineInsightsEndpoint": "https://isd-staging.zende.sk/grafana/d/pipeline-insight/pipeinsights",
        "grafanaStageInsightsEndpoint": "https://isd-staging.zende.sk/grafana/d/stage-insight/stageinsights"
    }
  help-text.json: "{\n  \"POLICY_LISTING\": {\n    \"HEADER\": \"Policies not found!\",\n
    \   \"BODY\": \"<div><p>Policy Management feature allows you to create policies
    to set guardrails for safe and fine grained controls in CI/CD pipelines.</p> <p>Static
    Policy lets users validate the conditions when creating a pipeline, whereas Runtime
    Policy enables users for automated decision making during pipeline execution.</p>
    <p>A policy defines a set of conditions that must be met.</p> <p>As an example,
    a policy could be created to define a blackout window period (or a moratorium period)
    for performing production deployments. A moratorium period defines the time period
    within which no production deployments should be performed. Any deployment to the
    production environment during this period will automatically be rejected/stopped.</p>
    <p>ISD uses Open Policy Engine(OPA) for policy definition & execution. OPA is a
    open source, general-purpose policy engine that unifies policy enforcement across
    the stack. It uses a high-level declarative language called Rego that lets you specify
    policy as code.</p> <p>Click on <b>New Policy</b> button to create a new policy.</p></div>\"\n
    \ },\n  \"AGENT_LISTING\": {\n    \"HEADER\": \"No Agents found!\",\n    \"BODY\":
    \"<div><p>The Agent allows ISD to reach through firewalls in a secure manner, allowing
    access to private Kubernetes clusters as well as reach internal services such as
    Jenkins and Artifactory. The agent is typically used with OpsMx's SaaS ISD offering,
    where OpsMx hosts the ISD Platform, but services used by the platform are within
    a secure area owned by the customer. One of the core advantages of using an agent
    is that the credentials do not need to be disclosed to anyone i.e. credentials remain
    with-in the cluster where deployment is done.</p> <p>The Agent is a two part system:
    a <b>Controller</b> runs near ISD, and the <b>Agent</b> runs in the target secure
    cluster. The Agent is configured to communicate with specific services (Kubernetes,
    Jenkins etc) within a customer's security domain, while the Controller is in ISD's
    domain.</p> <p>The Agent is deployed using a manifest generated by ISD. This manifest
    has per-installation credentials to authenticate to the controller, controller address
    etc. Services are configured in the Agent by the customer. URL endpoints, CD account
    names and credentials are provided to the agent using a service configuration. The
    credentials never leave the agent's security domain.</p> <p>Click on <b>New Agent</b>
    to create the Agent for your environment. This button is enabled when CD Instance
    is configured in <b>Setup->CD Integration</b>.\"\n  },\n  \"AGENT_CREATION\": {\n
    \   \"HEADER\": \"Agent\",\n    \"BODY\": \"<div><p>Adding an agent involves the
    following steps:</p><ul class='helpTextUI'><li>Enter the details (name, cluster
    and description) and click save</li> <li>Click <b>Download Manifest</b> which appears
    after save</li><li>In the remote Kubernetes cluster, create service configmap in
    the default namespace. Examples are available here: https://github.com/OpsMx/standard-gitops-repo/tree/master/SAMPLES/agent-config</li>
    <li>Apply the downloaded manifest in the default namespace using <b>kubectl apply
    -f <downloaded file></b> ; Note that the agent should be able to reach the Load
    Balancer configured for the agent-grpc service,</li><li>Check the Setup->Agents
    screen for the agent connection status</li></ul></div>\",\n    \"AGENT_NAME\": {\n
    \     \"TOOLTIP\": \"Name of the agent with which it will referred to\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Agent Name cannot be empty\",\n        \"cannotContainSpace\":
    \"Agent Name cannot contain space\",\n        \"noSpecialCharacters\": \"Allowed
    special character is '-'\",\n        \"startingFromNumber\": \"Agent Name should
    not start with number\",\n        \"agentNameExist\": \"Agent Name already exists\"\n
    \     }\n    },\n    \"CLUSTER_NAME\": {\n      \"TOOLTIP\": \"Name of the remote
    cluster on which agent will be installed on\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Cluster Name cannot be empty\",\n        \"cannotContainSpace\":
    \"Cluster Name cannot contain space\",\n        \"noSpecialCharacters\": \"Allowed
    special character is '-'\",\n        \"startingFromNumber\": \"Cluster Name should
    not start with number\"\n      }\n    },\n    \"DESCRIPTION\": {\n      \"TOOLTIP\":
    \"Short description about the agent\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n
    \   \"CONNECT_TO_SPINNAKER\": {\n      \"TOOLTIP\": \"The spinnaker instance you
    want to associate this account to\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Please select Spinnaker\"\n      }\n    }\n  },\n  \"CLOUDPROVIDER_LISTING\":
    {\n  \"HEADER\": \"No Cloud Targets found!\",\n  \"BODY\": \"<div><p>Cloud Targets
    are integrations to Cloud platforms you deploy your applications to.</p> <p>In this
    section, youll register credentials for your Cloud platforms. Those credentials
    are known as Accounts. ISD allows you to create & manage Accounts for different
    Cloud Providers such as AWS, GCP, Kubernetes, etc.</p> <p>When CD instance (Spinnaker)
    is configured for <b>Direct Sync</b>, <b>New Accounts</b> button will not be visible.</p>
    <p><b>New Accounts</b> button will be enabled when CD instance (Spinnaker) is configured
    to use External Accounts in <b>Setup->CD Integration</b>.Click on <b>New Accounts</b>
    button to create an account for your cloud provider. You can create multiple accounts
    for the same provider.</p> <p>Click on <b>Sync Accounts</b> button to sync Cloud
    target accounts with CD Tool</p></div>\"\n  },\n    \"CLOUDPROVIDER_CREATION\":
    {\n      \"HEADER\": \"Cloud Target\",\n      \"BODY\": \"<div><p>Cloud Targets
    are integrations to cloud platforms you deploy your applications to. In this section,
    youll register credentials for your cloud platforms. Those credentials are known
    as accounts. ISD allows you to create & manage accounts for different cloud providers
    such as AWS, GCP, Kubernetes, etc.</p><p>You can create multiple accounts for the
    same provider.</p> <p>After saving this configuration, click on 'Sync Accounts'
    button to sync cloud target accounts with CD Tool.</p></div>\",\n      \"AGENT_NAME\":
    {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Agent name cannot be empty\",\n          \"cannotContainSpace\": \"Agent name
    cannot contain space\",\n          \"noSpecialCharacters\": \"Allowed special character
    are ',-'\"\n        }\n      },\n      \"CLOUD_PROVIDER\": {\n        \"TOOLTIP\":
    \"The Cloud Target type for which you want to add the account\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Please select Cloud Target\"\n        }\n      },\n
    \     \"SPINNAKER\": {\n        \"TOOLTIP\": \"The Spinnaker instance with which
    this account would be tied to\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Please select Spinnaker\"\n        }\n      },\n      \"ENVIRONMENT\": {\n        \"TOOLTIP\":
    \"The environment name for the account. Many accounts can share the same environment
    (e.g. dev, test, prod)\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Please select Environment\"\n        }\n      },\n      \"CUSTOM_ENVIRONMENT\":
    {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\": {\n          \"noSpecialCharacters\":
    \"Environment Name cannot contain special characters\",\n          \"cannotContainSpace\":
    \"Environment Name cannot contain space\",\n          \"required\": \"Environment
    Name cannot be empty\",\n          \"startingFromNumber\": \"Environment Name cannot
    start with number\",\n          \"maxlength\": \"Environment name should not have
    more than 63 characters!\",\n          \"exists\": \"Environment name already exists\"\n
    \       }\n      },\n      \"ACCOUNT_NAME\": {\n        \"TOOLTIP\": \"Name of the
    account to operate on\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Account name cannot be empty\",\n          \"cannotContainSpace\": \"Account name
    cannot contain space\",\n          \"noSpecialCharacters\": \"Allowed special character
    is '-'\",\n          \"startingFromNumber\": \"Account Name cannot start with numbers\"\n
    \       }\n      },\n      \"NAMESPACE\": {\n        \"TOOLTIP\": \"A list of namespaces
    this Spinnaker account can deploy to and will cache (namespaces should be 'coma'
    separated ex: default,dev\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Namespace cannot be empty\",\n          \"cannotContainSpace\": \"Namespace cannot
    contain space\",\n          \"noSpecialCharacters\": \"Special characters not allowed
    except ',-'\"\n        }\n      },\n      \"OMIT_NAMESPACE\": {\n        \"TOOLTIP\":
    \"A list of namespaces this Spinnaker account cannot deploy to or cache\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"\",\n          \"noSpecialCharacters\": \"Special characters
    not allowed except ',-'\"\n        }\n      },\n      \"UPLOAD_KUBECONFIG_FILE\":
    {\n        \"TOOLTIP\": \"The path to your kubeconfig file. By default, it will
    be under the Spinnaker users home directory in the typical .kube/config location.\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"File cannot be empty\"\n
    \       }\n      },\n      \"EXECUTE\": {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"cannotContainSpace\": \"Execute Permissions cannot contain space\"\n
    \       }\n      },\n      \"ACCOUNT_ID\": {\n        \"TOOLTIP\": \"Your AWS account
    ID to manage. Refer http://docs.aws.amazon.com/IAM/latest/UserGuide/console_account-alias.html
    for more information\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Account Id cannot be empty\",\n          \"cannotContainSpace\": \"Account Id
    cannot contain space\"\n        }\n      },\n      \"ROLE\": {\n        \"TOOLTIP\":
    \"If set, Halyard will configure a credentials provider that uses AWS Security Token
    Service to assume the specified role\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Role cannot be empty\",\n          \"cannotContainSpace\": \"Role cannot contain
    space\"\n        }\n      },\n      \"REGIONS\": {\n        \"TOOLTIP\": \"The AWS
    regions this Spinnaker account will manage\",\n        \"VALIDATION_MESSAGE\": {\n
    \         \"required\": \"Region cannot be empty\",\n          \"cannotContainSpace\":
    \"Region cannot contain space\"\n        }\n      },\n      \"PRIMARY_ACCOUNT\":
    {\n        \"TOOLTIP\": \"Whether this account is the primary account? If yes then
    provide the access & secret key details.\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"DYNAMIC_ACCOUNT\": {\n        \"TOOLTIP\": \"If Enabled, this
    account will be added to the spinnaker using External Account Configuration, which
    allows you to load the configurations dynamically without requiring redeployment
    of Clouddriver.\",\n        \"VALIDATION_MESSAGE\": {}\n        },         \n      \"ACCESS_KEY\":
    {\n        \"TOOLTIP\": \"The default access key used to communicate with AWS\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Access key cannot be
    empty\"\n        }\n      },\n      \"ACCESS_KEY_BAKERY\": {\n        \"TOOLTIP\":
    \"The default access key used for AWS bakery configuration\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Access Key (Bakery) cannot be empty\"\n        }\n
    \     },\n      \"SECRET_KEY\": {\n        \"TOOLTIP\": \"The secret key used to
    communicate with AWS\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Secret key cannot be empty\"\n        }\n      },\n      \"SECRET_KEY_BAKERY\":
    {\n        \"TOOLTIP\": \"The default secret key used for AWS baskery configuration\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Secret Key (Bakery)
    cannot be empty\"\n        }\n      },\n      \"APP_KEY\": {\n        \"TOOLTIP\":
    \"The App Key (password) of your service principal\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"App key cannot be empty\",\n          \"cannotContainSpace\":
    \"App key cannot contain space\"\n        }\n      },\n      \"CLIENT_ID\": {\n
    \       \"TOOLTIP\": \"The Client Id (also called appId) of your service principal\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Client Id cannot be
    empty\",\n          \"cannotContainSpace\": \"Client Id cannot contain space\"\n
    \       }\n      },\n      \"AZURE_REGIONS\": {\n        \"TOOLTIP\": \"The Azure
    regions this Spinnaker account will manage\",\n        \"VALIDATION_MESSAGE\": {\n
    \         \"required\": \"Region cannot be empty\",\n          \"cannotContainSpace\":
    \"Region cannot contain space\"\n        }\n      },\n      \"DEFAULT_KEYVALUT\":
    {\n        \"TOOLTIP\": \"The name of a Key Vault that contains the user name, password,
    and ssh public key used to create VMs\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Default Keyvault cannot be empty\",\n          \"cannotContainSpace\": \"Default
    Keyvault cannot contain space\"\n        }\n      },\n      \"SUBSCRIPTION_ID\":
    {\n        \"TOOLTIP\": \"The subscriptionId that your service principal is assigned
    to\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Subscription
    Id cannot be empty\",\n          \"cannotContainSpace\": \"Subscription Id cannot
    contain space\"\n        }\n      },\n      \"TENANT_ID\": {\n        \"TOOLTIP\":
    \"The tenantId that your service principal is assigned to\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Tenant Id cannot be empty\",\n          \"cannotContainSpace\":
    \"Tenant Id cannot contain space\"\n        }\n      },\n      \"DEFAULT_RESOURCE_GROUP\":
    {\n        \"TOOLTIP\": \"The default resource group to contain any non-application
    specific resources.\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Default Resouce Group cannot be empty\",\n          \"cannotContainSpace\": \"Default
    Resouce Group cannot contain space\"\n        }\n      },\n      \"OBJECT_ID\":
    {\n        \"TOOLTIP\": \"The objectId of your service principal. This is only required
    if using Packer to bake Windows images.\",\n        \"VALIDATION_MESSAGE\": {\n
    \         \"required\": \"Object Id cannot be empty\",\n          \"cannotContainSpace\":
    \"Object Id cannot contain space\"\n        }\n      },\n      \"PACKER_RESOURCE_GROUP\":
    {\n        \"TOOLTIP\": \"The resource group to use if baking images with Packer\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Packer Resouce Group
    cannot be empty\",\n          \"cannotContainSpace\": \"Packer Resouce Group cannot
    contain space\"\n        }\n      },\n      \"PACKER_STORAGE_ACCOUNT\": {\n        \"TOOLTIP\":
    \"The storage account to use if baking images with Packer.\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Packer Storage Account cannot be empty\",\n          \"cannotContainSpace\":
    \"Packer Storage Account cannot contain space\"\n        }\n      },\n      \"SSH_PUBLIC_KEY\":
    {\n        \"TOOLTIP\": \"Whether to use SSH public key to provision the linux vm.
    The default value is true which means using the ssh public key.\",\n        \"VALIDATION_MESSAGE\":
    {\n        }\n      },\n      \"GCP_FILE\": {\n        \"TOOLTIP\": \"Upload the
    kubeconfig file. By default, it will be under the users home directory in the typical
    .kube/config location\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"File cannot be empty\"\n        }\n      },\n      \"AWS_ACCOUNT_NAME\": {\n        \"TOOLTIP\":
    \"Please select a valid AWS account. Do note that the Amazon ECS account will use
    credentials from the corresponding AWS account. If you do not see a valid AWS account
    in the dropdown, please create one from Cloud targets -> New Account\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Please Select AWS Account\"\n        }\n      },\n
    \     \"PROJECT_NAME\": {\n        \"TOOLTIP\": \"Name of your Google Cloud project\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Project Name cannot
    be empty\"\n        }\n      }\n    },\n  \"SPINNAKER_LISTING\": {\n    \"HEADER\":
    \"No Spinnaker Configured!\",\n    \"BODY\": \"<div><p>CD Integration page allows
    you to connect to a CD instance. This enables ML based verification, Policy enforcement,
    Informed Approvals, etc.</p><p>Click on the <b>New CD Integration</b> button to
    connect to a CD instance. Only one instance is supported.</p></div>\"\n  },\n  \"SPINNAKER_SETUP\":
    {\n    \"HEADER\": \"Spinnaker\",\n    \"BODY\": \"<p>In this page you can add /
    update information about your CD instance.</p> <p><strong>Fields:</strong></p> <ul
    class='helpTextUI'> <li><strong>CD Name</strong>: User defined name for CD instance.<br><span>
    Example: opsmx-spinnaker</span></li> <li><strong>CD URL</strong>: Gate URL of the
    CD instance.<br> <span>Example: https://spinnaker-gate.xyz.com or http://oes-gate:8084</span></li>
    <li><strong>Authentication Type:</strong>: Can be LDAP or X509; for AD, use LDAP</li>
    <li><strong>Token: </strong> This is used when Authentication Type is LDAP; username
    & password to LDAP server separated by <b>:</b> in base64 format; Output of 'echo
    -ne 'username:password' | base64 -w0'</li> <li><strong>Password: </strong>This is
    used when Authentication Type is X509; Password for P12 File</li> <li><strong>P12
    File:</strong> This is used when Authentication Type is X509; P12 File needed for
    X509 Authentication</li></ul><p>GitOps style Spinnaker is suported where in all
    configuration is maintained in a repository such as git. These optional sections
    help configure gitOps style Spinnaker:</p><ul class='helpTextUI'><li><strong>Source
    Control for Accounts: </strong>You can specify the repository for External configuration
    in Spinnaker</li> <li><strong>Source Control for Pipeline: </strong>You can specify
    the repository for pipeline gitOps that allows you to save and restore pipelines
    from a git repository</li></ul>\",\n    \"ACCOUNT_CREATION_INFO\": \"The CD name
    should be the same as the Spinnaker name configured in echo-local.yml\",\n    \"ACCOUNT_CREATION_ADDITIONAL_INFO\":
    \"<p></p><p>Adding a Spinnaker instance with CD Name different than the Spinnaker
    name configured in <i>echo-local.yml</i> will require a manual update to the <i>echo-local.yml</i>
    and a <i>hal deploy apply</i>. This change is required to allow publishing Spinnaker
    events to RabbitMQ.</p>\",\n    \"SPINNAKER_NAME\": {\n      \"TOOLTIP\": \"Name
    of the Spinnaker instance\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"CD Name cannot be empty\",\n        \"cannotContainSpace\": \"CD Name cannot contain
    space\",\n        \"noSpecialCharacters\": \"Allowed special character is '-'\",\n
    \       \"startingFromNumber\": \"CD Name should not start with number\"\n      }\n
    \   },\n    \"SPINNAKER_GATE_URL\": {\n      \"TOOLTIP\": \"Gate Url of the Spinnaker
    instance\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"CD Gate URL
    cannot be empty\",\n        \"cannotContainSpace\": \"CD Gate URL cannot contain
    space\",\n        \"invalidUrl\": \"CD Gate URL is invalid\"\n      }\n    },\n
    \   \"AUTHENTICATION_TYPE\": {\n      \"TOOLTIP\": \"Select the type of authentication
    for the spinnaker being added\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Please select Authentication Type\"\n      }\n    },\n    \"LDAP_USERNAME\": {\n
    \     \"TOOLTIP\": \"User Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"User Name cannot be empty\",\n        \"minlength\": \"User Name should be more
    than 4 characters\"\n      }\n    },\n    \"LDAP_PASSWORD\": {\n      \"TOOLTIP\":
    \"Password\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Password
    cannot be empty\",\n        \"minlength\": \"Password should be more than 8 characters\"\n
    \     }\n    },\n    \"TOKEN\": {\n      \"TOOLTIP\": \"Token for Spinnaker authentication\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Token cannot be empty\",\n
    \       \"minlength\": \"Token should be more than 8 characters\"\n      }\n    },\n
    \   \"PASSWORD\": {\n      \"TOOLTIP\": \"Password\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Password cannot be empty\",\n        \"minlength\": \"Password
    should be more than 8 characters\"\n      }\n    },\n    \"P12_FILE\": {\n      \"TOOLTIP\":
    \"P12 File\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"P12 File
    cannot be empty\"\n      }\n    },\n    \"SYNC_ACCOUNTS\": {\n      \"TOOLTIP\":
    \"Select Mode of synchronisation of Cloud Targets between Autopilot & Spinnaker\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Sync Accounts
    type\"\n      }\n    },\n    \"ACCOUNTS_PROVIDER\": {\n      \"TOOLTIP\": \"Source
    Control for Halyard Configuration and / or External Account Configuration\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select provider\"\n      }\n    },\n    \"ACCOUNTS_ACCOUNT_NAME\":
    {\n      \"TOOLTIP\": \"Account name of the Source Control\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Account Name\"\n      }\n    },\n    \"ACCOUNTS_REPOSITORY\":
    {\n      \"TOOLTIP\": \"Repository name with full path in the selected Source Control
    Eg., https://github.com/OpsMx/Opsmx-Saas.git\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Repository cannot be empty\",\n        \"cannotContainSpace\":
    \"Repository cannot contain space\",\n        \"invalidUrl\": \"Repository is invalid\"\n
    \     }\n    },\n    \"ACCOUNTS_SOURCE_PATH\": {\n      \"TOOLTIP\": \"Existing
    path in the repository\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n    \"ACCOUNTS_REGION\":
    {\n      \"TOOLTIP\": \"The AWS regions this Spinnaker account will manage\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Region cannot be empty\",\n
    \       \"cannotContainSpace\": \"Region cannot contain space\",\n        \"startingFromNumber\":
    \"Region should not start with number\"\n      }\n    },\n    \"ACCOUNTS_BUCKET_NAME\":
    {\n      \"TOOLTIP\": \"Bucket Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Bucket Name cannot be empty\",\n        \"cannotContainSpace\": \"Bucket Name
    cannot contain space\",\n        \"startingFromNumber\": \"Bucket Name should not
    start with number\"\n      }\n    },\n    \"PIPELINE_PROVIDER\": {\n      \"TOOLTIP\":
    \"Use this Spinnaker for pipeline promotion.\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Please select provider\"\n      }\n    },\n    \"PIPELINE_ACCOUNT_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Please select Account Name\"\n      }\n    },\n    \"PIPELINE_REPOSITORY\": {\n
    \     \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Repository cannot be empty\",\n        \"cannotContainSpace\": \"Repository cannot
    contain space\",\n        \"invalidUrl\": \"Repository is invalid\"\n      }\n    },\n
    \   \"PIPELINE_SOURCE_PATH\": {\n      \"TOOLTIP\": \"Existing path in the repository\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"PIPELINE_REGION\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Region cannot be
    empty\",\n        \"cannotContainSpace\": \"Region cannot contain space\",\n        \"startingFromNumber\":
    \"Region should not start with number\"\n      }\n    },\n    \"PIPELINE_BUCKET_NAME\":
    {\n      \"TOOLTIP\": \"Bucket Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Bucket Name cannot be empty\",\n        \"cannotContainSpace\": \"Bucket Name
    cannot contain space\",\n        \"startingFromNumber\": \"Bucket Name should not
    start with number\"\n      }\n    }\n  },\n  \"INTEGRATOR_LISTING\": {\n    \"HEADER\":
    \"No Integrator found!\",\n    \"BODY\": \"<div><p>ISD offers integration with many
    CI/CD Tools. Integrations are grouped under the following categories - Artifact,
    CI, Governance, Monitoring Tools, Notifications, Policy and SAST/DAST.</p> <p>Integrations
    are used to</p> <ul><li>pull logs & metrics for Continuous Verification</li><li>pull
    meta data from CI/CD Tools for Informed Approvals</li><li>enforce organizational
    policies at the time of creation or execution of a pipeline</li><li>configure Artifacts,
    Cloud Providers etc.</li><p>Click on the <b<New Integration</b> button to start
    integrating your tools </p></div>\",\n    \"SYNC_SPINNAKER_ACCOUNTS\": {\n      \"TOOLTIP\":
    \"Push Integration changes to Spinnaker\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   }\n  },\n  \"PIPELINE_EXECUTION_AUDIT_LISTING\": {\n    \"HEADER\": \"Pipeline
    executions not found!\",\n    \"BODY\": \"<div>This page shows pipeline executions
    coming from a CD Tool such as Spinnaker in a list view. It also contains the summary
    view showing the total number of Pipeline Runs, Successful Runs, Failed Runs, Cancelled
    Runs.</p> <p> Only important fields including Application, Service, Pipeline, Status,
    Start Time and End Time are shown by default. Additional fields can be enabled using
    the Hamburger menu towards the right corner.</p></div>\",\n    \"TOOLTIP\": {\n
    \     \"EXECUTION_DATA\": \"Pipeline is in Running State\",\n      \"CONNECTOR_DATA\":
    \"Pipeline is in Running State\",\n      \"STAGE_DURATION\": \"Pipeline is in Running
    State\"\n    },\n    \"VALIDATION_MESSAGE\": {\n      \"STAGE_DURATION\": \"No Data
    available to view Stage Duration\",\n      \"PIPELINE_NOT_EXISTS\" : \"Execution
    details not found.\"\n    }\n  },\n  \"PIPELINE_AUDIT_LISTING\": {\n    \"HEADER\":
    \"Pipeline updates not found!\",\n    \"BODY\": \"<div>This page shows pipeline
    updates coming from a CD Tool such as Spinnaker in a list view.</div>\"\n  },\n
    \ \"POLICY_AUDIT_LISTING\": {\n    \"HEADER\": \"Policy updates / executions not
    found!\",\n    \"BODY\": \"<div><p>This page shows policy updates and policy executions,
    along with allowed/denied information, in a list view. Possible uses, apart from
    audit and compliance, includes helping users understand the policies that they might
    be inadvertently trying to break.</p><p>For policy updates, ensure that a policy
    is created/updated under <strong><a routerLink='/policymanagement'>Setup -> Policies</a></strong>.
    For policy execution events, please add a policy stage in a pipeline and execute
    it.</div>\"\n  },\n  \"USERS__AUDIT_LISTING\": {\n    \"HEADER\": \"User information
    not found!\",\n    \"BODY\": \"<div><p>This page displays user information, including
    their login details and current user status, which is determined based on their
    activities within the system over a specific time period.</p><ul class='helpTextUl'><li>ACTIVE
    - The user is currently logged in and has performed an action within the last 30
    minutes.</li><li>AWAY - The user is logged in and has not performed any actions
    within 30 minutes.</li><li>LOGGED OUT - The user has either been logged out or the
    session has timed out due to inactivity.</li><li>INACTIVE - The user hasnt logged
    in for 30 days.</li></ul></div>\"\n  },\n  \"POLICY_CREATION\": {\n    \"HEADER\":
    \"Policy\",\n    \"BODY\": \"<p>In this page, you can define & manage policies.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li> <strong>Name:</strong> User defined name for the policy</li><li><strong>Policy
    Type:</strong> Static Policy lets users validate the conditions when creating a
    pipeline, whereas Runtime Policy enables users for automated decision making during
    pipeline execution.</li><li> <strong>Policy Engine:</strong> Policy Engine to be
    used; currently, only OPA is supported</li> <li><strong>Policy Engine Account:</strong>
    Policy Engine Account for the Credentials. You can manage accounts from Setup ->
    Integrations -> Policy </li> <li><strong>Policy File:</strong> File containing the
    Policy You can upload the file by clicking on <strong>Choose File</strong> button.
    This is optional. If not present, you can enter the policy directly in the <strong>Policy
    Details</strong> field</li><li> <strong>Policy Details:</strong> Policy definition</li>
    <li><strong>Policy Permissions:</strong>Enable/disable access to the policy in Autopilot
    to specific usergroups</li></ul>\",\n    \"NAME\": {\n      \"TOOLTIP\": \"Policy
    Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Name cannot be
    empty\",\n        \"cannotContainSpace\": \"Name cannot contain space\",\n        \"exists\":
    \"Name already exists\",\n        \"enablerestriction\": \"Keywords 'allow' and
    'deny' cannot be used as policy name.\"\n      }\n    },\n    \"POLICY_DETAILS\":
    {\n      \"TOOLTIP\": \"Define your policy using the rego language\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Policy Details cannot be empty\"\n      }\n    },\n    \"POLICY_ENGINE\":
    {\n      \"TOOLTIP\": \"Supported Policy Account Types\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Policy Account Type\"\n      }\n    },\n
    \   \"POLICY_ENGINE_ACCOUNT\": {\n      \"TOOLTIP\": \"Policy Account Names\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Policy Engine
    Account\"\n      }\n    },\n    \"POLICY_TYPE\": {\n      \"TOOLTIP\": \"A static
    policy lets users validate conditions before the start of execution, whereas a Runtime
    policy enables users for automated decision making during execution.\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Policy Engine Type\"\n      }\n    },\n
    \   \"POLICY_DESCRIPTION\": {\n      \"TOOLTIP\": \"Optional Description for the
    policy\"\n    },\n    \"POLICY_FILE\": {\n      \"TOOLTIP\": \"File containing the
    Policy. You can upload the file by clicking on 'Choose File' button. This is optional.
    If not present, you can enter the policy directly in the 'Policy Details' field\"\n
    \   }\n  },\n  \"VERIFICATION\": {\n    \"HEADER\": \"Verification Gate executions
    not found!\",\n    \"BODY\": \"<div><p>This page shows Verification Gate executions
    in a list view.</p> <p>The Continuous Verification performs automated log and metrics
    analysis for new releases with built-in unsupervised and supervised machine learning
    algorithms for risk analysis and canary deployments.</p><p>Continuous Verification
    is a release verification process that provides Dev and Ops engineers an intelligent
    automated real-time actionable risk assessment of a new release deployed. The Continuous
    Verification verifies the latest version of the service comparing to the baseline
    or prior release after production rollout. The baseline can be a deployment done
    prior or the current deployment during rollout using canary or blue/green or rolling
    update strategies.</p> <p>It leverages unsupervised and supervised machine learning
    techniques to analyze 100s of metrics and logs data to perform in-depth analysis
    of architectural regressions, performance, scalability and security violations of
    new releases in a scalable way for enterprises.</p> <p>ISD provides a Verification
    Gate to analyze logs from your Target Application and this can be inserted as a
    Stage in your CI/CD Pipeline. Note that one must configure the metric and log datasources,
    such as Prometheus and Elastic before using this functionality.</p> <p>Insert Verification
    Gate to a pipeline in your application using <b>Pipeline Builder -> Add Stage</b>.
    When the pipeline is run, the Gate executions will start appearing in this page.</p></div>\",\n
    \   \"LOG_ANALYSIS\": {\n      \"BODY\": \"\",\n      \"SENSITIVITY\": {\n        \"TOOLTIP\":
    \"Impact of Unexpected Issues on the log scoring\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"PERCEIVED_RISK\": {\n        \"TOOLTIP\": \"The overall risk
    associated with changes made in this verification run\",\n        \"VALIDATION_MESSAGE\":
    {}\n      }\n    },\n    \"ANALYSIS_SUMMARY\": {\n      \"LOG_TEMPLATE\": {\n        \"TOOLTIP\":
    \"Log template for the verification run\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"METRIC_TEMPLATE\": {\n        \"TOOLTIP\": \"Metric template for
    the verification run\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"LOG_BASELINE_START_TIME\":
    {\n        \"TOOLTIP\": \"Start time of the canary analysis for Baseline\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"LOG_BASELINE_END_TIME\": {\n        \"TOOLTIP\": \"End  time
    of the canary analysis for Baseline\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"LOG_NEW_RELEASE_START_TIME\": {\n        \"TOOLTIP\": \"Start time of the
    canary analysis for New Release\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"LOG_NEW_RELEASE_END_TIME\": {\n        \"TOOLTIP\": \"End  time of the canary
    analysis for New Release\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"ANALYSIS_TYPE\":
    {\n        \"TOOLTIP\": \"The type of verification analysis done, can be metric,
    log or both metric and log analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"LOG_STATUS\": {\n        \"TOOLTIP\": \"The current status of the log analysis\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"LOG_SCORE\": {\n        \"TOOLTIP\":
    \"The overall score of the current log analysis report\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"METRIC_STATUS\": {\n        \"TOOLTIP\": \"The current status
    of the metric analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"METRIC_SCORE\":
    {\n        \"TOOLTIP\": \"The overall score of the current metric analysis report\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"BASELINE_SIZE\": {\n        \"TOOLTIP\":
    \"The size of the file with the Baseline logs\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"NEW_RELEASE_SIZE\": {\n        \"TOOLTIP\": \"The size of
    the file with the New Release logs\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"BASELINE_LINES\": {\n        \"TOOLTIP\": \"The number of log lines for
    the Baseline\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"NEW_RELEASE_LINES\":
    {\n        \"TOOLTIP\": \"The number of log lines for the New Release\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"ANALYSIS_DURATION\": {\n        \"TOOLTIP\": \"The time taken
    to perform the current verification run\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"LIFETIME_HOURS\": {\n        \"TOOLTIP\": \"The duration for which
    the canary analysis was performed, 1 lifetime hour is equal to 1 hour.\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"LIFETIME_MINUTES\": {\n        \"TOOLTIP\": \"Minutes to let
    the analysis run before making a final determination\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"RECLASSIFICATION_DURATION\": {\n        \"TOOLTIP\": \"The
    time taken to perform reclassification\",\n        \"VALIDATION_MESSAGE\": {}\n
    \     },\n      \"INTERVAL_MINUTES\": {\n        \"TOOLTIP\": \"The Lifetime hours
    in minutes\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"REGULAR_EXPRESSION\":
    {\n        \"TOOLTIP\": \"A sequence of characters to specify the search pattern\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"RESPONSE_KEY\": {\n        \"TOOLTIP\":
    \"Field name in the index where the regular expression is to be searched\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"SCORING_ALGORITHM\": {\n        \"TOOLTIP\": \"Scoring Algorithm
    for the risk analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"BASELINE_LOGS\":
    {\n        \"TOOLTIP\": \"View the Baseline logs\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"NEW_RELEASE_LOGS\": {\n        \"TOOLTIP\": \"View the New
    Release logs\",\n        \"VALIDATION_MESSAGE\": {}\n      }\n    },\n    \"METRIC_ANALYSIS\":
    {\n      \"BODY\": \"\"\n    },\n    \"CORRELATION\": {\n      \"BODY\": \"\"\n
    \   }\n  },\n  \"MANUAL_TRIGGER\": {\n    \"BODY\": \"<p>Continuous Verification
    is a REST service that can be deployed on premise or use managed cloud service for
    analysis. Continuous Verification interfaces with monitoring systems for logs and
    metrics and uses the metadata provided in start analysis phase to retrieve the logs
    and metrics for deployment verification. Continuous Verification does not interface
    with the services deployed directly for its analysis.            Deployment Pipeline
    can be based on Spinnaker or Jenkins for Enterprise Continuous Delivery. Verification
    can also be triggered manually by providing the required parameters in this dialog
    box.</p>\",\n    \"APPLICATION\": {\n      \"TOOLTIP\": \"Name of the application\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"BASELINE_START_TIME\": {\n      \"TOOLTIP\":
    \"Time to enable warming up of the container\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"NEW_RELEASE_START_TIME\": {\n      \"TOOLTIP\": \"Intervals in which
    metric-data is fetched and analysed\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"SUCCESSFUL_SCORE\": {\n      \"TOOLTIP\": \"The score under which the Analysis
    should fail\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"UNHEALTHY_SCORE\":
    {\n      \"TOOLTIP\": \"The score above which the Analysis should be a pass\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"ANALYSIS_LIFETIME\": {\n      \"TOOLTIP\":
    \"The time in hours for which the Canary Analysis should be run\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"RUN_INFO\": {\n      \"TOOLTIP\": {\n        \"Build Info\":
    \"http://jenkins.opsmx.net:8181/jenkins/job/Dev-visibilityservice-build-branch/770/\",\n
    \       \"Code Repository\": \"https://github.com/OpsMx/visibility-service\",\n
    \       \"Version\": \"v1.09\"\n      },\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"SERVICE\": {\n      \"TOOLTIP\": \"Service\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TEMPLATE_NAME\": {\n      \"TOOLTIP\": \"Template Name\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"GATE\": {\n      \"TOOLTIP\":
    \"Gate\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"FILTER_KEY\": {\n      \"TOOLTIP\":
    \"Filter Key\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"BASELINE\": {\n
    \     \"TOOLTIP\": \"Baseline\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"NEW_RELEASE\":
    {\n      \"TOOLTIP\": \"New Release\",\n      \"VALIDATION_MESSAGE\": \"\"\n    }\n
    \ },\n  \"TEST_VERIFICATON\": {\n    \"HEADER\": \"Test Verification Gate executions
    not found!\",\n    \"BODY\": \"<div> <p>The Continuous Verification performs automated
    log and metric analysis for new releases with built-in unsupervised and supervised
    machine learning algorithms for risk analysis. Autopilot provides a Test Verification
    Gate to analyse logs from your Test Harness and this can be inserted as a Stage
    in your CI/CD Pipeline. </p>     <p>This page shows Test Verification Gate executions
    in a list view. </p> <p>Insert Test Verification Gate to a pipeline in your application
    using <a [routerLink]='['/setup/applications']'><strong>Setup -> Applications</strong></a>.When
    the pipeline is run, the Gate executions will start appearing in this page.</p>
    </div>\"\n  },\n  \"TEST_CASE\": {\n    \"HEADER\": \"Test Cases not found!\",\n
    \   \"BODY\": \"<div> <p>The Continuous Verification performs automated log and
    metric analysis for new releases with built-in unsupervised and supervised machine
    learning algorithms for risk analysis. Autopilot provides a Test Verification Gate
    to analyse logs from your Test Harness and this can be inserted as a Stage in your
    CI/CD Pipeline. </p>     <p>This page shows Test Cases in a list view. </p> <p>Insert
    Test Verification Gate to a pipeline in your application using <a [routerLink]='['/setup/applications']'><strong>Setup
    -> Applications</strong></a>.When the pipeline is run, the Gate executions will
    start appearing in this page.</p> </div>\"\n  },\n  \"VISIBILITY_LISTING\": {\n
    \   \"HEADER\": \" <div><span style='font-size: 16px; font-weight: bold;'>Approval
    Gate executions not found!</span></div>\",\n    \"BODY\": \"<div><p>This page shows
    Approval Gate executions in a list view.</p> <p>ISD provides <b>approval</b> mechanism
    for deployments. To make an informed decision regarding pipeline execution, an approver
    may need to check the data from multiple data sources, such as CI Systems, Repositories,
    SAST/DAST Tools etc. ISD provides Approval Gate feature which fetches relevant information
    from multiple CI/CD Tools and presents the data in one place, to enable the user
    to make an quick and informed decision on pipeline execution. This Gate can be inserted
    as a Stage in your CI/CD Pipeline.</p> <p>Note that appropriate data sources must
    be configured in the <b>Setup -> Integration</b> view before Approval stage can
    be used.</p> <p>Insert Approval Gate to a pipeline in your application using <b>Pipeline
    Builder -> Add Stage</b>. When the pipeline is run, the Gate executions will start
    appearing in this page.</p></div>\"\n  },\n  \"VISIBILITY_DETAILS\": {\n    \"APPLICATION_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"SERVICE_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"APPROVAL_BTN_TITLE\":
    {\n      \"TOOLTIP\": \"Insufficient Permission to execute\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"GATE_NAME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"STATUS\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"COMMENT\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TRIGGER_URL\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"APPROVAL_GROUP\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"CONNECTORS\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"ACTIVATED_TIME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"REVIEWED_AT\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"REVIEWER\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"COMMENTS\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"FORM_GRID\": {\n    \"ADD_NEW_ROW\": {\n      \"TOOLTIP\":
    \"Add New Row\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DELETE_ROW\":
    {\n      \"TOOLTIP\": \"Delete row\",\n      \"VALIDATION_MESSAGE\": \"\"\n    }\n
    \ },\n  \"APPLICATION_DASHBOARD\": {\n    \"VERIFICATION_FAILURES\": {\n      \"TOOLTIP\":
    \"Total number of Verification Failures including Test Verification Failures\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    }\n  },\n  \"APPLICATION_LISTING\": {\n
    \   \"HEADER\": \"No applications were found to match your filter!\",\n    \"BODY\":
    \"\",\n    \"PLACEHOLDER\": \"You don't have access to this Page. Please contact
    your Administrator\",\n    \"SYNC_SPINNAKER\": {\n      \"TOOLTIP\": \"To be able
    to work on applications created in Spinnaker, you need to import them here\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"SYNC_SPINNAKER_NOT_CONFIGURED\":
    {\n      \"TOOLTIP\": \"Configure Spinnaker to Sync Spinnaker Applications from
    here\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"SYNC_SPINNAKER_ERROR\":
    {\n      \"TOOLTIP\": \"Could not fetch Spinnaker Details. Please contact Administrator\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DISABLE_CREATE_APPLICATION_BTN\":
    {\n      \"TOOLTIP\": \"You do not have permission to create Application\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"START_DEPLOYMENT\": {\n    \"APPLICATION_NAME\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Application Name
    is required\",\n        \"empty\": \"Please create Spinnaker Application to continue\"\n
    \     }\n    },\n    \"SERVICE_NAME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Service Name is required\",\n        \"empty\": \"Pipelines
    are not present for this Application\"\n      }\n    },\n    \"START_DEPLOYMENT_BTN\":
    {\n      \"TOOLTIP\": \"Please create Spinnaker Application to 'Start New Deployment'\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Service Name is required\"\n
    \     }\n    }\n  },\n  \"APPLICATION_DETAILS\": {\n    \"HEADER\": \"Application
    Details\",\n    \"BODY\": \"<ul class='helpTextUI'><li><strong>Application Name</strong>:
    User defined name of the application</li> <li><strong>Description</strong>: Application
    description</li> <li><strong>Email ID</strong>: Your email id</li></ul>\",\n    \"APPLICATION_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"exists\":
    \"Application already exists\",\n        \"noSpecialCharacters\": \"Application
    Name cannot contain special characters\",\n        \"cannotContainSpace\": \"Application
    Name cannot contain space\",\n        \"required\": \"Application Name cannot be
    empty\",\n        \"startingFromNumber\": \"Application Name cannot start with numbers\",\n
    \       \"maxlength\": \"Application name should not have more than 63 characters!\"\n
    \     }\n    },\n    \"APPLICATION_DESCRIPTION\": {\n      \"TOOLTIP\": \"\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"EMAIL_ID\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"email\": \"Email Id is invalid\",\n
    \       \"required\": \"Email Id cannot be empty\"\n      }\n    }\n  },\n  \"SERVICE_DETAILS\":
    {\n    \"HEADER\": \"Services\",\n    \"BODY\": \"<p>An Application can contain
    multiple services. A service can contain multiple pipelines. When a Service is created,
    a Pipeline with the same name is created automatically. You can add more pipelines
    by clicking on '+' symbol in <strong>Service Pipeline</strong></p>\",\n    \"SERVICE_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"exists\":
    \"Service already exists\",\n        \"noSpecialCharacters\": \"Service Name cannot
    contain special characters\",\n        \"cannotContainSpace\": \"Service Name cannot
    contain space\",\n        \"required\": \"Service Name cannot be empty\",\n        \"startingFromNumber\":
    \"Service Name cannot start with number\",\n        \"maxlength\": \"Service name
    should not have more than 63 characters!\"\n      }\n    },\n    \"SERVICE_PIPELINE\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"ADD_NEW_SERVICE\":
    {\n      \"TOOLTIP\": \"Add a new Service\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"SHOW_OR_HIDE_SERVICE\": {\n      \"TOOLTIP\": \"Show/Hide this service
    in the deployment dashboard\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DELETE_PIPELINE_ICON\":
    {\n      \"TOOLTIP\": \"Delete Pipeline from Service\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE_PERMISSION\": {\n      \"TOOLTIP\": \"Insufficient Permission
    to Delete this Service\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"DELETE_SERVICE\":
    {\n      \"TOOLTIP\": \"Service can be deleted on deleting pipelines\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"GROUP_PERMISSION\": {\n    \"APP_PERMISSIONS\": {\n      \"TOOLTIP\":
    \"Authorization definition for this Application\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"groupValid\": \"Groups cannot be empty\",\n        \"permissionsValid\":
    \"Atleast 1 permission should be assigned to the groups\",\n        \"allPermissionForOneGroup\":
    \"Atleast 1 group should have all permissions\"\n      }\n    },\n    \"INTEGRATORS_PERMISSIONS\":
    {\n      \"TOOLTIP\": \"Configure specific user groups access to this integration.\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"CLOUD_PROVIDER_PERMISSIONS\":
    {\n      \"TOOLTIP\": \"Authorization definition for this Cloud Targets\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"AGENT_PERMISSIONS\": {\n      \"TOOLTIP\": \"Authorization definition
    for this Agent\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"POLICY_PERMISSIONS\":
    {\n      \"TOOLTIP\": \"Authorization definition for this Policy\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"ADD_GROUP\": {\n      \"TOOLTIP\": \"Add New Group\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE\": {\n      \"TOOLTIP\": \"Delete\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    }\n  },\n  \"GATE_DETAILS\": {\n    \"HEADER\": \"Gate Configuration\",\n
    \   \"BODY\": \"<p>Select Gates from <strong>Existing Gates</strong> dropdown to
    load Gate Configuration and to add new Gate Configuration click the <strong>Add
    New Gate</strong> button</p> <p>Autopilot has the following Gate Types</p> <ul class='helpTextUI'>
    <li><strong>Approval</strong>: Fetches relevant information from multiple CI/CD
    Tools, presents the data in one place, to enable the user to make quick and informed
    decision on pipeline execution</li> <li><strong>Verification</strong>: Analyze logs
    & metrics from your target application to evaluate the risk in software delivery</li>
    <li><strong>Test Verification</strong>: Analyze logs from your Test Harness to evaluate
    the risk in software delivery</li>  <li><strong>Policy</strong>: Defines a set of
    conditions that need to be verified while creating or executing a CI/CD pipeline</li>
    </ul>\",\n    \"PIPELINE\": {\n      \"TOOLTIP\": \"Shows the structure of how the
    Gates are stacked in the Pipeline\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"TYPE\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"EXISITING_GATE\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"ENVIRONMENT\": {\n      \"TOOLTIP\": \"Specify Environment for
    this Gate\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Environment
    Name is Invalid\"\n      }\n    },\n    \"CUSTOM_ENVIRONMENT_NAME\": {\n      \"TOOLTIP\":
    \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"noSpecialCharacters\": \"Environment
    Name cannot contain special characters\",\n        \"cannotContainSpace\": \"Environment
    Name cannot contain space\",\n        \"required\": \"Environment Name cannot be
    empty\",\n        \"startingFromNumber\": \"Environment Name cannot start with number\",\n
    \       \"maxlength\": \"Environment name should not have more than 63 characters!\",\n
    \       \"exists\": \"Environment name already exists\"\n      }\n    },\n    \"GATE_NAME\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"exists\":
    \"Gate already exists\",\n        \"noSpecialCharacters\": \"Gate Name cannot contain
    special characters\",\n        \"cannotContainSpace\": \"Gate Name cannot contain
    space\",\n        \"required\": \"Gate Name cannot be empty\",\n        \"startingFromNumber\":
    \"Gate Name cannot start with number\",\n        \"maxlength\": \"Gate name should
    not have more than 63 characters!\"\n      }\n    },\n    \"DEPENDS_ON\": {\n      \"TOOLTIP\":
    \"This field determines the placement of the current Gate in the Pipeline. This
    field is not required if there are no Stages in the Pipeline\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Depends On cannot be empty\"\n      }\n    },\n    \"CONNECTOR\":
    {\n      \"TOOLTIP\": \"Tool to gather information for informed Approvals\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Connector\"\n      }\n    },\n    \"ACCOUNT\":
    {\n      \"TOOLTIP\": \"Account name of the connector\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Please select Account\"\n      }\n    },\n    \"TEMPLATE\":
    {\n      \"TOOLTIP\": \"Define the specific fields of interest from connector\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Template\"\n
    \     }\n    },\n    \"ADD_NEW_TEMPLATE\": {\n      \"TOOLTIP\": \"Add New Connector\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"EDIT_TEMPLATE\": {\n      \"TOOLTIP\":
    \"Edit Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"VIEW_TEMPLATE\":
    {\n      \"TOOLTIP\": \"View Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"DELETE_TEMPLATE\": {\n      \"TOOLTIP\": \"Delete Template\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TEMPLATE_TOOL_TYPE\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"TEMPLATE_NAME\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"noSpecialCharacters\": \"Template Name cannot contain special characters\",\n
    \       \"required\": \"Template Name cannot be empty\",\n        \"startingFromNumber\":
    \"Template Name cannot start with number\",\n        \"maxlength\": \"Template Name
    should not have more than 63 characters!\"\n      }\n    },\n    \"TEMPLATE_DESCRIPTION\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"AUTOMATED_APPROVAL\":
    {\n      \"TOOLTIP\": \"Use predefined conditions to Approve or Reject a request.
    You can configure conditions using Policies.\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Please select Approval Condition\"\n      }\n    },\n    \"APPROVAL_GROUPS\":
    {\n      \"TOOLTIP\": \"Selected groups will be able to review this Approval Gate\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Please select Approval
    Groups to continue\"\n      }\n    },\n    \"APPROVAL_GROUP_MSG\": {\n      \"TOOLTIP\":
    \"Selected groups should have atleast view access to the application\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"GATE_SECURITY_SOURCE_URL\": {\n      \"TOOLTIP\": \"Source Url\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"GATE_SECURITY_SOURCE_URL_COPY\":
    {\n      \"TOOLTIP\": \"Copy Source Url\",\n      \"VALIDATION_MESSAGE\": \"\"\n
    \   },\n    \"PAYLOAD_CONSTRAINTS\": {\n      \"TOOLTIP\": \"Payload Constraints
    for Gate Security\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"PAYLOAD_CONSTRAINTS_KEY\":
    {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\": {\n        \"cannotContainSpace\":
    \"Key cannot contain space\",\n        \"required\": \"Invalid Key\"\n      }\n
    \   },\n    \"LOG_TEMPLATE\": {\n      \"TOOLTIP\": \"A collection of all the information
    needed to run the log analysis\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"CREATE_GATE_CONFIG_TEMPLATE\": {\n      \"TOOLTIP\": \"Create New Template\",\n
    \     \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"EDIT_GATE_CONFIG_TEMPLATE\": {\n
    \     \"TOOLTIP\": \"Edit Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n
    \   \"VIEW_GATE_CONFIG_TEMPLATE\": {\n      \"TOOLTIP\": \"View Template\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE_GATE_CONFIG_TEMPLATE\": {\n      \"TOOLTIP\": \"Delete
    Template\",\n      \"VALIDATION_MESSAGE\": \"\"\n    },\n    \"METRIC_TEMPLATE\":
    {\n      \"TOOLTIP\": \"Information needed to run the metric analysis\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"POLICY\": {\n      \"TOOLTIP\": \"\",\n      \"VALIDATION_MESSAGE\":
    \"\"\n    },\n    \"DELETE_PERMISSION\": {\n      \"TOOLTIP\": \"Insufficient Permission
    to Delete this Gate\",\n      \"VALIDATION_MESSAGE\": \"\"\n    }\n  },\n  \"LOGGED_INUSER_DETAILS\":
    {\n    \"HEADER\": \"No Users found\",\n    \"BODY\": \"\"\n  },\n    \n  \"APPLICATION_DEPLOYMENT\":
    {\n    \"DEPLOYMENT_GRID_SYNC\": {\n      \"TOOLTIP\": \"When the cluster deployment
    matches with the latest pipeline execution it is 'In Sync'; if not, it is 'Out of
    Sync'\"\n    }\n  },\n\"INTEGRATION\": {\n\"AMAZONS3\":{\n  \"HEADER\": \"Amazon
    S3\",\n  \"BODY\":\"<span><p>Spinnaker can be configured to use AWS S3 bucket as
    Spinnaker's persistent storage or Artifact source</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name
    for your AWS S3 access. The account name appears in Spinnaker as an input source
    for artifact selection.<span class='noBr'></span></li><li><strong>Access Key Id</strong>:
    AWS IAM user access key who has access to the identified S3 bucket. Not required,
    If Spinnaker is running in EC2 or EKS with an associated IAM role. In that case,
    the IAM instance role is used for S3 connectivity.</li><li><strong>Secret Access
    Key</strong>: AWS IAM user Secret Key. Not required, If Spinnaker is running in
    EC2 or EKS with an associated IAM role. In that case, the IAM instance role is used
    for S3 connectivity.</li><li><strong>Region</strong>: AWS region where the AWS S3
    bucket is located</li><li><strong>API Endpoint</strong>: AWS S3 API endpoint, only
    required when using an S3 clone such as Minio</li><li><strong>API Region</strong>:
    AWS S3 API region, only required when using an S3 clone such as Minio</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your AWS S3
    access. The account name appears in Spinnaker as an input source for artifact selection.\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"ACCESS_ID\":{\n    \"TOOLTIP\":\"AWS IAM user's access key who has access
    to the identified S3 bucket. Not required, If Spinnaker is running in EC2 or EKS
    with an associated IAM role. In that case, the IAM instance role is used for S3
    connectivity.\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Access Key
    Id cannot be empty\"\n    }\n  },\n  \"SECRET_KEY\":{\n    \"TOOLTIP\":\"AWS IAM
    user Secret Key. Not required, If Spinnaker is running in EC2 or EKS with an associated
    IAM role. In that case, the IAM instance role is used for S3 connectivity.\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Secret Access Key cannot be empty\"\n
    \   }\n  },\n  \"REGION\":{\n    \"TOOLTIP\":\"AWS region where the AWS S3 bucket
    is located\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Region cannot
    be empty\"\n    }\n  },\n  \"APIENDPOINT\":{\n    \"TOOLTIP\":\"AWS S3 API endpoint,
    only required when using an S3 clone such as Minio\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"APIREGION\":{\n    \"TOOLTIP\":\"AWS S3 API region, only required
    when using an S3 clone such as Minio\",\n    \"VALIDATION_MESSAGE\":{\n    }\n  },\n
    \ \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to configure the
    resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"ARTIFACTORY\":{\n
    \ \"HEADER\": \"Artifactory\",\n  \"BODY\":\"<span><p>JFrog Artifactory integration
    can be used as an Artifact source in Spinnaker and also a Data source for Approval-Gate.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name
    for your Jfrog Artifactory access. The account name appears in Spinnaker as an Artifactory
    trigger type input.</li><li><strong>Endpoint</strong>: The base URL of your Artifactory
    search is reachable at. <span class='noBr'>(Example: https://xyz.my-jfrog.com)</span></li><li><strong>Repo</strong>:
    The Artifactory repo which needs to be searched</li><li><strong>Repo Type</strong>:
    The package type of repo in your Artifactory is to be searched. Default is Maven.</li><li><strong>Group
    Id</strong>: The group id in your Artifactory is to be searched</li><li><strong>Authentication
    Type </strong>: Select how the external resource confirms the user credentials</li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>Username</strong>:
    The Artifactory user's username for authentication</li><li><strong>Token</strong>:
    Artifactory personal access token. You can find <a href='https://www.jfrog.com/confluence/display/JFROG/Access+Tokens'
    target='_blank'>here</a> how to generate personal access tokens. <span class='autolinebreak'>(Example:
    ZlQDAwMFwvdXNlcnNcL21hZGh1a2FyIiwic2NwIjoiYXBwbGllZC1wZXJtaXNzaW9uc1wvYWRtaW4gYXBpOioiLCJhdWQiOlsiamZydEAqIiwiamZhY0AqIiwiamZldnmbWRAKiJdLCJpc3MiOiJqZmZlQDAAzNzY3MiwiaWF0IjoxNjI5ODY0ODcyLCJqdGkiOiI1ZWFiNjlhYi1hZDY0LTRjOGItOTMyZC0wMDAxMWZiZWU5YWIifQ.tzBgL3fQgZ1dwlLLS2UAT7G)</span></li><li><strong>Username
    & Password</strong>: Accepts the user's username and password to connect to Artifactory.</li><li><strong>Password</strong>:
    The Artifactory user's password for authentication</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your Jfrog
    Artifactory access. The account name appears in Spinnaker as an Artifactory trigger
    type input.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"ENDPOINT\":{\n    \"TOOLTIP\":\"The base URL of your Artifactory search
    is reachable at\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Endpoint
    cannot be empty\",\n      \"invalidUrl\": \"Endpoint URL is invalid\"\n    }\n  },\n
    \ \"REPO\":{\n    \"TOOLTIP\":\"The repo in your artifactory to be searched\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Repo cannot be empty\"\n    }\n
    \ },\n  \"REPOTYPE\":{\n    \"TOOLTIP\":\"The package type of repo in your Artifactory
    is to be searched. Default is Maven.\",\n    \"VALIDATION_MESSAGE\":{\n    }\n  },\n
    \ \"GROUPID\":{\n    \"TOOLTIP\":\"The group id in your Artifactory is to be searched.\",\n
    \   \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Authentication cannot be empty\"\n    }\n  },\n  \"TOKEN\":{\n
    \   \"TOOLTIP\":\"The Token of the artifactory user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Token cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The
    Artifactory user's username for authentication\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"User Name cannot be empty\"\n    }\n  },\n  \"PASSWORD\":{\n
    \   \"TOOLTIP\":\"The Artifactory user's password for authentication\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Password cannot be empty\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Toggle on to propagate the change into the CD Tool.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"BITBUCKET\":{\n
    \ \"HEADER\": \"Bitbucket Cloud\",\n  \"BODY\":\"<span><p>BitBucket Cloud integration
    can be used as a datasource for Approval Gate as well as to configure Spinnaker
    for BitBucket Cloud.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your BitBucket Cloud access. <span
    class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host URL</strong>:
    BitBucket Cloud (SaaS) Web URL. <span class='noBr'>It is usually https://bitbucket.org
    </span></li><li><strong>API URL</strong>: This is needed by Autopilot to access
    Bitbucket Cloud resources such as accounts & repositories through API calls <span
    class='noBr'>(Example: https://api.bitbucket.org/2.0/repositories)</span></li><li><strong>Authentication
    Type</strong>: Select one of the available options. If you are unsure, consult your
    BitBucket administrator to determine which authentication mechanism is used.</li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>User
    Name</strong>: The BitBucket Cloud Service username </li><li><strong>Token</strong>:
    The user's username and access token This token is obtained from the Bitbucket user
    profile page here. <span class='noBr'>(Example: xCPkVZfxaE9iULmfYYkK)</span></li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your BitBucket
    Cloud access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"BitBucket Cloud (SaaS) Web URL. It is usually
    https://bitbucket.org\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host
    URL cannot be empty\",\n      \"invalidUrl\": \"Host URL is invalid\"\n    }\n  },\n
    \ \"APIURL\":{\n    \"TOOLTIP\":\"Bitbucket API base URL. Eg. https://api.github.com\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"API URL cannot be empty\",\n
    \     \"invalidUrl\": \"API URL is invalid\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select one of the available options. If you are unsure, consult
    your BitBucket administrator to determine which authentication mechanism is used.\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"The user's
    access token. This token is obtained from the Bitbucket user profile page.\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot be empty\"\n    }\n
    \ },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The BitBucket Cloud Service username\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User Name cannot
    contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\":{\n    \"TOOLTIP\":\"The BitBucket Cloud Service password\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Password cannot be empty\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"VALIDATETOGGLE\":{\n
    \   \"TOOLTIP\":\"This button controls the validation of the configuration. If it
    is on, ISD will check the configuration for errors before saving it. If it is off,
    ISD will save the configuration as it is, without any validation. We recommend keeping
    the button on unless you are sure that the configuration is correct and does not
    need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"BITBUCKET_SERVER\":{\n
    \ \"HEADER\": \"Bitbucket Server\",\n  \"BODY\":\"<span><p>BitBucket Server integration
    can be used as a datasource for Approval Gate as well as to configure Spinnaker
    for BitBucket Server.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your BitBucket Cloud access. <span
    class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host URL</strong>:
    BitBucket Cloud (SaaS) Web URL. <span class='noBr'> It is usually https://bitbucket.org</span></li><li><strong>Authentication
    Type</strong>: Select one of the available options. If you are unsure, consult your
    BitBucket administrator to determine which authentication mechanism is used.</li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>User
    Name</strong>: Bitbucket Server User Name</li><li><strong>Token</strong>: The user's
    username and access token This token is obtained from the Bitbucket user profile
    page. You can find <a href='https://confluence.atlassian.com/bitbucketserver/personal-access-tokens-939515499.html'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    DjpMgHmwqUnIvvmljFgqGQ)</span></li><li><strong>Username & Password </strong>: Accepts
    the user's username and password to connect to Bitbucket. Deprecated and not recommended.</li><li><strong>Password</strong>:
    Bitbucket Server Password</li><li><strong>Permissions</strong>: Configure specific
    user groups access to this integration.</li></ul></span>\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"User-defined account name for your BitBucket Cloud access.\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"BitBucket Cloud (SaaS) Web URL. It is usually
    https://bitbucket.org\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host
    URL cannot be empty\",\n      \"invalidUrl\": \"Host URL is invalid\"\n    }\n  },\n
    \ \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select one of the available options.
    If you are unsure, consult your BitBucket administrator to determine which authentication
    mechanism is used.\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"The
    user's access token. This token is obtained from the Bitbucket user profile page.\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot be empty\"\n    }\n
    \ },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The BitBucket Server username\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n      \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \     \"required\":\"User Name cannot be empty\",\n      \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"The
    BitBucket server password\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password
    cannot be empty\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch
    On this toggle to configure the resource in a gitops enabled Spinnaker instance\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"DOCKERHUB\":{\n  \"HEADER\": \"Docker
    Registry\",\n  \"BODY\":\"<span><p><ul class='helpTextUl'><li><strong>Account Name</strong>:
    User-defined account name for your Docker registry access.</li><li><strong>Registry
    URL</strong>: The registry URL from which you want to pull and deploy images. <span
    class='noBr'> DockerHub example: https://hub.docker.com</span></li><li><strong>Email</strong>:
    Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io
    will be used.</li><li><strong>Repositories</strong>: An optional list of repositories
    to cache images from. If not provided, Spinnaker will try to read the list of accessible
    repositories from the registries _catalog endpoint. <span class='noBr'> Example:
    library/ubuntu (Public repositories are prefixed with library/)</span></li><li><strong>Group
    Membership</strong>: user must be a member of at least one specified group in order
    to make changes to this accounts cloud resources</li><li><strong>Authentication
    Type </strong>: Select an authentication type that corresponds to the connection
    credential parameter.</li><li><strong>Anonymous</strong>: No username or password
    is used. Access identity is anonymous.</li><li><strong>User Name</strong>: The username
    of the Docker Registry user to authenticate as</li><li><strong>Token</strong>: The
    token of the Docker Registry user to authenticate as</li><li><strong>Username &
    Password</strong>: Accepts the user's username and password to connect to Docker
    Registry.</li><li><strong>Password</strong>: The password of the Docker Registry
    user to authenticate as</li><li><strong>Validate</strong>: This button controls
    the validation of the configuration. If it is on, ISD will check the configuration
    for errors before saving it. If it is off, ISD will save the configuration as it
    is, without any validation. We recommend keeping the button on unless you are sure
    that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></p></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your Docker
    registry access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"URL\":{\n    \"TOOLTIP\":\"The registry URL from which you want to pull
    and deploy images. DockerHub example: https://hub.docker.com\",\n    \"VALIDATION_MESSAGE\":
    {\n  \"required\": \"Registry URL cannot be empty\"\n}\n  },\n\"EMAIL\":{\n  \"TOOLTIP\":\"Users
    docker registry email. If no value is specified, the default value of fake.email@spinnaker.io
    will be used.\"\n},\n\"REPOSITORIES\":{\n\"TOOLTIP\":\"An optional list of repositories
    to cache images from. If not provided, Spinnaker will try to read the list of accessible
    repositories from the registries _catalog endpoint. Example: library/ubuntu (Public
    repositories are prefixed with library/)\"\n},\n\"REQUIREDGROUPMEMBERSHIP\":{\n
    \ \"TOOLTIP\":\"user must be a member of at least one specified group in order to
    make changes to this accounts cloud resources\"\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select an authentication type that corresponds to the connection
    credential parameter.\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"The
    token of the Docker Registry user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Token cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The
    username of the Docker Registry user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n      \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \     \"required\":\"User Name cannot be empty\",\n      \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"The
    password of the Docker Registry user to authenticate as\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Password cannot be empty\"\n    }\n  },\n  \"HOSTURL\":{\n
    \   \"TOOLTIP\":\"Docker Registry Host URL\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host
    URL cannot be empty\",\n      \"invalidUrl\": \"Host URL is invalid\"\n    }\n  },\n
    \ \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Toggle on to propagate the change into
    the CD Tool.\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This
    button controls the validation of the configuration. If it is on, ISD will check
    the configuration for errors before saving it. If it is off, ISD will save the configuration
    as it is, without any validation. We recommend keeping the button on unless you
    are sure that the configuration is correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"OCR\":{\n  \"HEADER\": \"Generic Docker Registries (ACR, Quay, JFrog)\",\n
    \ \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined
    account name for your GCR Docker registry access.</li><li><strong>Registry URL</strong>:
    The registry URL from which you want to pull and deploy images. <span class='noBr'>
    For example: https://quay.io - RedHat quay.io</span></li><li><strong>Email</strong>:
    Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io
    will be used.</li><li><strong>Repositories</strong>: An optional list of repositories
    to cache images from. If not provided, Spinnaker will try to read the list of accessible
    repositories from the registries _catalog endpoint. <span class='noBr'> Example:
    library/ubuntu (Public repositories are prefixed with library/)</span></li><li><strong>Group
    Membership</strong>: A user must be a member of at least one specified group in
    order to make changes to this accounts cloud resources</li><li><strong>Authentication
    Type</strong>: Select an authentication type that corresponds to the connection
    credential parameter.</li><li><strong>Anonymous</strong>: No username or password
    is used. Access identity is anonymous.</li><li><strong>User Name</strong>: Your
    docker registry username</li><li><strong>Token</strong>: Your docker registry token</li><li><strong>Username
    & Password</strong>: Accepts the user's username and password to connect to Generic
    Docker Registries (ACR, Quay, JFrog).</li><li><strong>Password</strong>: Your docker
    registry password</li><li><strong>Validate</strong>: This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.</li><li><strong>Connect to CD</strong>: Toggle
    on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your GCR Docker
    registry access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"REPOSITORIES\":{\n    \"TOOLTIP\":\"An optional list of repositories to
    cache images from. If not provided, Spinnaker will try to read the list of accessible
    repositories from the registries _catalog endpoint. Example: library/ubuntu (Public
    repositories are prefixed with library/)\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\",\n      \"startingFromNumber\": \"Repository cannot start
    with numbers\"\n    }\n  },\n  \"URL\":{\n    \"TOOLTIP\":\"The registry URL from
    which you want to pull and deploy images. For example: https://quay.io - RedHat
    quay.io\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Registry URL cannot
    be empty\"\n    }\n  },\n  \"EMAIL\":{\n    \"TOOLTIP\":\"Users docker registry
    email. If no value is specified, the default value of fake.email@spinnaker.io will
    be used.\"\n  },\n  \"REQUIREDGROUPMEMBERSHIP\":{\n    \"TOOLTIP\":\"A user must
    be a member of at least one specified group in order to make changes to this accounts
    cloud resources\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select
    an authentication type that corresponds to the connection credential parameter.\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"Your docker
    registry token\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot
    be empty\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"Your docker registry
    password\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password cannot
    be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"Your docker registry
    username\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"HOSTURL\":{\n    \"TOOLTIP\":\"Container Registry Host URL\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Host URL cannot be empty\",\n      \"invalidUrl\": \"Host URL
    is invalid\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Toggle on
    to propagate the change into the CD Tool.\"\n  },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This
    button controls the validation of the configuration. If it is on, ISD will check
    the configuration for errors before saving it. If it is off, ISD will save the configuration
    as it is, without any validation. We recommend keeping the button on unless you
    are sure that the configuration is correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"GITHUB\":{\n  \"HEADER\": \"GitHub\",\n  \"BODY\":\"<span><p>GITHUB integration
    can be used as a datasource for Approval Gate as well as to configure Spinnaker
    for GitHub.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your GitHub access.<span class='noBr'>(Example:
    opsmx-github)</span></li><li><strong>Host URL</strong>: Github's host address, such
    as https://github.com</li><li><strong>API URL</strong>: Github's API endpoint host
    address, <span class='noBr'>such as https://api.github.com</span></li><li><strong>Token</strong>:
    GitHub personal access token. You can find <a href='https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token'
    target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example:
    ghp_ln1eJK4yuomnY6JREp72IDJC4Hq6Sm)</span></li><li><strong>User Name</strong>: The
    GitHub username</li><li><strong>Validate</strong>: This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.</li><li><strong>Connect to CD</strong>: Toggle
    to configure Spinnaker for GitHub</li><li><strong>Permissions</strong>: Configure
    specific user groups access to this integration.</li></ul></span>\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"User-defined account name for your GitHub access.\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"Github's
    host address, such as https://github.com\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host
    URL cannot be empty\",\n      \"invalidUrl\": \"Host URL is invalid\"\n    }\n  },\n
    \ \"URL\":{\n    \"TOOLTIP\":\"Github's API endpoint host address, such as https://api.github.com\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"API URL cannot be empty\",\n
    \     \"invalidUrl\": \"API URL is invalid\"\n    }\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"The
    user's token\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot
    be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"The GitHub username\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User Name cannot
    contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to configure the
    resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"GITLAB\":{\n
    \ \"HEADER\": \"GitLab\",\n  \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your GitLab access.</li><li><strong>Host
    URL</strong>: GitLab's host address, such as https://gitlab.com</li><li><strong>Authentication
    Type</strong>: Select how the external resource confirms the user credentials</li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>Token</strong>:
    The user's personal access token. Please refer <a href='https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html'
    target='_blank'>this document</a> for generating tokens.</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance</li><li><strong>Permissions</strong>: Configure specific user
    groups access to this integration.</li></ul></span>\",\n  \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined
    account name for your GitLab access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"HOSTURL\":{\n    \"TOOLTIP\":\"GitLab's host address, such as https://gitlab.com\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Host URL cannot be empty\",\n
    \     \"invalidUrl\": \"Host URL is invalid\"\n    }\n  },\n  \"APIBASEURL\":{\n
    \   \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"API URL
    cannot be empty\",\n      \"invalidUrl\": \"API URL is invalid\"\n    }\n  },\n
    \ \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the external resource confirms
    the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"GitLab
    token\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token cannot be empty\"\n
    \   }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to
    configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"GITREPO\":{\n
    \ \"HEADER\": \"Git Repo\",\n  \"BODY\": \"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your Git Repo access.</li><li><strong>API
    URL</strong>: The API URL of the Git repository URL.<p><strong>Examples</strong>:</p><ul
    class='helpTextUl'><li>https://api.github.com</li><li>https://api.bitbucket.org/2.0/respositories</li><li>https://gitlab.com/api/v4/</li></ul></li><li><strong>Authentication
    Type</strong>: Select an authentication type that corresponds to the connection
    credential parameter. Recommended using the user token method.</li><li><strong>User
    Name</strong>:Git username</li><li><strong>Token</strong>: Git token</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance</li><li><strong>Permissions</strong>: Configure specific user
    groups access to this integration.</li></ul></span>\",\n  \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined
    account name for your Git Repo access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"APIURL\":{\n    \"TOOLTIP\":\"<div><div>The API URL of the Git repository
    URL.</div><strong>Examples</strong>:<ul><li>https://api.github.com</li><li>https://api.bitbucket.org/2.0/respositories</li><li>https://gitlab.com/api/v4/</li></ul></div>\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"API URL cannot be empty\",\n
    \     \"invalidUrl\": \"API URL is invalid\"\n    }\n  },\n  \"DEPLOYMENT\":{\n
    \   \"TOOLTIP\":\"This Halyard deployment will be used for Account creation / update\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"deployment URL cannot be empty\",\n
    \     \"invalidUrl\": \"deployment URL is invalid\"\n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n
    \   \"TOOLTIP\":\"Select an authentication type that corresponds to the connection
    credential parameter. Recommended using the user token method.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"URL\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"API
    URL cannot be empty\",\n      \"invalidUrl\": \"API URL is invalid\"\n    }\n  },\n
    \ \"TOKEN\":{\n    \"TOOLTIP\":\"Git token\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"PASSWORD\":{\n    \"TOOLTIP\":\"Git password\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Password cannot be empty\"\n
    \   }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"Git username\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n      \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \     \"required\":\"User Name cannot be empty\",\n      \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"VALIDATETOGGLE\":{\n
    \   \"TOOLTIP\":\"This button controls the validation of the configuration. If it
    is on, ISD will check the configuration for errors before saving it. If it is off,
    ISD will save the configuration as it is, without any validation. We recommend keeping
    the button on unless you are sure that the configuration is correct and does not
    need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"HELM\":{\n  \"HEADER\":
    \"Helm\",\n  \"BODY\": \"<span><ul class='helpTextUl'><li><strong>Account Name</strong>:
    User-defined account name for target Helm repository access.</li><li><strong>Repository</strong>:
    Helm Chart Repositorys HTTP endpoint.</li><li><strong>Authentication Type</strong>:
    Select an authentication type that corresponds to the connection credential parameter.</li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>User
    Name</strong>: User Name</li><li><strong>Password</strong>: Password</li><li><strong>Username
    & Password</strong>: Accepts the user's username and password to connect to Helm.</li><li><strong>Password
    File</strong>: The path to a file containing your docker password in plaintext (not
    a docker/config.json file)</li><li><strong>Validate</strong>: This button controls
    the validation of the configuration. If it is on, ISD will check the configuration
    for errors before saving it. If it is off, ISD will save the configuration as it
    is, without any validation. We recommend keeping the button on unless you are sure
    that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle ON to propagate the change to Spinnaker Toggle on to propagate
    the change into the CD Tool.</li><li><strong>Permissions</strong>: Configure specific
    user groups access to this integration.</li</ul></span>\",\n  \"ACCOUNTNAME\":{\n
    \   \"TOOLTIP\":\"User-defined account name for target Helm repository access\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"REPOSITORY\":{\n    \"TOOLTIP\":\"Helm Chart Repositorys HTTP endpoint\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\":\"Repository cannot be empty\",\n
    \     \"invalidUrl\": \"Repository URL is invalid\"\n    }\n  },\n  \"DEPLOYMENT\":{\n
    \   \"TOOLTIP\":\"This Halyard deployment will be used for Account creation / update\",\n
    \   \"VALIDATION_MESSAGE\":{\n    \n    }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select
    an authentication type that corresponds to the connection credential parameter.\",\n
    \   \"VALIDATION_MESSAGE\":{}\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Token cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"User
    Name\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User Name
    cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Password\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\" : \"Password cannot be empty\"\n    }\n  },\n  \"PASSWORDCOMMAND\":
    {\n    \"TOOLTIP\": \"Command to retrieve docker token/password, commands must be
    available in environment\",\n    \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"FILE\":
    {\n    \"TOOLTIP\": \"The path to a file containing your docker password in plaintext
    (not a docker/config.json file)\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n
    \ \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Toggle on to propagate the change into
    the CD Tool.\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This
    button controls the validation of the configuration. If it is on, ISD will check
    the configuration for errors before saving it. If it is off, ISD will save the configuration
    as it is, without any validation. We recommend keeping the button on unless you
    are sure that the configuration is correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"HTTP\":{\n  \"HEADER\": \"Http\",\n  \"BODY\": \"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for HTTP protocol-based artifacts</li><li><strong>Authentication
    Type</strong>: Select an authentication type that corresponds to the connection
    credential parameter.</li><li><strong>Anonymous</strong>: No username or password
    is used. Access identity is anonymous.</li><li><strong>User Name</strong>: HTTP
    basic auth User Name</li><li><strong>Password</strong>: Password</li><li><strong>Username
    & Password</strong>: Accepts the user's username and password to connect to Http.</li><li><strong>Password
    File</strong>: The path to a file containing your docker password in plaintext (not
    a docker/config.json file)</li><li><strong>Validate</strong>: This button controls
    the validation of the configuration. If it is on, ISD will check the configuration
    for errors before saving it. If it is off, ISD will save the configuration as it
    is, without any validation. We recommend keeping the button on unless you are sure
    that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for HTTP protocol-based
    artifacts\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select an authentication type
    that corresponds to the connection credential parameter.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"HTTP basic auth
    User Name\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Password\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\" : \"Password cannot be empty\"\n    }\n  },\n  \"PASSWORDCOMMAND\":
    {\n    \"TOOLTIP\": \"Command to retrieve docker token/password, commands must be
    available in environment\",\n    \"VALIDATION_MESSAGE\":{\n    }\n  },\n  \"FILE\":
    {\n    \"TOOLTIP\": \"The path to a file containing your docker password in plaintext
    (not a docker/config.json file)\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n
    \ \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Toggle on to propagate the change into
    the CD Tool.\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This
    button controls the validation of the configuration. If it is on, ISD will check
    the configuration for errors before saving it. If it is off, ISD will save the configuration
    as it is, without any validation. We recommend keeping the button on unless you
    are sure that the configuration is correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"GCS\":{\n  \"HEADER\": \"GCS\",\n  \"BODY\": \"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your Google Cloud Storage access.</li><li><strong>Authentication
    Type</strong>: Select an authentication type that corresponds to the connection
    credential parameter. </li><li><strong>Anonymous</strong>: No username or password
    is used. Access identity is anonymous.</li><li><strong>Json key file (File)</strong>:
    Configures Google service accounts json file </li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool. </li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your Google
    Cloud Storage access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select an authentication type
    that corresponds to the connection credential parameter.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"FILE\": {\n    \"TOOLTIP\": \"Configures Google service accounts json
    file\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Toggle
    on to propagate the change into the CD Tool.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"ECR\":{\n
    \ \"HEADER\": \"ECR\",\n  \"BODY\": \"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your ECR Docker registry access.</li><li><strong>Registry
    URL</strong>: The registry URL from which you want to pull and deploy images. <span
    class='noBr'> For example:https://aws_account_id.dkr.ecr.region.amazonaws.com</span></li><li><strong>Repositories</strong>:
    An optional list of repositories to cache images from. If not provided, Spinnaker
    will try to read the list of accessible repositories from the registries _catalog
    endpoint. <span class='noBr'> Example: library/ubuntu (Public repositories are prefixed
    with library/)</span></li><li><strong>Email</strong>: Users docker registry email.
    If no value is specified, the default value of fake.email@spinnaker.io will be used.</li><li><strong>Group
    Membership</strong>: A user must be a member of at least one specified group in
    order to make changes to this accounts cloud resources</li><li><strong>Authentication
    Type</strong>: Select an authentication type that corresponds to the connection
    credential parameter.</li><li><strong>Anonymous</strong>: No username or password
    is used. Access identity is anonymous.</li><li><strong>User Name</strong>: Your
    docker registry username</li><li><strong>Password-command</strong>: Command to retrieve
    docker token/password, commands must be available in environment</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your ECR Docker
    registry access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"REPOSITORIES\":{\n    \"TOOLTIP\":\"Users docker registry email. If no
    value is specified, the default value of fake.email@spinnaker.io will be used.\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository cannot contain
    space\",\n      \"startingFromNumber\": \"Repository cannot start with numbers\"\n
    \   }\n  },\n  \"URL\":{\n    \"TOOLTIP\":\"The registry URL from which you want
    to pull and deploy images. For example:https://aws_account_id.dkr.ecr.region.amazonaws.com\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"required\" : \"Registry URL cannot be empty\"\n
    \   }\n  },\n  \"GROUPMEMBERSHIP\":{\n    \"TOOLTIP\":\"A user must be a member
    of at least one specified group in order to make changes to this accounts cloud
    resources\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\"\n    }\n  },\n  \"REGION\": {\n    \"TOOLTIP\": \"AWS region\"\n
    \ },\n  \"EMAIL\":{\n    \"TOOLTIP\":\"An optional list of repositories to cache
    images from. If not provided, Spinnaker will try to read the list of accessible
    repositories from the registries _catalog endpoint. Example: library/ubuntu (Public
    repositories are prefixed with library/)\",\n    \"VALIDATION_MESSAGE\":{\n      \"email\":\"Email
    Id is invalid\",\n      \"required\":\"Email Id cannot be empty\"\n    }\n  },\n
    \ \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select an authentication type that
    corresponds to the connection credential parameter.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"Your docker
    registry username\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Your docker registry password\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"PASSWORDCOMMAND\": {\n    \"TOOLTIP\": \"Command to retrieve docker
    token/password, commands must be available in environment\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\" : \"Password-command cannot be empty\"\n    }\n  },\n  \"FILE\":
    {\n    \"TOOLTIP\": \"The path to a file containing your docker password in plaintext
    (not a docker/config.json file)\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n
    \ \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Toggle on to propagate the change into
    the CD Tool.\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This
    button controls the validation of the configuration. If it is on, ISD will check
    the configuration for errors before saving it. If it is off, ISD will save the configuration
    as it is, without any validation. We recommend keeping the button on unless you
    are sure that the configuration is correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ }\n},\n\"PUBSUB\":{\n  \"HEADER\": \"PUBSUB\",\n  \"BODY\": \"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your Google Cloud Pub/Sub access.</li><li><strong>Project
    Name</strong>: The name of the GCP project your subscription lives in</li><li><strong>Subscription
    Name</strong>: The name of the subscription to listen to and it should have PubsSub
    Viewer and PubSub Subscriber Roles as mandatory. This identifier does not include
    the name of the project, and must already be configured for Spinnaker to work.</li><li><strong>Message
    Format</strong>: Supporting Message Formats: GCB,GCS,GCR,CUSTOM</li><li><strong>Authentication
    Type</strong>: Select how the external resource confirms the user credentials</li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>Translation
    Template</strong>: To translate the Pub/Sub payload into a Spinnaker artifact, you
    need to create a Jinja template that defines how to transform the payload data.
    The Jinja template should produce a JSON list of Spinnaker artifacts as its output.
    You can use any valid Jinja syntax in your template. Example : https://spinnaker.io/docs/guides/user/pipeline/triggers/pubsub/#example</li><li><strong>Json
    key file (File)</strong>: Configures Google service accounts json file</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance</li><li><strong>Permissions</strong>: Configure specific user
    groups access to this integration.</li></ul></span>\",\n  \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined
    account name for your Google Cloud Pub/Sub access.\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n  },\n  \"PROJECTNAME\": {\n
    \   \"TOOLTIP\": \"The name of the GCP project your subscription lives in\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"cannotContainSpace\":\"Project Name cannot contain space\",\n      \"required\":\"Project
    Name cannot be empty\"\n    }\n  },\n  \"SUBSCRIPTIONNAME\": {\n    \"TOOLTIP\":
    \"The name of the subscription to listen to and it should have PubsSub Viewer and
    PubSub Subscriber Roles as mandatory. This identifier does not include the name
    of the project, and must already be configured for Spinnaker to work.\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"cannotContainSpace\":\"Subscription Name cannot contain space\",\n      \"required\":\"Subscription
    Name cannot be empty\"\n    }\n  },\n  \"MESSAGEFORMAT\": {\n    \"TOOLTIP\":\"Supporting
    Message Formats: GCB,GCS,GCR,CUSTOM\",\n    \"VALIDATION_MESSAGE\": {}\n  },\n  \"TEMPLATEFILE\":
    {\n    \"TOOLTIP\": \"To translate the Pub/Sub payload into a Spinnaker artifact,
    you need to create a Jinja template that defines how to transform the payload data.
    The Jinja template should produce a JSON list of Spinnaker artifacts as its output.
    You can use any valid Jinja syntax in your template. Example : https://spinnaker.io/docs/guides/user/pipeline/triggers/pubsub/#example\",\n
    \   \"VALIDATION_MESSAGE\": {}\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select
    how the external resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"FILE\": {\n    \"TOOLTIP\": \"JSON service account that Spinnaker will
    use as credentials\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n  \"VALIDATETOGGLE\":{\n
    \   \"TOOLTIP\":\"This button controls the validation of the configuration. If it
    is on, ISD will check the configuration for errors before saving it. If it is off,
    ISD will save the configuration as it is, without any validation. We recommend keeping
    the button on unless you are sure that the configuration is correct and does not
    need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"GCB\":{\n  \"HEADER\":
    \"GCB\",\n  \"BODY\": \"<div><p>This page allows you to connect Google Cloud Build
    with ISD. Google cloud build can be used as an automated trigger as well as a stage
    in the pipeline.</p><p>To configure a pipeline to be triggered by a completed GCB
    build, after this integration is succefully created, go to your application's pipeline
    menu. Click on the configuration stage of a pipeline, then select Pub/Sub as the
    automated trigger. Select Pub/Sub System type as Google and select your subscribtion
    name.</p><p>To run GCB Build as part of a pipeline, create a stage of type Google
    Cloud Build, select your GCB Account and configure the build definition.In the Produces
    Artifacts section, you may supply any artifacts that you expect the build to create
    in order to make these artifacts available to downstream stages</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: The user defined name of this
    account.<span></span></li><li><strong>Project Name</strong>: <span>The name of the
    GCP project in which to trigger and monitor builds</span></li><li><strong>Subscription
    Name</strong>: <span> The name of the PubSub subscription on which to listen for
    build changes</span></li><li><strong>Authentication Type</strong>: <span>Select
    how the external resource confirms the user credentials</span></li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>Json
    key file (File) </strong>: <span>JSON service account that Spinnaker will use as
    credentials</span></li><li><strong>Validate</strong>: This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.</li><li><strong>Connect to CD</strong>: <span>Switch
    On this toggle to configure the resource in a gitops enabled CD tool</span></li><li><strong>Permissions</strong>:
    <span>Configure specific user groups access to this integration.</span></li></ul></div>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"The name of the account to operate on\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name cannot
    contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"PROJECTNAME\": {\n    \"TOOLTIP\": \"The name of the GCP project in which
    to trigger and monitor builds\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Project
    Name cannot contain space\",\n      \"required\":\"Project Name cannot be empty\"\n
    \   }\n  },\n  \"SUBSCRIPTIONNAME\": {\n    \"TOOLTIP\": \"The name of the PubSub
    subscription on which to listen for build changes and it should have PubsSub Viewer
    and PubSub Subscriber Roles as mandatory.\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Subscription
    Name cannot contain space\",\n      \"required\":\"Subscription Name cannot be empty\"\n
    \   }\n  },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select how the external
    resource confirms the user credentials\",\n    \"VALIDATION_MESSAGE\":{}\n  },\n
    \ \"FILE\": {\n    \"TOOLTIP\": \"JSON service account that Spinnaker will use as
    credentials\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"GCB
    User Name\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Password\",\n    \"VALIDATION_MESSAGE\":{\n
    \   }\n  },\n  \"SPINNAKERTOGGLE\":{\n    \"TOOLTIP\":\"Switch On this toggle to
    configure the resource in a gitops enabled Spinnaker instance\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"GCR\":{\n
    \ \"HEADER\": \"GCR\",\n  \"BODY\": \"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your GCR Docker registry access.</li><li><strong>Registry
    URL</strong>: The registry URL from which you want to pull and deploy images. <span
    class='noBr'> For example: https://gcr.io - Global GCR, https://[us|eu|asia].gcr.io
    - Regional GCR</span></li><li><strong>Email</strong>: Users docker registry email.
    If no value is specified, the default value of fake.email@spinnaker.io will be used.</li><li><strong>Repositories</strong>:
    An optional list of repositories to cache images from. If not provided, Spinnaker
    will try to read the list of accessible repositories from the registries _catalog
    endpoint. <span class='noBr'> Example: library/ubuntu (Public repositories are prefixed
    with library/)</span></li><li><strong>Group Membership</strong>: A user must be
    a member of at least one specified group in order to make changes to this accounts
    cloud resources</li><li><strong>Authentication Type</strong>: Select an authentication
    type that corresponds to the connection credential parameter.</li><li><strong>Anonymous</strong>:
    No username or password is used. Access identity is anonymous.</li><li><strong>User
    Name</strong>: GCR User Name</li><li><strong>Token</strong>: Your Google container
    registry authentication token</li><li><strong>Username & Password</strong>: Accepts
    the user's username and password to connect to GCR.</li><li><strong>Password</strong>:
    Your docker registry password</li><li><strong>Password File</strong>: The path to
    a file containing your docker password in plaintext (not a docker/config.json file)</li><li><strong>Password-command</strong>:
    Command to retrieve docker token/password, commands must be available in environment</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \ \"ACCOUNTNAME\":{\n    \"TOOLTIP\":\"User-defined account name for your GCR Docker
    registry access.\",\n    \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \ },\n  \"AUTHENTICATIONTYPE\":{\n    \"TOOLTIP\":\"Select an authentication type
    that corresponds to the connection credential parameter.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"REPOSITORIES\":{\n    \"TOOLTIP\":\"An optional list of repositories to
    cache images from. If not provided, Spinnaker will try to read the list of accessible
    repositories from the registries _catalog endpoint. Example: library/ubuntu (Public
    repositories are prefixed with library/)\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\",\n      \"startingFromNumber\": \"Repository cannot start
    with numbers\"\n    }\n  },\n  \"REQUIREDGROUPMEMBERSHIP\":{\n    \"TOOLTIP\":\"A
    user must be a member of at least one specified group in order to make changes to
    this accounts cloud resources\",\n    \"VALIDATION_MESSAGE\":{\n      \"cannotContainSpace\":\"Repository
    cannot contain space\"\n    }\n  },\n  \"EMAIL\":{\n    \"TOOLTIP\":\"Users docker
    registry email. If no value is specified, the default value of fake.email@spinnaker.io
    will be used.\",\n    \"VALIDATION_MESSAGE\":{\n      \"email\":\"Email Id is invalid\",\n
    \     \"required\":\"Email Id cannot be empty\"\n    }\n  },\n  \"URL\":{\n    \"TOOLTIP\":\"The
    registry URL from which you want to pull and deploy images. For example: https://gcr.io
    - Global GCR, https://[us|eu|asia].gcr.io - Regional GCR\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\":\"Registry URL cannot be empty\",\n      \"invalidUrl\": \"Registry
    URL is invalid\"\n    }\n  },\n  \"TOKEN\":{\n    \"TOOLTIP\":\"Your Google container
    registry authentication token\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\":\"Token
    cannot be empty\"\n    }\n  },\n  \"USERNAME\":{\n    \"TOOLTIP\":\"GCR User Name\",\n
    \   \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"User Name cannot
    contain special characters other than - and _\",\n      \"cannotContainSpace\":\"User
    Name cannot contain space\",\n      \"required\":\"User Name cannot be empty\",\n
    \     \"startingFromNumber\": \"User Name cannot start with numbers\"\n    }\n  },\n
    \ \"PASSWORD\": {\n    \"TOOLTIP\": \"Your docker registry password\",\n    \"VALIDATION_MESSAGE\":{\n
    \     \"required\" : \"Password cannot be empty\"\n    }\n  },\n  \"PASSWORDCOMMAND\":
    {\n    \"TOOLTIP\": \"Command to retrieve docker token/password, commands must be
    available in environment\",\n    \"VALIDATION_MESSAGE\":{\n      \"required\" :
    \"Password-command cannot be empty\"\n    }\n  },\n  \"FILE\": {\n    \"TOOLTIP\":
    \"The path to a file containing your docker password in plaintext (not a docker/config.json
    file)\",\n    \"VALIDATION_MESSAGE\": {\n    }\n  },\n  \"SPINNAKERTOGGLE\":{\n
    \   \"TOOLTIP\":\"Toggle on to propagate the change into the CD Tool.\",\n    \"VALIDATION_MESSAGE\":{}\n
    \ },\n  \"VALIDATETOGGLE\":{\n    \"TOOLTIP\":\"This button controls the validation
    of the configuration. If it is on, ISD will check the configuration for errors before
    saving it. If it is off, ISD will save the configuration as it is, without any validation.
    We recommend keeping the button on unless you are sure that the configuration is
    correct and does not need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n},\n\"BAMBOO\":{\n
    \   \"HEADER\": \"Bamboo CI\",\n    \"BODY\":\"<span><p>Bamboo CI integration can
    be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'> <li><strong>Account Name</strong>: User defined name for the
    Bamboo CI Account <span class='noBr'>(Example: opsmx-bamboo)</span></li><li><strong>Bamboo
    End Point </strong>: Bamboo CI URL <span class='noBr'>(Example: https://xyz.mybamboo.com)</span></li><li><strong>Authentication
    Type</strong>: Select how the external resource confirms the user credentials</li><li><strong>Token</strong>:
    Bamboo CI personal access token. You can find <a href='https://confluence.atlassian.com/bamboo/personal-access-tokens-976779873.html'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    YmFrwqw0w9r90skfsOk9wcdd014p98kklw==)</span></li><li><strong>User Name</strong>:
    Bamboo CI User Name</li><li><strong>Password</strong>: Bamboo CI Password</li><li><strong>Username
    & Password</strong>: Accepts the user's username and password to connect to Bamboo
    CI.</li><li><strong>Permissions</strong>: Configure specific user groups access
    to this integration.</li></ul></span>\",\n    \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"The
    name of the account to operate on\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"ENDPOINT\":{\n      \"TOOLTIP\":\"Bamboo URL\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Bamboo End Point cannot be empty\",\n        \"invalidUrl\":
    \"Bamboo End Point URL is invalid\"\n      }\n    },\n    \"AUTHENTICATIONTYPE\":{\n
    \     \"TOOLTIP\":\"Select how the external resource confirms the user credentials\",\n
    \     \"VALIDATION_MESSAGE\":{}\n    },\n    \"TOKEN\":{\n      \"TOOLTIP\":\"Your
    Bamboo token\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Token cannot
    be empty\"\n      }\n    },\n    \"USERNAME\":{\n      \"TOOLTIP\":\"Your Bamboo
    username\",\n      \"VALIDATION_MESSAGE\":{\n        \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n        \"cannotContainSpace\":\"User
    Name cannot contain space\",\n        \"required\":\"User Name cannot be empty\",\n
    \       \"startingFromNumber\": \"User Name cannot start with numbers\"\n      }\n
    \   },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"Your Bamboo password\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Password cannot be empty\"\n      }\n    }\n  },\n  \"JENKINS\":{\n
    \   \"HEADER\":\"Jenkins\",\n    \"BODY\":\"<span><p>Jenkins integration can be
    used as a datasource for Approval Gate as well as to configure Spinnaker for Jenkins.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name
    for your Jenkins access. <span class='noBr'>(Example: opsmx-jenkins)</span></li><li><strong>Host
    URL</strong>: Jenkins host address, <span class='noBr'>such as https://jenkins.opsmx.net</span></li><li><strong>Authentication
    Type</strong>: Select an authentication type that corresponds to the connection
    credential parameter. It is preferable to use token authentication with username
    and token.</li><li><strong>User Name</strong>: Jenkins User Name</li><li><strong>Token</strong>:
    Jenkins personal access token. You can find <a href='https://www.jenkins.io/doc/book/using/using-credentials/'
    target='_blank'>here</a> how to generate personal access tokens. <span>(Example:
    77d67609a841b1811a114b7fbfa109b3c2)</span></li><li><strong>Password</strong>: Jenkins
    Password</li><li><strong>Username & Password</strong>: Accepts the user's username
    and password to connect to Jenkins</li><li><strong>Validate</strong>: This button
    controls the validation of the configuration. If it is on, ISD will check the configuration
    for errors before saving it. If it is off, ISD will save the configuration as it
    is, without any validation. We recommend keeping the button on unless you are sure
    that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Toggle to configure Spinnaker for Jenkins</li><li><strong>CSRF</strong>:
    Recommended to toggle on the CSRF (Cross-Site Request Forgery) flag</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User-defined account name for your Jenkins
    access.\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"HOSTURL\":{\n      \"TOOLTIP\":\"Jenkins host address, such as https://jenkins.opsmx.net\",\n
    \     \"VALIDATION_MESSAGE\":{\n        \"required\":\"Host URL cannot be empty\",\n
    \       \"invalidUrl\": \"Host URL is invalid\"\n      }\n    },\n    \"AUTHENTICATIONTYPE\":{\n
    \     \"TOOLTIP\":\"Select an authentication type that corresponds to the connection
    credential parameter. It is preferable to use token authentication with username
    and token.\",\n      \"VALIDATION_MESSAGE\":{}\n    },\n    \"CSRFFLAG\":{\n      \"TOOLTIP\":\"Recommended
    to toggle on the CSRF (Cross-Site Request Forgery) flag.\",\n      \"VALIDATION_MESSAGE\":{}\n
    \   },\n    \"TOKEN\":{\n      \"TOOLTIP\":\"Your Jenkins token\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Token cannot be empty\"\n      }\n    },\n    \"USERNAME\":{\n
    \     \"TOOLTIP\":\"Your Jenkins username\",\n      \"VALIDATION_MESSAGE\":{\n        \"noSpecialCharacters\":
    \"User Name cannot contain special characters other than - and _\",\n        \"cannotContainSpace\":\"User
    Name cannot contain space\",\n        \"required\":\"User Name cannot be empty\",\n
    \       \"startingFromNumber\": \"User Name cannot start with numbers\"\n      }\n
    \   },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"Your Jenkins password\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Password cannot be empty\"\n      }\n    },\n    \"SPINNAKERTOGGLE\":{\n
    \     \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops
    enabled Spinnaker instance\",\n      \"VALIDATION_MESSAGE\":{}\n    },\n  \"VALIDATETOGGLE\":{\n
    \   \"TOOLTIP\":\"This button controls the validation of the configuration. If it
    is on, ISD will check the configuration for errors before saving it. If it is off,
    ISD will save the configuration as it is, without any validation. We recommend keeping
    the button on unless you are sure that the configuration is correct and does not
    need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n  },\n  \"JIRA\":{\n    \"HEADER\":
    \"Jira\",\n    \"BODY\":\"<span><ul><li><strong>Account Name</strong> : User defined
    name for the Jira account</li><li><strong>Email</strong> : Jira Email Id</li><li><strong>Token</strong>
    : Jira Personal Access Token</li><li><strong>Host URL</strong> : Jira Host URL</li><li><strong>Account
    Type</strong>: Cloud Jira: Please use this option if you are using cloud instance
    of Jira. On-Prem Jira: Please use this option if you are using Jira on-prem</li><li><strong>Connect
    to CD</strong> : Switch On this toggle to configure the resource in a gitops enabled
    spinnaker instance</li><li><strong>Permissions</strong> : Configure specific user
    groups access to this integration.</li></ul></span>\",\n    \"ACCOUNTNAME\":{\n
    \     \"TOOLTIP\":\"User defined name for the Jira account\",\n      \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n    },\n    \"EMAIL\":{\n      \"TOOLTIP\":\"Jira
    Email Id\",\n      \"VALIDATION_MESSAGE\":{\n        \"email\":\"Email Id is invalid\",\n
    \       \"required\":\"Email Id cannot be empty\"\n      }\n    },\n    \"TOKEN\":{\n
    \     \"TOOLTIP\":\"Jira Personal Access Token\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Token cannot be empty\"\n      }\n    },\n    \"HOSTURL\":{\n
    \     \"TOOLTIP\":\"Jira Host URL\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Host
    URL cannot be empty\",\n        \"invalidUrl\": \"Host URL is invalid\"\n      }\n
    \   },\n    \"ACCOUNTTYPE\":{\n      \"TOOLTIP\": \"Cloud Jira: Please use this
    option if you are using cloud instance of Jira. On-Prem Jira: Please use this option
    if you are using Jira on-prem\",\n      \"VALIDATION_MESSAGE\": {\n      }\n    },\n
    \   \"SPINNAKERTOGGLE\":{\n      \"TOOLTIP\":\"Switch On this toggle to configure
    the resource in a gitops enabled Spinnaker instance\",\n      \"VALIDATION_MESSAGE\":{}\n
    \   }\n    \n  },\n  \"SERVICENOW\":{\n    \"HEADER\": \"Service Now\",\n    \"BODY\":\"<span><p>Service
    integration can be used to configure ServiceNow Custom stages in Spinnaker. In addition,
    it can also be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    Service Account <span class='noBr'>(Example: myservicenow)</span></li><li><strong>Host
    URL</strong>: ServiceNow URL <span class='noBr'>(Example: https://servicenow.opsmx.com)</span></li><li><strong>User
    Name</strong>: ServiceNow User Name, for authentication</li><li><strong>Password</strong>:
    ServiceNow Password for the User who is authenticated</li><li><strong>Connect to
    CD</strong>: Toggle to configure Spinnaker for CD</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User defined name for the Service Now
    account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"USERNAME\":{\n      \"TOOLTIP\":\"Service Now User Name\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"noSpecialCharacters\": \"User Name cannot contain special characters other
    than - and _\",\n        \"cannotContainSpace\":\"User Name cannot contain space\",\n
    \       \"required\":\"User Name cannot be empty\",\n        \"startingFromNumber\":
    \"User Name cannot start with numbers\"\n      }\n    },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"Service
    Now Password\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Password
    cannot be empty\"\n      }\n    },\n    \"HOSTURL\":{\n      \"TOOLTIP\":\"Service
    Now Host URL\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Host URL
    cannot be empty\",\n        \"invalidUrl\": \"Host URL is invalid\"\n      }\n    }\n
    \ }\n  ,\n  \"APPDYNAMICS\":{\n    \"HEADER\": \"APPDYNAMICS\",\n    \"BODY\":\"<span><ul><li><strong>Account
    Name</strong> : User defined name for the APPDYNAMICS account</li><li><strong>Controller
    Host</strong> : APPDYNAMICS Controller Host</li><li><strong>Temporary Access Token</strong>
    : APPDYNAMICS Personal Temporary Access Token</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User defined name for the APPDYNAMICS
    account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"CONTROLLERHOST\":{\n      \"TOOLTIP\":\"APPDYNAMICS Controller Host\",\n
    \     \"VALIDATION_MESSAGE\":{\n        \"required\":\"Controller Host  cannot be
    empty\",\n        \"invalidUrl\": \"Controller Host URL is invalid\"\n      }\n
    \   },\n    \"TEMPORARYACCESSTOKEN\":{\n      \"TOOLTIP\":\"APPDYNAMICS Personal
    Temporary Access Token\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Temporary
    Access Token cannot be empty\"\n      }\n    }\n  },\n  \"CLOUDWATCH\":{\n    \"HEADER\":
    \"AWS-CLOUDWATCH\",\n    \"BODY\":\"<span><p>Amazon CloudWatch Can be used as a
    monitoring provider in the verification gates</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the
    AWS-CLOUDWATCH account</li><li><strong>Access Key Id</strong>: AWS-CLOUDWATCH Access
    Key Id</li><li><strong>Secret Access Key</strong>: AWS-CLOUDWATCH Secret Access
    Key</li><li><strong>Permissions</strong>: Configure specific user groups access
    to this integration.</li></ul></span>\",\n    \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User
    defined name for the AWS-CLOUDWATCH account\",\n      \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n    },\n    \"ACCESS_ID\":{\n
    \     \"TOOLTIP\":\"AWS-CLOUDWATCH Access Key Id\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Access Key Id cannot be empty\"\n      }\n    },\n    \"SECRET_KEY\":{\n
    \     \"TOOLTIP\":\"AWS-CLOUDWATCH Secret Access Key\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Secret Access Key cannot be empty\"\n      }\n    }\n  },\n
    \ \"DATADOG\":{\n    \"HEADER\": \"DATADOG\",\n    \"BODY\":\"<span><ul><li><strong>Account
    Name</strong> : User defined name for the DATADOG account</li><li><strong>API Key</strong>
    : DATADOG API Key</li><li><strong>Application Key</strong> : DATADOG Application
    Key</li><li><strong>Permissions</strong> : Configure specific user groups access
    to this integration.</li></ul></span>\",\n    \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User
    defined name for the DATADOG account\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   \n    },\n    \"API_KEY\":{\n      \"TOOLTIP\":\"DATADOG Api Key\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"API key cannot be empty\"\n      }\n    },\n    \"APPLICATION_KEY\":{\n
    \     \"TOOLTIP\":\"DATADOG Application Key\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Application Key cannot be empty\"\n      }\n    }\n  },\n
    \ \"DYNATRACE\":{\n    \"HEADER\": \"Dynatrace\",\n    \"BODY\":\"<span><ul><li><strong>Account
    Name</strong> : User defined name for the Dynatrace account</li><li><strong>Url</strong>
    : Dynatrace URL. For example, https://www.dynatrace.com</li><li><strong>Api Token</strong>
    : Dynatrace Personal Access Token</li><li><strong>Permissions</strong> : Configure
    specific user groups access to this integration.</li></ul></span>\",\n    \"ACCOUNTNAME\":{\n
    \     \"TOOLTIP\":\"User defined name for the Dynatrace account\",\n      \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n    },\n    \"END_POINT\":{\n
    \     \"TOOLTIP\":\"Dynatrace URL\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Endpoint
    Url cannot be empty\",\n        \"invalidUrl\": \"Endpoint URL is invalid\"\n      }\n
    \   },\n    \"API_TOKEN\":{\n      \"TOOLTIP\":\"Dynatrace Personal Access Token\",\n
    \     \"VALIDATION_MESSAGE\":{\n        \"required\":\"Api Token cannot be empty\"\n
    \     }\n    }\n  },\n  \"ELASTICSEARCH\":{\n    \"HEADER\": \"Elasticsearch\",\n
    \   \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined
    account name for your Elasticsearch access.</li><li><strong>Elastic End Point</strong>:
    Elasticsearch host address, from which you access the Elasticsearch</li><li><strong>Username</strong>:
    Elasticsearch username </li><li><strong>Password</strong>: Elasticsearch password</li><li><strong>Kibana
    Endpoint</strong>: Elasticsearch Kibana host address, from which you access the
    Elasticsearch Kibana</li><li><strong>Kibana username</strong>: Elasticsearch Kibana
    username</li><li><strong>Kibana Password</strong>: Elasticsearch Kibana password</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul><span>\",\n
    \   \"ACCOUNTNAME\":{\n      \"TOOLTIP\":\"User-defined account name for your Elasticsearch
    access.\",\n      \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \   },\n    \"ENDPOINT\":{\n      \"TOOLTIP\":\"Elasticsearch host address, from
    which you access the Elasticsearch\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Elastic
    End Point cannot be empty\",\n        \"invalidUrl\": \"Elastic End Point URL is
    invalid\"\n      }\n    },\n    \"USERNAME\":{\n      \"TOOLTIP\":\"Elasticsearch
    username \",\n      \"VALIDATION_MESSAGE\":{\n        \"noSpecialCharacters\": \"User
    Name cannot contain special characters other than - and _\",\n        \"cannotContainSpace\":\"User
    Name cannot contain space\",\n        \"startingFromNumber\": \"User Name cannot
    start with numbers\"\n      }\n    },\n    \"PASSWORD\":{\n      \"TOOLTIP\":\"Elasticsearch
    password\",\n      \"VALIDATION_MESSAGE\":{\n        \"required\":\"Password cannot
    be empty\"\n      }\n    },\n    \"KIBANAENDPOINT\":{\n      \"TOOLTIP\":\"Elasticsearch
    Kibana host address, from which you access the Elasticsearch Kibana\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Kibana End Point cannot be empty\",\n        \"invalidUrl\":
    \"Kibana End Point URL is invalid\"\n      }\n    },\n    \"KIBANAUSERNAME\":{\n
    \     \"TOOLTIP\":\"Elasticsearch Kibana username\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"noSpecialCharacters\": \"Kibana User Name cannot contain special characters
    other than - and _\",\n        \"cannotContainSpace\":\"Kibana User Name cannot
    contain space\",\n        \"required\":\"Kibana User Name cannot be empty\",\n        \"startingFromNumber\":
    \"Kibana User Name cannot start with numbers\"\n      }\n    },\n    \"KIBANAPASSWORD\":{\n
    \     \"TOOLTIP\":\"Elasticsearch Kibana password\",\n      \"VALIDATION_MESSAGE\":{\n
    \       \"required\":\"Kibana Password cannot be empty\"\n      }\n    }\n  },\n
    \   \"GRAPHITE\":{\n      \"HEADER\": \"Graphite\",\n      \"BODY\":\"<span><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name
    for your Graphite access.</li><li><strong>Endpoint</strong>: Graphite host address,
    from which you access the Graphite </li><li><strong>Permissions</strong>: Configure
    specific user groups access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User-defined account name for your Graphite access.\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"URL\":{\n        \"TOOLTIP\":\"Graphite
    host address, from which you access the Graphite \",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"End Point cannot be empty\",\n          \"invalidUrl\":
    \"End Point URL is invalid\"\n        }\n      }\n    },\n    \"GRAYLOG\":{\n      \"HEADER\":
    \"GRAYLOG\",\n      \"BODY\":\"<span><ul><li><strong>Account Name</strong>: User-defined
    account name for your Graylog access.</li><li><strong>Endpoint</strong>: Graylog
    host address, from which you access the Graylog </li><li><strong>Token</strong>:
    GrayLog Personal Access Token. To generate a token, go to Greylog -> System / Users
    -> Users Overview, select a user and click on Edit tokens</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User-defined account name for your
    Graylog access.\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ENDPOINT\":{\n        \"TOOLTIP\":\"Graylog host address, from
    which you access the Graylog \",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"End
    Point cannot be empty\",\n          \"invalidUrl\": \"End Point URL is invalid\"\n
    \       }\n      },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"GrayLog Personal Access
    Token. To generate a token, go to Greylog -> System / Users -> Users Overview, select
    a user and click on Edit tokens\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Token
    cannot be empty\"\n        }\n      }\n    },\n    \"NEWRELIC\":{\n      \"HEADER\":
    \"New Relic\",\n      \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your NewRelic access.</li><li><strong>API
    Key</strong>: Provide your Newrelic User Key. This can be generated from New Relic's
    API keys UI</li><li><strong>Application Key</strong>: The application key identifies
    which account the incoming data belongs to.</li><li><strong>Account ID</strong>:
    Provide account ID to identify the account </li><li><strong>Query Key</strong>:
    Provide a query key to filter the data </li><li><strong>Permissions</strong>: Configure
    specific user groups access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User-defined account name for your NewRelic access.\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"APIKEY\":{\n
    \       \"TOOLTIP\":\"Provide your Newrelic User Key. This can be generated from
    New Relic's API keys UI\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"API
    key cannot be empty\"\n        }\n      },\n      \"APPLICATIONKEY\":{\n        \"TOOLTIP\":\"The
    application key identifies which account the incoming data belongs to.\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Application Key cannot be empty\"\n        }\n      },\n
    \     \"ACCOUNTID\":{\n        \"TOOLTIP\":\"Provide account ID to identify the
    account \",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Account
    Id cannot be empty\"\n        }\n      },\n      \"QUERYKEY\":{\n        \"TOOLTIP\":\"Provide
    a query key to filter the data \",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Query
    Key cannot be empty\"\n        }\n      },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"The
    user's token\"\n      }\n    },\n    \"PROMETHEUS\":{\n      \"HEADER\": \"Prometheus\",\n
    \     \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account Name</strong>:
    User-defined account name for your Prometheus access.</li><li><strong>Endpoint</strong>:
    Prometheus host address, from which you access the Prometheus</li><li><strong>Username</strong>:
    Prometheus username</li><li><strong>Password</strong>: Prometheus password</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User-defined account name for your
    Prometheus access.\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ENDPOINT\":{\n        \"TOOLTIP\":\"Prometheus host address, from
    which you access the Prometheus\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"End
    Point cannot be empty\",\n          \"invalidUrl\": \"End Point URL is invalid\"\n
    \       }\n      },\n      \"USERNAME\":{\n        \"TOOLTIP\":\"Prometheus username\",\n
    \       \"VALIDATION_MESSAGE\":{\n          \"noSpecialCharacters\": \"User Name
    cannot contain special characters other than - and _\",\n          \"cannotContainSpace\":\"User
    Name cannot contain space\",\n          \"required\":\"User Name cannot be empty\",\n
    \         \"startingFromNumber\": \"User Name cannot start with numbers\"\n        }\n
    \     },\n      \"PASSWORD\":{\n        \"TOOLTIP\":\"Prometheus password\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Password cannot be empty\"\n        }\n      }\n    },\n
    \   \"SPLUNK\":{\n      \"HEADER\": \"Splunk\",\n      \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your Splunk access.</li><li><strong>Splunk
    Url</strong>: Splunk host address, from which you access the Splunk</li><li><strong>Username</strong>:
    The Splunk's username</li><li><strong>Password</strong>: Splunk's password</li><li><strong>Splunk
    DashBoard Url </strong>: Splunk Dashboard URL that you want to access </li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul><span>\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User-defined account name for your
    Splunk access.\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"END_POINT\":{\n        \"TOOLTIP\":\"Splunk host address, from
    which you access the Splunk\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Splunk
    Url  cannot be empty\",\n          \"invalidUrl\": \"Splunk URL is invalid\"\n        }\n
    \     },\n      \"PASSWORD\":{\n        \"TOOLTIP\":\"Splunk's password\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Password cannot be empty\"\n        }\n      },\n      \"USER_NAME\":{\n
    \       \"TOOLTIP\":\"Splunk's user name\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"DASHBOARD_ENDPOINT\":{\n
    \       \"TOOLTIP\":\"Splunk Dashboard URL that you want to access \",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Splunk DashBoard Url cannot be empty\",\n          \"invalidUrl\":
    \"Splunk DashBoard URL is invalid\"\n        }\n      }\n    },\n    \"STACKDRIVER\":{\n
    \     \"HEADER\": \"Stackdriver\",\n      \"BODY\":\"<span><p>Google Cloud's operations
    suite (formerly Stackdriver) provides Integrated monitoring, logging, and trace
    managed services for applications and systems running on Google Cloud and beyond.</p><p><strong>Fields</strong>:</p><ul
    class='helpTextUl'><li><strong>Account Name</strong> : User defined name for the
    Stackdriver account</li><li><strong>Encrypted Key File</strong> : Stackdriver Encrypted
    Key file</li><li><strong>Permissions</strong>: Configure specific user groups access
    to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the Stackdriver account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"KEY_FILE\":{\n
    \       \"TOOLTIP\":\"Stackdriver Encrypted Key file\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Encrypted Key File cannot be empty\"\n        }\n      }\n
    \   },\n    \"SUMOLOGIC\":{\n      \"HEADER\": \"Sumo Logic\",\n      \"BODY\":\"<span><ul><li><strong>Account
    Name</strong>: User defined name for the Sumologic account</li><li><strong>Access
    ID</strong>: Sumologic Access Id. You can generate Access Id (Administration > Security
    > Access Keys)</li><li><strong>Access Key</strong>: Sumologic Access Key. You can
    generate Access Id (Administration > Security > Access Keys)</li><li><strong>Zone</strong>:
    Sumologic Zone</li><li><strong>Permissions</strong>: Configure specific user groups
    access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User
    defined name for the Sumologic account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ACCESSID\":{\n        \"TOOLTIP\":\"sumologic Access Id. You can
    generate Access Id (Administration > Security > Access Keys)\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Access Id cannot be empty\"\n        }\n      },\n      \"ACCESSKEY\":{\n
    \       \"TOOLTIP\":\"sumologic Access Key. You can generate Access Id (Administration
    > Security > Access Keys)\",\n        \"VALIDATION_MESSAGE\":{\n      \"required\":\"Access
    key cannot be empty\"\n        }\n      },\n      \"ZONE\":{\n        \"TOOLTIP\":\"sumologic
    Zone\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Zone
    cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Zone
    cannot contain space\",\n      \"required\":\"Zone cannot be empty\",\n      \"startingFromNumber\":
    \"Zone cannot start with numbers\"\n    }\n      }\n    },\n    \n    \"VMWARETANZU\":{\n
    \     \"HEADER\": \"VMWare Tanzu Observability\",\n      \"BODY\":\"<span><ul><li><strong>Account
    Name</strong>: User-defined account name for your VMWare Tanzu access</li><li><strong>Endpoint</strong>:
    VMWare Tanzu host address, from which you access the VMWare Tanzu</li><li><strong>Email</strong>:
    Provide the user's registered and authorized email</li><li><strong>API token</strong>:
    The user's API token. To generate an API token, log in to your instance as user
    with the API Tokens permission. Click the gear icon at the top right of the toolbar
    and select your user name. On the API Access tab, click Generate.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User-defined account name for your
    VMWare Tanzu access\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"END_POINT\":{\n        \"TOOLTIP\":\"VMWare Tanzu host address,
    from which you access the VMWare Tanzu\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"End
    Point cannot be empty\",\n          \"invalidUrl\": \"End Point is invalid\"\n        }\n
    \     },\n      \"EMAIL\":{\n        \"TOOLTIP\":\"Provide the user's registered
    and authorized email\",\n        \"VALIDATION_MESSAGE\":{\n          \"email\":\"Email
    is invalid\",\n          \"required\":\"Email cannot be empty\"\n        }\n      },\n
    \     \"API_TOKEN\":{\n        \"TOOLTIP\":\"The user's API token. To generate an
    API token, log in to your instance  as user with the API Tokens permission. Click
    the gear icon  at the top right of the toolbar and select your user name. On the
    API Access tab, click Generate. \",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Api
    Token cannot be empty\"\n        }\n      }\n    },\n    \"MSTEAMS\":{\n      \"HEADER\":
    \"Microsoft Teams\",\n      \"BODY\":\"\"\n    },\n    \"SLACK\":{\n      \"HEADER\":
    \"Slack\",\n      \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account Name</strong>:
    User-defined account name for your Slack access.</li><li><strong>BotName</strong>:
    Provide the bot name where you want to receive notifications in slack</li><li><strong>Token</strong>:
    The user's token to authenticate with slack.</li><li><strong>Validate</strong>:
    This button controls the validation of the configuration. If it is on, ISD will
    check the configuration for errors before saving it. If it is off, ISD will save
    the configuration as it is, without any validation. We recommend keeping the button
    on unless you are sure that the configuration is correct and does not need validation.</li><li><strong>Connect
    to CD</strong>: Switch On this toggle to configure the resource in a gitops enabled
    Spinnaker instance</li><li><strong>Permissions</strong>: Configure specific user
    groups access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the Slack account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"BOTNAME\":{\n
    \       \"TOOLTIP\":\"Slack Bot Name\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Bot Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Bot
    Name cannot contain space\",\n      \"required\":\"Bot Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Bot Name cannot start with numbers\"\n    }\n      },\n
    \     \"TOKEN\":{\n        \"TOOLTIP\":\"Slack Personal Access Token\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      },\n      \"SPINNAKERTOGGLE\":{\n
    \       \"TOOLTIP\":\"Switch On this toggle to configure the resource in a gitops
    enabled Spinnaker instance\",\n        \"VALIDATION_MESSAGE\":{}\n      },\n  \"VALIDATETOGGLE\":{\n
    \   \"TOOLTIP\":\"This button controls the validation of the configuration. If it
    is on, ISD will check the configuration for errors before saving it. If it is off,
    ISD will save the configuration as it is, without any validation. We recommend keeping
    the button on unless you are sure that the configuration is correct and does not
    need validation.\",\n    \"VALIDATION_MESSAGE\":{}\n  }\n    },\n    \"OPA\":{\n
    \     \"HEADER\": \"OPA\",\n      \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your OPA server access.</li><li><strong>EndPoint</strong>:
    OPA server host address, <span>such as https://opa:8181</span></li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User-defined account name for your
    OPA server access\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ENDPOINT\":{\n        \"TOOLTIP\":\"OPA server host address, such
    as https://opa:8181\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"End
    Point cannot be empty\",\n          \"invalidUrl\": \"End Point URL is invalid\"\n
    \       }\n      }\n    },\n    \"AQUAWAVE\":{\n      \"HEADER\": \"Aqua Wave\",\n
    \     \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account Name</strong>:
    User-defined account name for your Aqua Wave access.</li><li><strong>Username</strong>:
    The Aquawave username</li><li><strong>Bearer Token</strong>: The user's token.</li><li><strong>Permissions</strong>:
    Configure specific user groups access to this integration.</li></ul></span>\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User-defined account name for your
    Aqua Wave access.\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\":
    \"Account Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"USERNAME\":{\n        \"TOOLTIP\":\"The Aquawave username\",\n
    \       \"VALIDATION_MESSAGE\":{\n          \"noSpecialCharacters\": \"User Name
    cannot contain special characters other than - and _\",\n          \"cannotContainSpace\":\"User
    Name cannot contain space\",\n          \"required\":\"User Name cannot be empty\",\n
    \         \"startingFromNumber\": \"User Name cannot start with numbers\"\n        }\n
    \     },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"Aqua Wave Personal Access Token\",\n
    \       \"VALIDATION_MESSAGE\":{\n          \"required\":\"Bearer token cannot be
    empty\"\n        }\n      }\n    },\n    \"APPSCAN\":{\n      \"HEADER\": \"HCL
    AppScan\",\n      \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account Name</strong>:
    User-defined account name for your HCL AppScan access.</li><li><strong>Bearer Token</strong>:
    The user's token</li><li><strong>Permissions</strong>: Configure specific user groups
    access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User-defined
    account name for your HCL AppScan access.\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"TOKEN\":{\n
    \       \"TOOLTIP\":\"The user's personal access token \",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Bearer token cannot be empty\"\n        }\n      }\n    },\n
    \   \"JFROG\":{\n      \"HEADER\": \"JFrog XRay Scanning\",\n      \"BODY\":\"<span><ul
    class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name
    for your Jfrog Xray access.</li><li><strong>Endpoint</strong>: Your Jfrog Xray host
    address, from which you access the Jfrog Xray instance</li><li><strong>Token</strong>:
    The user's token.</li><li><strong>Permissions</strong>: Configure specific user
    groups access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User-defined account name for your Jfrog Xray access.\",\n
    \       \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name
    cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"ENDPOINT\":{\n        \"TOOLTIP\":\"Jfrog Xray host address, from
    which you access the Jfrog Xray instance\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Endpoint cannot be empty\",\n          \"invalidUrl\":
    \"Endpoint URL is invalid\"\n        }\n      },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"The
    user's token from jfrog xray to authenticate\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Token cannot be empty\"\n        }\n      }\n    },\n    \"PRISMACLOUD\":{\n
    \     \"HEADER\": \"Prisma Cloud\",\n      \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your Prisma Cloud access.</li><li><strong>Host
    Url</strong>: Your Prisma Cloud host address, from which you access the Prisma Cloud
    instance</li><li><strong>Application URL</strong>: Prisma Cloud Application URL</li><li><strong>Access
    Key ID</strong>: The user's access key who has access to the Prisma Cloud. If you
    are unsure, consult your Prisma Cloud administrator to get an access key.</li><li><strong>Secret
    key</strong>: The user's secret key</li><li><strong>Permissions</strong>: Configure
    specific user groups access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User-defined account name for your Prisma Cloud access.\",\n
    \       \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account Name
    cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"HOSTURL\":{\n        \"TOOLTIP\":\"Prisma Cloud host address,
    from which you access the Prisma Cloud instance\",\n        \"VALIDATION_MESSAGE\":{\n
    \         \"required\":\"Host URL cannot be empty\",\n          \"invalidUrl\":
    \"Host URL is invalid\"\n        }\n      },\n      \"APPLICATIONURL\":{\n        \"TOOLTIP\":\"Prisma
    Cloud Application URL\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Application
    URL cannot be empty\",\n          \"invalidUrl\": \"Application URL is invalid\"\n
    \       }\n      },\n      \"ACCESSKEYID\":{\n        \"TOOLTIP\":\"The user's access
    key who has access to the Prisma Cloud. If you are unsure, consult your Prisma Cloud
    administrator to get an access key.\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Access
    Key Id cannot be empty\"\n        }\n      },\n      \"SECRETKEY\":{\n        \"TOOLTIP\":\"The
    user's secret key\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Secret
    Key cannot be empty\"\n        }\n      }\n    },\n    \"SONARQUBE\":{\n      \"HEADER\":
    \"SonarQube\",\n      \"BODY\":\"<span><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User-defined account name for your Sonarqube access. </li><li><strong>Host
    Url</strong>: Sonarqube host address, from which you access the Sonaqube instance</li><li><strong>Token</strong>:
    The user's token (it is optional)</li><li><strong>Permissions</strong>: Configure
    specific user groups access to this integration.</li></ul></span>\",\n      \"ACCOUNTNAME\":{\n
    \       \"TOOLTIP\":\"User defined name for the SonarQube account\",\n        \"VALIDATION_MESSAGE\":{\n
    \     \"noSpecialCharacters\": \"Account Name cannot contain special characters
    other than -\",\n      \"cannotContainSpace\":\"Account Name cannot contain space\",\n
    \     \"required\":\"Account Name cannot be empty\",\n      \"startingFromNumber\":
    \"Account Name cannot start with numbers\"\n    }\n      },\n      \"HOSTURL\":{\n
    \       \"TOOLTIP\":\"Sonarqube host address, from which you access the Sonaqube
    instance\",\n        \"VALIDATION_MESSAGE\":{\n          \"required\":\"Host URL
    cannot be empty\",\n          \"invalidUrl\": \"Host URL is invalid\"\n        }\n
    \     },\n      \"TOKEN\":{\n        \"TOOLTIP\":\"The user's token (it is optional)\",\n
    \       \"VALIDATION_MESSAGE\":{\n          \"required\":\"Token cannot be empty\"\n
    \       }\n      }\n    },\n    \"AUTOPILOT\":{\n      \"HEADER\": \"Autopilot\",\n
    \     \"BODY\": \"<div><p>This page allows you to configure autopilot, which can
    be used as a connector in the approval stage. To include verification information
    in an approval gate, add a new row in the connector configuration, selct 'Verification'
    from the connector dropdwon, select your Autopilot account and provide the Canary
    ID.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account
    Name</strong>: User defined name for the Autopilot account<span></span></li><li><strong>User
    Name</strong>: <span>Autopilot (ISD) User Name</span></li><li><strong>Permissions</strong>:
    <span>Configure specific user groups access to this integration.</span></li></ul></div>\",\n
    \     \"ACCOUNTNAME\":{\n        \"TOOLTIP\":\"User defined name for the Autopilot
    account\",\n        \"VALIDATION_MESSAGE\":{\n      \"noSpecialCharacters\": \"Account
    Name cannot contain special characters other than -\",\n      \"cannotContainSpace\":\"Account
    Name cannot contain space\",\n      \"required\":\"Account Name cannot be empty\",\n
    \     \"startingFromNumber\": \"Account Name cannot start with numbers\"\n    }\n
    \     },\n      \"USERNAME\":{\n        \"TOOLTIP\":\" Autopilot User Name\",\n
    \       \"VALIDATION_MESSAGE\":{\n          \"noSpecialCharacters\": \"User Name
    cannot contain special characters other than - and _\",\n          \"cannotContainSpace\":\"User
    Name cannot contain space\",\n          \"required\":\"User Name cannot be empty\",\n
    \         \"startingFromNumber\": \"User Name cannot start with numbers\"\n        }\n
    \     }\n    }\n},\n  \"UNCHANGED_FORM\": \"Form is unchanged. Please make modifications
    in the form to enable the button.\",\n  \"INVALID_FORM\": \"Few fields are mandatory
    or invalid. Please fill the form to enable the button.\",\n  \"NO_WRITE_ACCESS\":
    \"You have only read permission. Please check with your administrator for updating
    permissions.\",\n  \"METRIC_TEMPLATE\": {\n    \"APM_INFRA\": {\n      \"TEMPLATE_NAME\":
    {\n        \"TOOLTIP\": \"The unique name of the template for identification\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Template Name cannot
    be empty\",\n          \"noSpecialCharacters\": \"Template Name cannot contain special
    characters\",\n          \"cannotContainSpace\": \"Template Name cannot contain
    space\",\n          \"startingFromNumber\": \"Template Name cannot start with number\",\n
    \         \"maxlength\": \"Template name should not have more than 63 characters!\",\n
    \         \"exists\": \"Template already exists\"\n        }\n      },\n      \"APM_MONITORING_PROVIDER\":
    {\n        \"TOOLTIP\": \"Select an APM datasource provider of choice\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"APM_ACCOUNT\": {\n        \"TOOLTIP\": \"Select the account
    of interest in the configured APM datasource \",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"APM_APPLICATION\": {\n        \"TOOLTIP\": \"Select the application
    of interest that you want to monitor\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"APM_API_SELECTION\": {\n        \"TOOLTIP\": \"Select the relevant API metrics
    to monitor \",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"INFRA_MONITORING_PROVIDER\":
    {\n        \"TOOLTIP\": \"Select an INFRA metrics datasource provider of choice\",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"INFRA_ACCOUNT\": {\n        \"TOOLTIP\":
    \"Select the account of interest in the configured INFRA metrics datasource \",\n
    \       \"VALIDATION_MESSAGE\": {}\n      },\n      \"INFRA_METRIC_GROUPS\": {\n
    \       \"TOOLTIP\": \"Metrics groups organized as groups for quick overview on
    each infrastructure component\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"FILTER_KEY\": {\n        \"TOOLTIP\": \"A metric scope placeholder to filter
    the scope of the metric\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Filter Key cannot be empty\",\n          \"cannotContainSpace\": \"Filter Key
    cannot contain space\"\n        }\n      },\n      \"BASELINE\": {\n        \"TOOLTIP\":
    \"A unique metric scope to identify the baseline metric\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Baseline cannot be empty\",\n          \"cannotContainSpace\":
    \"Baseline cannot contain space\"\n        }\n      },\n      \"NEW_RELEASE\": {\n
    \       \"TOOLTIP\": \"A unique metric scope to identify the canary metric\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"New Release cannot
    be empty\",\n          \"cannotContainSpace\": \"New Release cannot contain space\"\n
    \       }\n      },\n      \"NORMALIZATION\": {\n        \"TOOLTIP\": \"The selected
    Load metric will be dividing all the metrics to make the metrics more comparable
    to each other\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"THRESHOLD\":
    {\n        \"TOOLTIP\": \"Select 'Hard' mode for a stringent analysis and 'Easy'
    mode for a more lenient analysis\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"SPECIFY_CRITICAL_WATCHLIST\": {\n        \"TOOLTIP\": \"Metrics marked as
    critical, will affect the overall verification score if they fail Metrics marked
    as in watchlist will be shown first in the metric analysis report\",\n        \"VALIDATION_MESSAGE\":
    {}\n      }\n    },\n    \"CUSTOM\": {\n      \"TEMPLATE_NAME\": {\n        \"TOOLTIP\":
    \"The unique name of the template for identification\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Template Name cannot be empty\",\n          \"noSpecialCharacters\":
    \"Template Name cannot contain special characters\",\n          \"cannotContainSpace\":
    \"Template Name cannot contain space\",\n          \"startingFromNumber\": \"Template
    Name cannot start with number\",\n          \"maxlength\": \"Template name should
    not have more than 63 characters!\",\n          \"exists\": \"Template already exists\"\n
    \       }\n      },\n      \"DATA_SOURCE\": {\n        \"TOOLTIP\": \"Select a datasource
    provider of choice\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Data source cannot be empty\"\n        }\n      },\n      \"ACCOUNT\": {\n        \"TOOLTIP\":
    \"Select the account of interest in the configured datasource \",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Account cannot be empty\"\n        }\n      },\n      \"FILTER_KEY\":
    {\n        \"TOOLTIP\": \"Metric Scope Placeholder will be replaced by Baseline
    & New Release values in the Metric Query; For example, Scope Placeholder pod_name
    will be replaced by Baseline & New Release values in the metric query avg(container_memory_usage_bytes{pod=~'pod_name',container!=''})
    for getting baseline & New Release metrics data respectively from the monitoring
    provider\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Filter
    Key cannot be empty\",\n          \"cannotContainSpace\": \"Filter Key cannot contain
    space\"\n        }\n      },\n      \"BASELINE\": {\n        \"TOOLTIP\": \"Unique
    metric scope to identify the baseline metric data\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Baseline cannot be empty\",\n          \"cannotContainSpace\":
    \"Baseline cannot contain space\"\n        }\n      },\n      \"NEW_RELEASE\": {\n
    \       \"TOOLTIP\": \"Unique metric scope to identify the canary metric data\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"New Release cannot
    be empty\",\n          \"cannotContainSpace\": \"New Release cannot contain space\"\n
    \       }\n      },\n      \"ADD_NEW_QUERY\": {\n        \"TOOLTIP\": \"Add New
    Query\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"QUERY_SELECTION\":
    {\n        \"TOOLTIP\": \"Select the relevant metrics to monitor \",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"QUERY_NAME\": {\n        \"TOOLTIP\": \"A meaningful name
    given to a query or a group of similar queries \",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Query Name cannot be empty\"\n        }\n      },\n
    \     \"QUERY_STRING\": {\n        \"TOOLTIP\": \"Query to fetch the metric from
    the data source provider\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Query String cannot be empty\"\n        }\n      },\n      \"RISK_DIRECTION\":
    {\n        \"TOOLTIP\": \"Direction in which the metric difference is allowed to
    expand\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"THRESHOLD\": {\n
    \       \"TOOLTIP\": \"Percentage difference beyond which the Metric is treated
    as FAIL\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n      \"CRITICAL\": {\n
    \       \"TOOLTIP\": \"Critical\",\n        \"VALIDATION_MESSAGE\": {}\n      },\n
    \     \"WATCHLIST\": {\n        \"TOOLTIP\": \"Metrics marked as in watchlist will
    be shown first in the metric analysis report\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"WEIGHT\": {\n        \"TOOLTIP\": \"Numerical importance given
    to a metric; it can range from 0 as lowest to 1 as the highest\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"CRITICALITY\": {\n        \"TOOLTIP\": \"Normal is selected
    to remove the metric from the metric group for score calculation if it has no data,
    Critical is selected to fail the entire analysis if this metric fails or has no
    data, Must Have Data is used to fail a metric if data is missing\",\n        \"VALIDATION_MESSAGE\":
    {}\n      },\n      \"NAN_STRATEGY\": {\n        \"TOOLTIP\": \"Handles NaN values
    which can occur if there is no data in a particular interval for metric data. \",\n
    \       \"VALIDATION_MESSAGE\": {}\n      }\n    }\n  },\n  \"USAGE_INSIGHTS\":
    {\n    \"APPLICATIONS\": {\n      \"TOOLTIP\": \"Total number of applications and
    active applications over time\"\n    },\n    \"PIPELINES\": {\n      \"TOOLTIP\":
    \"Total number of pipelines and active pipelines over time\"\n    },\n    \"PIPELINES_WITH_INTELLIGENT_GATES\":
    {\n      \"TOOLTIP\": \"Total number of pipelines and the number pipelines with
    intelligent gates(approval, policy and verification gates) over time\"\n    },\n
    \   \"INTELLIGENT_GATES_BREAKDOWN\": {\n      \"TOOLTIP\": \"This graph explains
    the intelligent gates usage in pipelines over time.\"\n    },\n    \"GATES_USED\":
    {\n      \"TOOLTIP\": \"This graph explains the intelligent gates executions over
    time.\"\n    },\n    \"USERS\": {\n      \"TOOLTIP\": \"The total number of registered
    users to this ISD instance Vs the number of active users over time\"\n    }\n  },\n
    \ \"DELIVERY_INSIGHTS\": {\n    \"PIPELINES\": {\n      \"TOOLTIP\": \"Number of
    pipeline executions over time\"\n    },\n    \"MOST_ACTIVE_PIPELINES\": {\n      \"TOOLTIP\":
    \"Pipelines which have executed most number of times\"\n    },\n    \"MOST_SUCCESSFUL_PIPELINES\":
    {\n      \"TOOLTIP\": \"Pipelines which have successfully executed most number of
    times\"\n    },\n    \"MOST_FAILED_PIPELINES\": {\n      \"TOOLTIP\": \"Pipelines
    which have failed most number of times\"\n    },\n    \"FASTEST_PIPELINES\": {\n
    \     \"TOOLTIP\": \"Pipelines with fastest execution times\"\n    },\n    \"SLOWEST_PIPELINES\":
    {\n      \"TOOLTIP\": \"Pipelines with slowest execution times\"\n    },\n    \"MANUAL_JUDGMENT\":
    {\n      \"TOOLTIP\": \"Pipelines with manual judgement having slowest execution
    times\"\n    }\n  },\n  \"ACCESS_MANAGEMENT\": {\n    \"ADMINISTRATOR\": {\n      \"INFO\":
    \"Super Administrator Groups will not appear in the dropdown since their Access
    Permissions cannot be modified. Administrators will have full Access to all Resources.\",\n
    \     \"TOOLTIP\": \"Groups with Administration Permissions\"\n    },\n    \"USER_ROLE_LISTING\":
    {\n      \"HEADER\": \"ROLE MANAGEMENT\",\n      \"BODY\": \"Users should be assigned
    user roles only if they need global access to one or more resources.\"\n    },\n
    \   \"USER_ROLE_CREATION\": {\n      \"ROLENAME\": {\n        \"TOOLTIP\": \"\",\n
    \       \"VALIDATION_MESSAGE\": {\n          \"required\": \"Role Name cannot be
    empty\",\n          \"cannotContainSpace\": \"Role Name cannot contain space\",\n
    \         \"noSpecialCharacters\": \"Role Name cannot contain special character\",\n
    \         \"startingFromNumber\": \"Role Name should not start with number\"\n        }\n
    \     },\n      \"USER_GROUPS\": {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Groups cannot be empty\"\n        }\n      },\n      \"PERMISSIONS\":
    {\n        \"VALIDATION_MESSAGE\": {\n          \"required\": \"Atleast one feature
    has to be enabled with permissions\"\n        }\n      }\n    },\n    \"FEATURE_VISIBILTY_LISTING\":
    {\n      \"HEADER\": \"FEATURE FLAG MANAGEMENT\",\n      \"BODY\": \"Feature Visibility
    is used for scenarios where one or more user groups need exclusive access to a specific
    feature. For example, the 'Compliance Team' should only access the Policy Management
    feature. Administrators can enable the feature flag for the compliance team user
    group. The feature visibility function will ensure that the policy management feature
    is not visible for all other user groups.\"\n    },\n    \"FEATURE_VISIBILTY_CREATION\":
    {\n      \"ROLENAME\": {\n        \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Role Name cannot be empty\",\n          \"cannotContainSpace\":
    \"Role Name cannot contain space\",\n          \"noSpecialCharacters\": \"Role Name
    cannot contain special character\",\n          \"startingFromNumber\": \"Role Name
    should not start with number\"\n        }\n      },\n      \"USER_GROUPS\": {\n
    \       \"TOOLTIP\": \"\",\n        \"VALIDATION_MESSAGE\": {\n          \"required\":
    \"Groups cannot be empty\"\n        }\n      },\n      \"PERMISSIONS\": {\n        \"VALIDATION_MESSAGE\":
    {\n          \"required\": \"Atleast one feature has to be enabled\"\n        }\n
    \     }\n    }\n  },\n  \"LOG_TEMPLATE\": {\n    \"STRING_PATTERN\": {\n      \"TOOLTIP\":
    \"String Pattern\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"String
    Pattern cannot be empty\"\n      }\n    },\n    \"LOG_TOPICS\": {\n      \"TOOLTIP\":
    \"Strings that appear in logs with their characterization\"\n    },\n    \"LOG_TAGS\":
    {\n      \"TOOLTIP\": \"Create custom tags based on business logic.\"\n    },\n
    \   \"CHARACTERIZATION_TOPIC\": {\n      \"TOOLTIP\": \"Characterization Topic\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Characterization Topic
    cannot be empty\"\n      }\n    },\n    \"TYPE\": {\n      \"TOOLTIP\": \"Type\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"ENABLE_CLUSTER_TAG\": {\n      \"TOOLTIP\":
    \"Create custom tags based on business logic.\",\n      \"VALIDATION_MESSAGE\":
    {}\n    },\n    \"CLUSTER_TAG_STRING\": {\n      \"TOOLTIP\": \"The string pattern
    that appears in logs\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Cluster Tag String cannot be empty\"\n      }\n    },\n    \"CLUSTER_TAG\": {\n
    \     \"TOOLTIP\": \"Cluster Tag\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Cluster Tag cannot be empty\"\n      }\n    },\n    \"LOG_TEMPLATE_NAME\": {\n
    \     \"TOOLTIP\": \"Log Template Name\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Template Name cannot be empty\",\n        \"noSpecialCharacters\": \"Template
    Name cannot contain special characters\",\n        \"cannotContainSpace\": \"Template
    Name cannot contain space\",\n        \"startingFromNumber\": \"Template Name cannot
    start with number\",\n        \"maxlength\": \"Template name should not have more
    than 63 characters!\",\n        \"exists\": \"Template already exists\"\n      }\n
    \   },\n    \"PROVIDER\": {\n      \"TOOLTIP\": \"Data source for Risk Analysis\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Provider cannot be empty\"\n
    \     }\n    },\n    \"LOG_ACCOUNT\": {\n      \"TOOLTIP\": \"Account of the Log
    provider; Refer Integrations tab under Setup\",\n      \"VALIDATION_MESSAGE\": {\n
    \       \"required\": \"Log Account cannot be empty\"\n      }\n    },\n    \"QUERY_FILTER_KEY\":
    {\n      \"TOOLTIP\": \"Unique Key which identify logs to be processed in the Index\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Query Filter Key cannot
    be empty\",\n        \"cannotContainSpace\": \"Query Filter Key cannot contain space\"\n
    \     }\n    },\n    \"BASELINE\": {\n      \"TOOLTIP\": \"Unique value which identify
    baseline logs in the Index\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Baseline cannot be empty\",\n        \"cannotContainSpace\": \"Baseline cannot
    contain space\"\n      }\n    },\n    \"NEW_RELEASE\": {\n      \"TOOLTIP\": \"Unique
    value which identify New Release logs in the Index\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"New Release cannot be empty\",\n        \"cannotContainSpace\":
    \"New Release cannot contain space\"\n      }\n    },\n    \"RESPONSE_KEYWORDS\":
    {\n      \"TOOLTIP\": \"Field name in the Index containing logs to be processed\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Response Keywords cannot
    be empty\",\n        \"cannotContainSpace\": \"Response Keywords cannot contain
    space\"\n      }\n    },\n    \"TIMESTAMP_KEY\": {\n      \"TOOLTIP\": \"Unique
    Key which identify the timestamp for log; this field is optional; by default, it
    is @timestamp for elasticsearch and timestamp for graylog\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"cannotContainSpace\": \"Timestamp Key cannot contain space\"\n      }\n
    \   },\n    \"AUTOBASELINE\": {\n      \"TOOLTIP\": \"ML based learning of the baseline
    from historic analysis\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n    \"CONTEXTUAL_CLUSTER\":
    {\n      \"TOOLTIP\": \"Enable/disable cluster of unexpected events in similar context\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"CONTEXTUAL_WINDOW_SIZE\": {\n      \"TOOLTIP\":
    \"Number of Log events to be seen in a Context. Allowed size in between 25 and 50\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"max\": \"Allowed size is in between 25
    to 50\",\n        \"min\": \"Allowed size is in between 25 to 50\"\n      }\n    },\n
    \   \"INFO_CLUSTER_SCORING\": {\n      \"TOOLTIP\": \"Enabling this option will
    include INFO clusters in scoring\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n
    \   \"SENSITIVITY\": {\n      \"TOOLTIP\": \"Impact of Unexpected Issues on the
    log scoring\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Sensitivity
    cannot be empty\"\n      }\n    },\n    \"SCORING_ALGORITHM\": {\n      \"TOOLTIP\":
    \"Scoring Algorithm for Risk Analysis\",\n      \"VALIDATION_MESSAGE\": {}\n    },\n
    \   \"LOG_GROUP\": {\n      \"TOOLTIP\": \"Group of log streams that share the same
    retention, monitoring, and access control settings\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Log Group cannot be empty\",\n        \"cannotContainSpace\":
    \"Log Group cannot contain space\"\n      }\n    },\n    \"LOG_STREAM\": {\n      \"TOOLTIP\":
    \"Sequence of log events that share the same source\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Log Stream cannot be empty\",\n        \"cannotContainSpace\":
    \"Log Stream cannot contain space\"\n      }\n    },\n    \"REGION\": {\n      \"TOOLTIP\":
    \"Geographic area where AWS data center\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Region cannot be empty\"\n      }\n    },\n    \"INDEX_PATTERN\": {\n      \"TOOLTIP\":
    \"Index containing logs for processing\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\":
    \"Intex Pattern cannot be empty\",\n        \"cannotContainSpace\": \"Intex Pattern
    cannot contain space\"\n      }\n    },\n    \"CUSTOM_REGEX\": {\n      \"TOOLTIP\":
    \"Custom Regular Expression to filter the logs\",\n      \"VALIDATION_MESSAGE\":
    {}\n    },\n    \"REGULAR_EXPRESSION\": {\n      \"TOOLTIP\": \"Sequence of characters
    that specifies a search pattern\",\n      \"VALIDATION_MESSAGE\": {\n        \"cannotContainSpace\":
    \"Regular Expression cannot contain space\"\n      }\n    },\n    \"RESPONSE_KEY\":
    {\n      \"TOOLTIP\": \"Field name in the Index where regex to be searched\",\n
    \     \"VALIDATION_MESSAGE\": {}\n    },\n    \"STREAM_ID\": {\n      \"TOOLTIP\":
    \"The streams are a mechanism to route messages into categories in realtime while
    they are processed\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Stream
    ID cannot be empty\",\n        \"cannotContainSpace\": \"Stream ID cannot contain
    space\"\n      }\n    },\n    \"NAMESPACE\": {\n      \"TOOLTIP\": \"Namespace\",\n
    \     \"VALIDATION_MESSAGE\": {\n        \"required\": \"Namespace cannot be empty\",\n
    \       \"cannotContainSpace\": \"Namespace cannot contain space\"\n      }\n    },\n
    \   \"TEST_CASE_KEY\": {\n      \"TOOLTIP\": \"Field in the log index which holds
    the test case names\",\n      \"VALIDATION_MESSAGE\": {\n        \"required\": \"Test
    Case Key cannot be empty\",\n        \"cannotContainSpace\": \"Test Case Key cannot
    contain space\"\n      }\n    },\n    \"TEST_SUITE_KEY\": {\n      \"TOOLTIP\":
    \"Field in the log index which  holds the test suite names\",\n      \"VALIDATION_MESSAGE\":
    {\n        \"required\": \"Test Suite Key cannot be empty\",\n        \"cannotContainSpace\":
    \"Test Suite Key cannot contain space\"\n      }\n    }\n  }\n}"
  nginx.conf: |
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
  
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log debug;
    pid /tmp/nginx.pid;
  
    # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;
  
    events {
        worker_connections 1024;
    }
  
    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
  
        access_log  /var/log/nginx/access.log  main;
  
        sendfile            on;
        tcp_nopush          on;
        tcp_nodelay         on;
        keepalive_timeout   65;
        types_hash_max_size 2048;
  
        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;
  
        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;
  
        server {
            listen       8080 default_server;
            #listen       [::]:8080 default_server;
            server_name  _;
            root /var/www/html;
  
            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;
  
            location ^~ /deck/gate/ {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /deck {
              proxy_pass http://spin-deck:9000/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /plugin-manifest.json {
              proxy_pass http://spin-deck:9000 ;
            }
  
            location ^~ /gate/ {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /ui {
              try_files $uri $uri/ /ui/index.html;
              proxy_set_header Host $host;
            }
  
            # Go to Gate if you don't know what to do
            location / {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
        }
    }
kind: ConfigMap
metadata:
  name: oes-ui-config
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/configmaps/oes-ui-nginxconf.yaml
apiVersion: v1
data:
  nginx.conf: |
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
  
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log debug;
    pid /tmp/nginx.pid;
  
    # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;
  
    events {
        worker_connections 1024;
    }
  
    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
  
        access_log  /var/log/nginx/access.log  main;
  
        sendfile            on;
        tcp_nopush          on;
        tcp_nodelay         on;
        keepalive_timeout   65;
        types_hash_max_size 2048;
  
        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;
  
        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;
  
        server {
            listen       8080 default_server;
            #listen       [::]:8080 default_server;
            server_name  _;
            root /var/www/html;
  
            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;
  
            location ^~ /deck/gate/ {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /deck {
              proxy_pass http://spin-deck:9000/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /plugin-manifest.json {
              proxy_pass http://spin-deck:9000 ;
            }
  
            location ^~ /gate/ {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /ui {
              try_files $uri $uri/ /ui/index.html;
              proxy_set_header Host $host;
            }
  
            # Go to Gate if you don't know what to do
            location / {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
        }
    }

kind: ConfigMap
metadata:
  name: oes-ui-nginxconf
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
---
# Source: oes/templates/configmaps/opa-persist.yaml
apiVersion: v1
data:
  opa-persist.sh: |
    wait_period=0
    while true
    do
    kubectl get po -n default -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')
    wait_period=$(($wait_period+10))
    if [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ];
    then
      echo \"Spinnaker and OES services are Up and Ready..\"
      set -x
      sleep 5
      BASEURL=http://oes-sapor:8085
      USERPASS="${GATEUSER}"
      curl -H x-spinnaker-user:$USERPASS $BASEURL/oes/policy/list > listofpolicies.json
      #Get the policy NAMES
      [ -s "listofpolicies.json" ] && (cat listofpolicies.json | jq .[] | jq -r .policyName > policies) || sleep infinity
      #for each NAME
      while read -e name; do
        #Get content
        curl -H x-spinnaker-user:$USERPASS $BASEURL/oes/policy/$name > tmp.json
        #Get Policy ID
        ID=`cat tmp.json|jq .response | jq '.policyId'`
        #Delete Policy ID
        cat tmp.json|jq .response | jq 'del(.policyId)'  > update.json
        #update
        curl -H x-spinnaker-user:$USERPASS -X PUT -H "Content-Type: application/json" -d @update.json $BASEURL/oes/v1/policy/$ID
      done <  policies
      sleep infinity
      #endFOR
    else
      if [ $wait_period -gt 2000 ];
      then
          echo \"Script is timed out as the OES is not ready yet.......\"
          break
      else
          echo \"Waiting for OES services to be ready\"
          sleep 1m
      fi
    fi
    done
kind: ConfigMap
metadata:
  name: opa-persist
---
# Source: oes/templates/configmaps/standard-error-codes.yaml
apiVersion: v1
data:
  standard-error-codes.csv: |-
    standardErrorCodesMapping.ISD-IsEmpty-400-01 = ISD-IsEmpty-400-01 : {0} - {1} is empty. Please provide the {1}.
    standardErrorCodesMapping.ISD-IsNull-400-02 = ISD-IsNull-400-02 : {0} - {1} is null. Please provide the {1}.
    standardErrorCodesMapping.ISD-MustBeAlphanumericName-400-03 = ISD-MustBeAlphanumericName-400-03 : {0} - {1} should be alphanumeric without any special characters !
    standardErrorCodesMapping.ISD-ExceedsMaxStringLength-400-04 = ISD-ExceedsMaxStringLength-400-04 : {0} - {1} should not have more than {2} characters.
    standardErrorCodesMapping.ISD-NotConfigured-400-05 = ISD-NotConfigured-400-05 : {0} - {1} is not configured. Please configure the {1} !
    standardErrorCodesMapping.ISD-PolicyNotProvided-400-06 = ISD-PolicyNotProvided-400-06 : {0} - Policies are mandatory for automated approval gate.
    standardErrorCodesMapping.ISD-EmptyKeyOrValueInJson-400-07 = ISD-EmptyKeyOrValueInJson-400-07 : {0} - {1} is missing in json !
    standardErrorCodesMapping.ISD-UnableToParseJSON-400-08 = ISD-UnableToParseJSON-400-08 : {0} - Unable to parse Json. Please provide a valid json with required data !
    standardErrorCodesMapping.ISD-MustBeANumber-400-09 = ISD-MustBeANumber-400-09 : {0} - {1} must be a number : {2}
    standardErrorCodesMapping.ISD-InvalidURL-400-10 = ISD-InvalidURL-400-10 : {0} - {1} is invalid - {2}
    standardErrorCodesMapping.ISD-BadRequest-400-11 = ISD-BadRequest-400-11 : {0} - {1} {2}
    standardErrorCodesMapping.ISD-Unauthorized-401-01 = ISD-Unauthorized-401-01 : {0} - {1} not authorized. {2}.
    standardErrorCodesMapping.ISD-Unauthorized-401-02 = ISD-Unauthorized-401-02 : {0} - User group not found for user : {1}.
    standardErrorCodesMapping.ISD-NotAdmin-401-03 = ISD-NotAdmin-401-03 : {0} - {1} is not an admin !
    standardErrorCodesMapping.ISD-Forbidden-403-01 = ISD-Forbidden-403-01 : {0} - {1} doesn't have {2} permission on this feature: {3}
    standardErrorCodesMapping.ISD-Forbidden-403-02 = ISD-Forbidden-403-02 : {0} - {1} is invalid.
    standardErrorCodesMapping.ISD-Forbidden-403-03 = ISD-Forbidden-403-03 : {0} - {1} : {2}.
    standardErrorCodesMapping.ISD-Forbidden-403-04 = ISD-Forbidden-403-04 : {0} - {1} namespace is not accessible for given kubeconfig account {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-01 = ISD-IsNotFound-404-01 : {0} - {1} not found : {2}
    standardErrorCodesMapping.ISD-NoData-404-02 = ISD-NoData-404-02 : {0} - No data found for {1}
    standardErrorCodesMapping.ISD-DoesNotExist-404-03 = ISD-DoesNotExist-404-03 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-04 = ISD-IsNotFound-404-04 : {0} - {1} not found {2}.
    standardErrorCodesMapping.ISD-AlreadyExists-409-01 = ISD-AlreadyExists-409-01 : {0} - {1} already exists: {2}
    standardErrorCodesMapping.ISD-Disconnected-409-02 = ISD-Disconnected-409-02 : {0} - {1}
    standardErrorCodesMapping.ISD-FailedToDelete-412-01 = ISD-FailedToDelete-412-01 : {0} - Unable to delete {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-FailedToDeletePolicy-412-02 = ISD-FailedToDeletePolicy-412-02 : {0} - Unable to delete policy as it is already in use for {1} gate !
    standardErrorCodesMapping.ISD-FailedToUpdate-412-03 = ISD-FailedToUpdate-412-03 : {0} - Unable to update {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-InvalidURL-422-01 = ISD-InvalidURL-422-01 : {0} - The requested {1} URL is invalid !
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-02 = ISD-ConnectionOrAuthenticationFailed-422-02 : {0} - {1} connection or authentication failed : HTTP status {2}
    standardErrorCodesMapping.ISD-InvalidCredentials-422-03 = ISD-InvalidCredentials-422-03 : {0} - {1} credentials are invalid !
    standardErrorCodesMapping.ISD-InvalidEndpoint-422-04 = ISD-InvalidEndpoint-422-04 : {0} - {1} endpoint is invalid !
    standardErrorCodesMapping.ISD-InvalidEndpointOrCredentials-422-05 = ISD-InvalidEndpointOrCredentials-422-05 : {0} - {1} endpoint or credentials are invalid !
    standardErrorCodesMapping.ISD-UsernameOrPasswordIsBlank-422-06 = ISD-UsernameOrPasswordIsBlank-422-06 : {0} - {1} is blank but {2} is supplied. Both must be present or blank.
    standardErrorCodesMapping.ISD-UnknownDatasource-422-07 = ISD-UnknownDatasource-422-07 : {0} - Unknown datasource or datasource is currently not supported : {1}
    standardErrorCodesMapping.ISD-InvalidProvider-422-08 = ISD-InvalidProvider-422-08 : {0} - {1} provider is invalid !
    standardErrorCodesMapping.ISD-InvalidPath-422-09 = ISD-InvalidPath-422-09 : {0} - {1} path is invalid !
    standardErrorCodesMapping.ISD-UnableToGenerate-422-10 = ISD-UnableToGenerate-422-10 : {0} - Unable to generate {1} !
    standardErrorCodesMapping.ISD-FailedToCreate-422-11 = ISD-FailedToCreate-422-11 : {0} - Failed to create {1}.
    standardErrorCodesMapping.ISD-EndpointIsBlank-422-12 = ISD-EndpointIsBlank-422-12 : {0} - {1} endpoint is blank. {2} must be blank.
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-13 = ISD-ConnectionOrAuthenticationFailed-422-13 : {0} - {1} connection or authentication failed.
    standardErrorCodesMapping.ISD-FailedToUpdate-422-14 = ISD-FailedToUpdate-422-14 : {0} - Failed to Update {1}.
    standardErrorCodesMapping.ISD-FailedToDelete-422-15 = ISD-FailedToDelete-422-15 : {0} - Failed to Delete {1}.
    standardErrorCodesMapping.ISD-DoesNotMatch-422-16 = ISD-DoesNotMatch-422-16 : {0} - {1} does not match {2}.
    standardErrorCodesMapping.ISD-DoesNotExist-422-17 =  ISD-DoesNotExist-422-17 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-DoesNotSupport-422-18 = ISD-DoesNotSupport-422-18 : {0} - {1} does not support {2}.
    standardErrorCodesMapping.ISD-UnableToVerify-422-19 = ISD-UnableToVerify-422-19 : {0} - Unable to verify {1}.
    standardErrorCodesMapping.ISD-FailedToInitialize-422-20 = ISD-FailedToInitialize-422-20 : {0} - Failed to initialize {1}.
    standardErrorCodesMapping.ISD-DoesNotHave-422-21 = ISD-DoesNotHave-422-21 : {0} - {1} does not have {2}.
    standardErrorCodesMapping.ISD-UnableToAddStage-424-01 = ISD-UnableToAddStage-424-01 : {0} - Unable to add stage in {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-424-02 = ISD-UnableToDelete-424-02 : {0} - Unable to delete {1} while analysis is under process !
    standardErrorCodesMapping.ISD-UnableToDelete-424-03 = ISD-UnableToDelete-424-03 : {0} - Unable to delete {1} as already in use {2}
    standardErrorCodesMapping.ISD-UnableToDelete-424-04 = ISD-UnableToDelete-424-04 : {0} - Unable to delete {1} as it is involved in multi-service analysis !
    standardErrorCodesMapping.ISD-ShouldBeNumber-500-01 = ISD-ShouldBeNumber-500-01 : {0} - {1} should be an number !
    standardErrorCodesMapping.ISD-ShouldBePositiveNumber-500-02 = ISD-ShouldBePositiveNumber-500-02 : {0} - {1} should be an positive number !
    standardErrorCodesMapping.ISD-UnableToFetch-500-03 = ISD-UnableToFetch-500-03 : {0} - Unable to fetch {1} from database. Please try after some time !
    standardErrorCodesMapping.ISD-UnableToCreate-500-04 = ISD-UnableToCreate-500-04 : {0} - Unable to create {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-500-05 = ISD-UnableToDelete-500-05 : {0} - Unable to delete {1} !
    standardErrorCodesMapping.ISD-UnableToUpdate-500-06 = ISD-UnableToUpdate-500-06 : {0} - Unable to update {1} !
    standardErrorCodesMapping.ISD-UnableToValidate-500-07 = ISD-UnableToValidate-500-07 : {0} - Unable to validate {1} !
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-01 = ISD-ServiceUnavailable-503-01 : {0} - {1} : {2}
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-02 = ISD-ServiceUnavailable-503-02 : {0} - {1}
    standardErrorCodesMapping.ISD-UnKnowHostException-503-03 = ISD-UnKnowHostException-503-03 : {0} - {1}
kind: ConfigMap
metadata:
  labels:
    app: oes
  name: standard-error-codes-config
---
# Source: oes/templates/customstages/ansible-config.yaml
apiVersion: v1
data:
  run.sh: |
        #!/bin/bash

        file="$inventoryfile"

        if test -z "$file"

        then

        echo "No Inventory file specified taking default values"

        exit 1

        else

        echo "Inventory file specified Manually"

        ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa

        git clone "https://"$gitusername":"$gitpassword"@"$gitrepo""

        host1=$(head -1 $file)

        ip=$(cat $file | head -2 | tail -1)

        host2=$(echo $host1 | cut -d "[" -f2 | cut -d "]" -f1)

        sshpass -p "$userpassword" ssh-copy-id -o StrictHostKeyChecking=no $nodeuser@$ip

        cat $file >> /etc/ansible/hosts

        touch /etc/ansible/group_vars/$host2

        echo "ansible_ssh_user: $nodeuser" > /etc/ansible/group_vars/$host2

        ansible -i /etc/ansible/hosts $host2 -m ping

        ansible-playbook --syntax-check "$ansiblefile"

        ansible-playbook "$ansiblefile"

        fi

kind: ConfigMap
metadata:
  name: ansible-config
---
# Source: oes/templates/customstages/custom-notification-email-config.yaml
apiVersion: v1
data:
  run.sh: |
    #!/bin/sh
    #Install SSMTP
    apk add ssmtp > /dev/null
    #Removing default file
    cat /dev/null >/etc/ssmtp/ssmtp.conf
    #Add configuration in ssmtp.conf file
    ssmtpemail=$(echo "$ssmtpemail" | tr -d [:space:])
    email=$(echo "$email"| tr -d [:space:])
    body=$(echo $body | tr -d [:space:])
    if [ -z $ssmtpemail ]
    then
    echo "not specified smtp email"
    exit 5
    else
    if [ -z $email ]
    then
    echo "not specified the sender email address"
    exit 5
    else
    if [ -z "$body" ]
    then
    echo "not specified the Email body"
    exit 5
    else
    cat <<EOT>> /etc/ssmtp/ssmtp.conf
    root=$ssmtpemail
    mailhub=smtp.gmail.com:587
    AuthUser=$ssmtpemail
    AuthPass=$emailpassword
    UserTLS=YES
    UseSTARTTLS=YES
    rewriteDomain=gmail.com
    hostname=localhost
    FromLineOverride=YES
    EOT
    #add body to file
    touch body.txt
    cat <<EOT>> body.txt
    $body
    EOT
    export MAILFROM="$ssmtpemail"
    export MAILTO="$email,$ccmail"
    export SUBJECT="$subject"
    export BODY="body.txt"
    (
    echo "From: $MAILFROM"
    echo "To: $MAILTO"
    echo "Subject: $SUBJECT"
    cat $BODY
    ) | /usr/sbin/sendmail $MAILTO
    fi
    fi
    fi
kind: ConfigMap
metadata:
  name: email-config
---
# Source: oes/templates/customstages/opsmx-terraspin-backend-config.yaml
apiVersion: v1
data:
  gcloudauth.sh: |
    #!/bin/bash
    #set -x
    jsonkey=$(ls /home/terraspin/opsmx/gcp/)
    if [ -z "$jsonkey" ]
            then
              echo "gcp service account is not configured in backend"
                exit 5
     else
        echo "Authenticating to gcp using service account"

         saemail=$(cat /home/terraspin/opsmx/gcp/$jsonkey | jq -r '.client_email')

          if [ "$?" -eq 0 ]
          then

    export GOOGLE_APPLICATION_CREDENTIALS=/home/terraspin/opsmx/gcp/$jsonkey
    gcloud auth activate-service-account $saemail --key-file=/home/terraspin/opsmx/gcp/$jsonkey > /dev/null


    bash run.sh
    else

    echo "service email is missing in the json key which you stored in backend"
    exit 5
    fi
    fi
  role.sh: "#!/bin/bash\nrole=$awsrole\nns=$namespace\nif [ -z \"$role\" ]\nthen\n
    \   echo \"not provided account name\"\n    exit 5\nelse\n    echo \"Checking
    the account validity\"\n    curl -soq GET \"http://spin-clouddriver-ro.$ns.svc.cluster.local:7002/credentials/$role\"
    --header \"Content-Type: application/json\" > roleinfo.json\n    if [ \"$?\" -eq
    0 ]\n    then\n        ##Extract the assume role from the account info Json using
    the jq\n        awsregion=$(cat roleinfo.json  | jq -r '.regions[].name')\n        awsassumeRole=$(cat
    roleinfo.json | jq -r '.assumeRole')\n        awsaccountId=$(cat roleinfo.json
    | jq -r '.accountId')\n        ##Get the Account Credentials using the Assume
    role \n        aws sts assume-role --role-arn \"arn:aws:iam::$awsaccountId:$awsassumeRole\"
    --role-session-name AWSCLI-Session > creds.json\n        ##Get the Account Credentials
    using the Assume role\n        awsaccesskey=$(cat creds.json | jq -r '.Credentials.AccessKeyId')\n
    \       awssecretkey=$(cat creds.json | jq -r '.Credentials.SecretAccessKey')\n
    \       awssessiontoken=$(cat creds.json | jq -r '.Credentials.SessionToken')\n
    \       export AWS_ACCESS_KEY_ID=$awsaccesskey\n        export AWS_SECRET_ACCESS_KEY=$awssecretkey\n
    \       export AWS_SESSION_TOKEN=$awssessiontoken\n        export AWS_REGION=$awsregion\n
    \       #aws configure list\n        bash run.sh\n    else\n        echo \"In-Valid
    account $role\"\n        exit 1\n    fi\nfi\n"
  run.sh: "#!/bin/bash \n#set -x\n\nterraformcommand=\"$command\"\nscriptact=$(echo
    \"$scriptaccount\" | tr -d [:space:])\ntfrepo=$(echo \"$repo\" | tr -d [:space:])\ntflocation=$(echo
    \"$location\" | tr -d [:space:])\noverride=$(echo \"$overridefile\" | tr -d [:space:])\nTFCMD=$(echo
    \"$terraformcommand\" | tr -d [:space:])\nstatefolder=$(echo \"$staterep\" | awk
    -F/ '{print $2}' | sed 's/\\.git\\>//g')\n\necho \"-------- Terraform Command
    ----------\"\necho \"            $TFCMD                   \"\necho \"-------------------------------------\"\n\nif
    [ -z $scriptact ]\nthen\n\techo \" Not Specified the Tf script account \"\n\texit
    1\nelse\n\tcheckaccount=$(cat /home/terraspin/opsmx/app/config/artifactaccounts.json
    | jq -r '.[][] | select (.accountname == \"'$scriptact'\")')\n\tif [ -z \"$checkaccount\"
    ]\n\tthen\n\t\techo \"Script Account is Not there artifactaccounts.json\"\n\t\texit
    1\n\telse\n\t\techo \"Script account is located in artifactaccounts.json\"\n\t\tusername=$(cat
    /home/terraspin/opsmx/app/config/artifactaccounts.json | jq -r '.[][] | select
    (.accountname == \"'$scriptact'\")|.username')\n\t\tpassword=$(cat /home/terraspin/opsmx/app/config/artifactaccounts.json
    | jq -r '.[][] | select (.accountname == \"'$scriptact'\")|.password')\n\t\thost=$(cat
    /home/terraspin/opsmx/app/config/artifactaccounts.json | jq -r '.[][] | select
    (.accountname == \"'$scriptact'\")|.host')\n                echo host $host\n\t\thosturl=$(echo
    ${host##*/})\n\t\tif [[ \"$tfrepo\" == *//* ]]\n                then\n                        echo
    \"checking the input Artifact repo  and branch\"\n                        tfbranch=$(echo
    $tfrepo | awk -F// '{print $2}')\n                        tfrepo=$(echo $tfrepo
    | awk -F// '{print $1}')\n                                if [[ \"$tfrepo\" ==
    */* ]] && [[ $tfrepo == *\".git\"* ]]\n                                then\n
    \                                       echo \"valid Artifact repo  name\"\n                                        if
    [ -z $tfbranch ]\n                                        then\n                                                 echo
    \"invalid input format of Artifact repo specify as ....> org/repo.git//branch\"\n
    \                                                exit 5\n                                         else\n
    \                                                echo \"Artifact repo Branch specified
    as $tfbranch\"\n                                         fi\n                                 else\n
    \                                        echo \"In valid repo name format of Artifact
    repo should be....> Org/repo.git \"\n                                         exit
    5\n                                 fi\n                         \n                 else\n
    \                        echo \"invalid input format of Artifact repo specify
    as ....>  org/repo.git//branch\"\n                         exit 5\n                 fi\n\tfi\nfi\n\n\n###################################################\n#TERRADORM
    COMMANDS FUNCTIONALITY \n###################################################\nif
    [ $TFCMD == \"plan\" ]\nthen\n    echo \"Plan executing............\"\n    cd
    $HOME\n    git clone https://$username:$password@$hosturl/$tfrepo workspace -b
    $tfbranch > /dev/null\n    cd workspace/$tflocation\n    TF_WORKSPACE=$TF_WORKSPACE
    terraform init\n    if [ $? -eq 0 ]; then\n       echo \"Terraform Init Completed\"\n
    \   else \n        echo \"$TF_WORKSPACE workspace does not exists... creating
    newly\"\n        terraform workspace new $TF_WORKSPACE\n        TF_WORKSPACE=$TF_WORKSPACE
    terraform init -reconfigure\n        echo \"Terraform Init Completed\"\n    fi\n
    \   terraform validate\n    if [ -z $override ]\n    then\n#\t    echo \"Not Specified
    the Override File\"\n\t    terraform plan -out=terraform.plan\n    else\n\t    terraform
    plan -var-file=$override -out=terraform.plan\n    fi\n    if [ $? -eq 0 ]; then\n\t
    \   echo \"Terraform Plan Completed\"\n    \n    else\n\t    echo Terraform Plan
    FAILED\n\t    exit 5\n    fi\n\nelif [ $TFCMD == \"apply\" ]\nthen\n    echo \"Apply
    executing...........................\"\n     cd $HOME\n     git clone https://$username:$password@$hosturl/$tfrepo
    workspace -b $tfbranch > /dev/null\n     cd workspace/$tflocation\n     TF_WORKSPACE=$TF_WORKSPACE
    terraform init\n     terraform validate\n     #terraform plan -var-file=$override
    -out terraform.plan\n\tif [ -z $override ]\n\tthen\n\t\t#echo \"Not Specified
    the Override File\"\n\t\tterraform apply -auto-approve\n\t\tif [ $? -eq 0 ]; then\n\t\t\techo
    \"------------------------------------------------\"\n\t\t\techo \"           Terraform
    Apply Completed            \"\n\t\t\techo \"------------------------------------------------\"\n\t\t\techo
    \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"COMPLETED\"\"\n\t\t\tFILE=outputs.tf\n\t\t\tif
    test -f \"$FILE\"; then\n\t\t\t\techo \"$FILE exists.\"\n\t\t\t\tterraform output
    > outputvariables\n\t\t\t\tcat outputvariables | tr -d ' ' | tr -d '\"'\n\t\t\tfi\n\t\telse\n\t\t\techo
    Terraform Apply  FAILED\n                        echo \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"FAILED\"\"\n
    \                       exit 5\n\t\tfi\n\n\telse\n\t\tterraform apply -var-file=$override
    -auto-approve\n\t\tif [ $? -eq 0 ]; then\n                        echo \"------------------------------------------------\"\n
    \                       echo \"           Terraform Apply Completed            \"\n
    \                       echo \"------------------------------------------------\"\n
    \                       echo \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"COMPLETED\"\"\n\t\t\tFILE=outputs.tf\n\t\t\tif
    test -f \"$FILE\"; then\n\t\t\t\techo \"$FILE exists.\"\n\t\t\t\tterraform output
    > outputvariables\n\t\t\t\tcat outputvariables | tr -d ' ' | tr -d '\"'\n\t\t\tfi\n\t\telse\n
    \                       echo Terraform Apply  FAILED\n                        echo
    \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"FAILED\"\"\n                        exit
    5\n                fi\n\n\n\tfi\n\nelif [ $TFCMD == \"destroy\" ]\nthen\n    echo
    \"Destroy executed\"\n\t\t     cd $HOME\n                     git clone https://$username:$password@$hosturl/$tfrepo
    workspace -b $tfbranch > /dev/null\n                     cd workspace/$tflocation\n
    \                    TF_WORKSPACE=$TF_WORKSPACE terraform init\n                     terraform
    validate\n\n                        if [ -z $override ]\n                        then\n
    \                             #  echo \"Not Specified the Override File\"\n                                terraform
    destroy -auto-approve\n\t\t\t\tif [ $? -eq 0 ]; then\n\t\t\t\t\techo \"------------------------------------------------\"\n\t\t\t\t\techo
    \"           Terraform Destroy Completed            \"\n\t\t\t\t\techo \"------------------------------------------------\"\n\t\t\t\t\techo
    \"SPINNAKER_PROPERTY_TERRAFORMDESTROY=\"COMPLETED\"\"\n\t\t\t\telse\n\t\t\t\t\techo
    \"Terraform Destroy Failed\"\n\t\t\t\t\texit 5\n\t\t\t\tfi\n\t\t\telse\n                                terraform
    destroy -var-file=$override -auto-approve\n\t\t\t\tif [ $? -eq 0 ]; then\n                                        echo
    \"------------------------------------------------\"\n                                        echo
    \"           Terraform Destroy Completed          \"\n                                        echo
    \"------------------------------------------------\"\n                                        echo
    \"SPINNAKER_PROPERTY_TERRAFORMDESTROY=\"COMPLETED\"\"\n                                else\n
    \                                       echo \"Terraform Destroy Failed\"\n\t\t\t\t\texit
    5\n                                fi\n\n                        fi\nelse\n    echo
    \"Not able to validate Terraform state \"plan\" or \"apply\" or \"destroy\" \"\nfi\n"
kind: ConfigMap
metadata:
  name: opsmx-terraspin-backend-config
---
# Source: oes/templates/customstages/updatepr-config.yaml
apiVersion: v1
data:
  run.sh: "#!/bin/sh\naccesstoken=$(echo \"$accesstoken\" | tr -d [:space:])\nmethod=$(echo
    \"$method\"| tr -d [:space:])\nurl=$(echo $url | tr -d [:space:])\nif [ -z $accesstoken
    ]\nthen\n\techo \"not specified accesstoken\"\n\texit 5\nelse\n\tif [ -z $method
    ]\n\tthen\n\t\techo \"not specified the method ....POST\"\n\t\texit 5\n\telse\n\t\tif
    [ -z \"$url\" ]\n\t\tthen\n\t\t       echo \"not specified the URL\"\n\t\t       exit
    5\n\t       else\n\t\t       curl -s -H \"Authorization: token $accesstoken\"
    -X $method -d '{\"body\":\"'\"$payload\"'\"}' \"$url\"\n\t\t       if [ $? -eq
    0 ]\n\t\t       then\n\t\t\t       echo \"curl call succeded\"\n\t\t       else\n\t\t\t
    \      echo Curl call not succeded with the URL $url\n\t\t\t       exit 5\n\t\t
    \      fi\n\t       fi\n       fi\nfi\n"
kind: ConfigMap
metadata:
  name: updatepr-config
---
# Source: oes/templates/pipeline-promotion/pipe-promot-config-cm.yaml
apiVersion: v1
data:
  repo.properties: |
    #properties file for pipeline promotion scripts

    # Common Stuff
    repo_type=git
    repo_name=repo_name
    root_folder=pipeline/
    #S3 Specific
    export AWS_ACCESS_KEY_ID=access_key
    export AWS_SECRET_ACCESS_KEY=secret_key

    #git mandatory patameters
    git_url=example.repo.com
    git_project=project_name
    git_user=username
    git_branch=samplerepo
    #git_password=
    #API
    git_api_url=https://api.github.com/repos  # bitbucket

    #Auto PR requirements
    merge_branch=false
    auto_merge=false
    git_approve_user=approver_user
    target_branch=master

    #optional
    #git_user_email=krish@company.com

    #delete pipeLine
    delete_on_sync_spin=
    delete_on_sync_repo=
    #git_approve_user_password=
    #git_secret_sshkey=
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: pipe-promot-config
---
# Source: oes/templates/pipeline-promotion/pipe-promot-scripts-cm.yaml
apiVersion: v1
data:
  bitbucket.sh: |
    #!/bin/bash
    #this script funtions only work for bitbucket central repository
    #this script funtions only work for git repo
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #   git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #  repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol
    # note *** env variables are mandatory to work with the script

    source scripts/git.sh
    git_bitbucket_api=$git_api_url
    pr_id=0
    approve_pr_bitbucket(){
      approve_req=$(curl -X POST -u $git_approve_user:$git_pr_token \
      $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/approve -o -I -L -s -w "%{http_code}")
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request "
        exit 1
      fi
    }
    merge_pr_bitbucket(){
      merge_req=$(curl  -X POST -u $git_user:$git_secret_token   \
      $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/merge -o -I -L -s -w "%{http_code}")
      echo $merge_req
      if [[ $merge_req == 200  ]]; then
        echo "merged pr successfully"
      elif [[ $merge_req == 202 ]]; then
        echo "merging is in progress will be merged in less than a min"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }
    create_pr_bitbucket(){
      local output=$(curl  -X POST -H "Content-Type: application/json" -u $git_user:$git_secret_token   $git_bitbucket_api${git_project}/${git_repo}/pullrequests -d '{
        "title": "merging '$git_branch' to '$target_branch'",
        "source": {
                "branch": {
                    "name": "'$git_branch'"
                }
            },
            "destination": {
                "branch": {
                    "name": "'$target_branch'"
                }
            }
    }')
      echo $output
      echo $output > pr_response.json
      grep  "There are no changes to be pulled" pr_response.json
      if [ "$?" = 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        pr_id=$(cat  pr_response.json| jq '(.id)' | sed 's/\"//g')
        if [ $? = 0 ]; then
          echo "successfully created pull request "
          #rm -f pr_response.json
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }
    sync_spin_to_bitbucket(){
      setup_git
      sync_spin_to_git
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_bitbucket_api=$git_bitbucket_api:$git_api_url_port
          create_pr_bitbucket
          if [[ $auto_merge == "true" ]]; then
            approve_pr_bitbucket
            sleep 5
            merge_pr_bitbucket
          fi
        else
          create_pr_bitbucket
          if [[ $auto_merge == "true" ]]; then
            approve_pr_bitbucket
            sleep 5
            merge_pr_bitbucket
          fi
        fi
      fi
    }
  deployer.sh: |
    #!/bin/bash
    echo "In deployer.sh"
    SBASE=scripts
    source config/repo.properties
    BRANCH_NAME_UI=$(echo $branch_ui | sed 's/[][]//g')
    echo $BRANCH_NAME_UI
    if [ -z "$BRANCH_NAME_UI" ]
    then
      echo "Not Provided the Branch in the spinnaker UI....Continuing with the default branch specified in configmap"
      echo $git_branch
    else
      echo "Provided the User defined Branch in spinnaker UI"
      git_branch=$BRANCH_NAME_UI
      echo $git_branch
    fi
    ROOT_FOLDER_UI=$(echo $rootfolder_ui | sed 's/[][]//g')
    echo $ROOT_FOLDER_UI
    if [ -z "$ROOT_FOLDER_UI" ]
    then
      echo "Not Provided the Save Path in the spinnaker UI....Continuing with the default path specified in configmap"
      echo $root_folder
    else
      echo "Provided the User defined Branch in spinnaker UI"
      root_folder=$ROOT_FOLDER_UI
      echo $root_folder
    fi
    source $SBASE/spin.sh
    source $SBASE/stash.sh
    source $SBASE/s3.sh
    source $SBASE/github.sh
    source $SBASE/bitbucket.sh
    echo "Sourcing complete"
    sync_repo_from_spinnaker(){
      if [[ $repo_type = "s3" ]];
      then
        upload_spin_to_s3
      elif [[ $repo_type = "stash" ]]; then
        sync_spin_to_stash
      elif [[ $repo_type == "bitbucket" ]]; then
        sync_spin_to_bitbucket
      elif [[ $repo_type = "git" ]]; then
        sync_spin_to_github
      elif [[ $repo_type = "gitea" ]]; then
        sync_spin_to_github
      else
        echo "Not specified Repo type"
        exit 5
      fi
    }
    sync_spinnaker_from_repo(){
      if [[ $repo_type = "s3" ]];
      then
        sync_from_s3_spin
      elif [[ $repo_type = "stash" || $repo_type = "git" || $repo_type = "bitbucket" ]]; then
        sync_git_to_spin
      elif [[ $repo_type = "gitea" ]]; then
        sync_git_to_spin
      fi
    }
    if [[ "$command" == "download" ]]; then
      sync_spinnaker_from_repo
    elif [[ "$command" == "upload" ]]; then
      echo "executing upload"
      #statement
      sync_repo_from_spinnaker
    else
      echo "ERROR: unknown command"
    fi
    echo "Done executing"
  git.sh: |
    #!/bin/bash
    source scripts/spin.sh
    git_repo=$repo_name
    tempdir="/tmp/"
    pull_requred=false
    branch_check() {
    if [[ $git_branch == "" ]]
    then
      cd $tempdir/$git_repo
      defaultbranch=$(git branch | awk '{print $2}')
      git_branch="$defaultbranch"
      echo "WAR: Not specified the branch to push the pipeline json, Considering the default branch $git_branch ..."
      cd -
    fi
    }
    setup_git() {
      echo "Setting up the Git "
      local name=${git_user:-spinnaker}
      local email=${git_user_email:-phani@opsmx.io}
      git config --global user.email "$email"
      git config --global user.name "$name"
    }
    validate_clone() {
      if [ $? == 0 ]
      then
        echo "Cloning done ${git_repo}"
      else
        echo "Cloning failed with repo ${git_repo}, Please check credentials and repo access...."
        exit 5
      fi
      branch_check
    }
    git_clone_http() {
      echo "cloning $git_project/$git_repo over https"
      if [[ $repo_type == "git" || $repo_type == "bitbucket" ]]; then
        clone_result=$(git clone https://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git $tempdir/$git_repo 2> /dev/null)
        validate_clone
      elif [[ $repo_type == "gitea" ]]; then
        clone_result=$(git clone http://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git $tempdir/$git_repo 2> /dev/null)
        validate_clone
      elif [[ $repo_type == "stash" ]]; then
        #statements
        if [[ $git_url_port != "" ]]; then
          clone_result=$(git  clone https://$git_user:${git_secret_token}@${git_url}:$git_url_port/scm/${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
          validate_clone
        else
          clone_result=$(git  clone https://$git_user:${git_secret_token}@${git_url}/scm/${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
          validate_clone
        fi
      fi
      #echo $clone_result
    }
    load_ssh(){
      mkdir /home/opsmx/.ssh
      cp /etc/git-secret/git_secret_sshkey ~/.ssh/id_rsa
      chmod 400 ~/.ssh/id_rsa
      ssh-keyscan github.com >> ~/.ssh/known_hosts
    }
    git_clone_ssh(){
      echo "cloning $git_project/$git_repo over ssh"
      if [[ $repo_type == "git" || $repo_type == "bitbucket" ]]
      then
        load_ssh
        clone_result=$(git clone git@${git_url}:${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
        validate_clone
      elif [[ $repo_type == "stash" && $git_url_port != "" ]]; then
        #statements
        clone_result=$(git clone ssh://git@${git_url}:$git_url_port/${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
      else
        clone_result=$(git clone ssh://git@${git_url}:${git_project}/$git_repo.git $tempdir/$git_repo $tempdir/$git_repo 2> /dev/null)
      fi
      #echo $clone_result
    }
    git_add_file() {
      local file=$1
      git add $file
    }
    git_add_all() {
      git add $1
    }
    git_tag_all() {
      git tag -a Backup-$TAGSTAMP -m "$msg"
      git push --tags
    }
    git_delete_file() {
      local file=$1
      git rm $file
    }
    git_checkout_branch(){
      all_branches=$(git branch -r| grep -w  origin/$git_branch)
      echo $all_lbranches
      if [[ $all_branches != "" ]]
      then
        branch_checkout_result=$(git checkout $git_branch)
        echo $branch_checkout_result
        pull_requred=true
      else
        git checkout -b $git_branch
      fi
    }
    git_add_all(){
      git add $1
    }
    git_commit_all() {
      local branch=$git_branch
      local msg="checking application and pipeline raw data"
      if [ "$pull_requred" = true ]; then
        git pull origin $branch --no-edit
        if [ "$?" != "0" ];then
         echo "[ERROR]: Failed to pull $branch upstream."
         exit 1
        fi
      fi
      opts=""
      if [ "$git_commit_sign" == "true" ]; then
        opts="-s"
      fi
      #git commit $opts -a -m $msg
      git commit -m "$msg"
      git push --set-upstream origin $branch
      if [ "$?" != "0" ];then
        echo "[ERROR]: Failed to push $branch upstream."
        exit 1
      fi
    }
    sync_spin_to_git() {
      echo "In upload function which copies spinnaker application and pipeline from spinnaker to repo"
      local user_root_folder=$root_folder
      if [ "$git_secret_sshkey" != "" ]; then
        git_clone_ssh
      elif [ "$git_secret_token" != "" ]; then
        git_clone_http
      else
        echo "git cloning requires either a git_aws_secret_key to be set or git_aws_secret_token"
       exit 5
      fi
      projectdir=$tempdir/$git_repo
      cd $projectdir
      #We are done, get update git
      git_checkout_branch
      if [ -z $spinnaker_applications ]
      then
        spin application list > app.json
        testappjson=$(cat app.json)
        if [ "$testappjson" == "null" ]; then
          echo "ERROR: spin application list , There are no applications"
          echo "Please check the spin-cli-config secret username and password is valid or not"
          exit 1
        else
          spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/","/,/g; s/^"\|"$//g')
          rm -rf app.json
          get_pipelines_data  $spinnaker_app
        fi
      else
        get_pipelines_data  $spinnaker_applications
      fi
      git_add_all $root_folder
      git_commit_all
      return 0
    }
    sync_git_to_spin(){
      setup_git
      if [ "$git_secret_sshkey" != "" ]; then
        git_clone_ssh
      elif [ "$git_secret_token" != "" ]; then
        git_clone_http
      else
        echo "git cloning requires either a git_aws_secret_key to be set or git_aws_secret_token"
       exit 5
      fi
      projectdir=$tempdir/$git_repo
      cd $projectdir
      git_checkout_branch
      syncup_spin
    }
  github.sh: |
    #!/bin/bash
    #this script funtions only work for github central repository
    #this script funtions only work for git repo
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #   git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #  repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol
    # note *** env variables are mandatory to work with the script

    source scripts/git.sh
    git_hub_api_url=$git_api_url
    approve_pr_github(){
      approve_req=$(curl -o -I -L -s -w "%{http_code}" -X POST -H "Accept: application/vnd.github.v3+json" -u $git_approve_user:$git_pr_token  $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/reviews \
      -d '{"body": "Spinnaker says LGTM","event": "APPROVE"}')
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request $"
        exit 1
      fi
    }
    merge_pr_github(){
      merge_req=$(curl -o -I -L -s -w "%{http_code}" -X PUT -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/merge)
      echo $merge_req
      if [[ $merge_req == "200" ]]; then
        echo "merged pr successfully"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }
    create_pr_github(){
      local output=$(curl  -X POST -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/${git_user}/${git_repo}/pulls \
      -d '{"title": "pull request to merge '$git_branch' to master","body": "pull request to merge latest pipleine jobs information to '$target_branch'", "head": "'${git_branch}'","base": "'$target_branch'"}')
      if [ "$?" != 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        echo $output
        echo $output > pr_response.json
        errors=$(cat  pr_response.json| jq '(.errors)' | sed 's/\"//g')
        if [[ $errors != null ]]; then
          echo "ERROR: failed to raise pull request $errors"
          exit 1
        fi
        pr_id=$(cat  pr_response.json| jq '(.number)' | sed 's/\"//g')
        if [[  $pr_id != ""  ]]; then
          echo "successfully created pull request "
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }
    sync_spin_to_github(){
      setup_git
      sync_spin_to_git
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_hub_api_url=$git_hub_api_url:$git_api_url_port
          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        else
          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        fi
      fi
    }
  s3.sh: |
    #!/bin/bash
    source scripts/spin.sh
    absolute_path="$(dirname $(readlink -f $0))"
    # s3_folder=folder/in/s3/bucket if not given script uploads to root folder or the s3 bucket
    # ***bucket_name=testenvpipelinebucket "bucktet name to upload pipeline configuration"
    # ***AWS_ACCESS_KEY_ID="SKJGIHOBGIHIHOOH" access key to access s3 bucket
    # ***AWS_SECRET_ACCESS_KEY="sdfjlasj2e334234sdljflsjflsd98y9sy/0UVv6eCg" secret to access s3 bucket
    # ***repo_type=s3 provide repo type as s3
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected

    # note *** env variables are mandatory to work with the script
    s3_folder=$root_folder
    tempdir="/tmp/"
    bucket_name=$repo_name
    create_bucket(){
      #to create a bucket in s3 bucket name needed
      aws s3 mb s3://$bucket_name
      if [ $? != 0 ]; then
        echo "[ERROR]: Failed to create s3 bucket  might be aleady existing"
      fi
    }

    list_bucket(){
      # to llst bucket objects
      aws s3 ls s3://$bucket_name/
      if [ $? != 0 ]; then
        echo "[ERROR]: Failed to list s3 bucket "
      fi
    }

    list_application_folder(){
      # to list an object folder
      aws ls s3://$bucket_name/${s_folder}/$1 | awk '{print $4}'
    }

    upload_spin_to_s3(){
      # get the pipeline data from spinnaker and store in root_folder
      echo APP $spinnaker_applications
      if [ -z $spinnaker_applications ]
      then
        spin application list > app.json
        testappjson=$(cat app.json)
        if [ "$testappjson" == "null" ]; then
          echo "ERROR: spin application list , There are no applications"
          echo "Please check the spin-cli-config secret username and password is valid or not"
          exit 1
        else
          spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/","/,/g; s/^"\|"$//g')
          rm -rf app.json
          get_pipelines_data  $spinnaker_app
        fi
      else
        get_pipelines_data $spinnaker_applications
      fi
      #  get_pipelines_data
      #upload spinnaker pipelines data and upload to s3 folder
      aws s3 cp $tempdir/$bucket_name/$s3_folder s3://$bucket_name/$s3_folder --recursive
      if [ "$?" != 0 ]; then
        echo "[ERROR]: Failed to upload to bucket" $bucket_name
      else
        echo "uploaded to bucket successfully"
      fi
    }
    sync_from_s3_spin(){
      echo "downloading  spinnaker application pipelines configuration"
      aws s3 sync  s3://$bucket_name/$s3_folder $tempdir$s3_folder
      #apply configuration in spinnaker
      syncup_spin
    }
    delete_s3_object(){
      #delete an object in bucket
      aws rm s3://$bucket_name/${s3_folder}/${application_name}/  --recursive
      if [ $? != 0 ]; then
        echo "[ERROR]: Failed to delete s3 application folder "
      else
        echo "created bucket successfully"
      fi
    }
  spin.sh: |
    #!/bin/bash
    #source $(dirname $0)/git.sh
    tempdir="/tmp/"
    #spinnaker_applications="sampleapp"
    get_app_pipelines(){
      spin pipeline list --application $1  > tmp.json
      testjson=$(cat tmp.json)
      if [ "$testjson" == "null" ]; then
        echo "ERROR: spin pipeline list --application $1, There is no pipeline json for the application $1"
        echo "Please check the spin-cli-config secret username and password is valid or not"
        exit 1
      fi
      cat tmp.json | jq '.[] | (.name)' | sed 's/\"//g' > pipelines_in_application.list
      cat tmp.json | jq '.[] | (.id)' | sed 's/\"//g' > pipelines_guid.list
      rm tmp.json
    }

    live_backup_spin() {
    #This function will backup existing spinnaker data and store it in local for further comparison
      if [[ $repo_type = "s3" ]]; then
        projectdir=$tempdir/$root_folder
      else
        projectdir=$tempdir/${git_repo}/$root_folder
      fi
      live_projectdir_workdir=$projectdir/live_backup
      if [ -d "$live_projectdir_workdir" ]
      then
        echo "given live_spinnaker_project_work_dir is present"
      else
        echo "given live_spinnaker_project_work_dir is not present therefore creating it"
        mkdir -p "$projectdir/live_backup"
      fi
      cd $live_projectdir_workdir
      spinnaker_app=$spinnaker_applications
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"

      spinnaker_pipe=$spinnaker_pipelines
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"

      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
         sourceApp=${spinnaker_app_array[$m]}
         echo -e "Processing application $sourceApp\n"
         mkdir -p $sourceApp ; cd $sourceApp
         # Get into the correct directory
         spin -k pipeline list --application $sourceApp  > tmp.json
         testjson=$(cat tmp.json)
         if [ "$testjson" == "null" ]; then
           echo "ERROR: spin pipeline list --application $sourceApp, There is no pipeline json for the application $sourceApp"
           echo "Please check the spin-cli-config secret username and password is valid or not"
           exit 1
         fi
         cat tmp.json | jq '.[] | (.name)' | sed 's/\"//g' > live_pipelines_in_application.list
         cat tmp.json | jq '.[] | (.id)' | sed 's/\"//g' > live_pipelines_guid.list
         rm tmp.json

         spin -k application get $sourceApp  > $sourceApp.json
         if [ "$?" != "0" ]; then
           echo "ERROR: spin application get $sourceApp"
           return 1
         fi

         if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
           for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
                pipeLine=${spinnaker_pipe_array[$p]}
                echo -e "    Processing pipeline $pipeLine\n"
                # Check if pipeline exists
                existingPipe=`grep \^${pipeLine}\$ live_pipelines_in_application.list`
                if [[ "$existingPipe" == "${pipeLine}" ]]; then
                   spin -k pipeline get --application $sourceApp  --name "$pipeLine" > "$pipeLine.json"
                   if [ "$?" != "0" ]; then
                       echo "ERROR: spin spin pipeline get --application $sourceApp  --name \"$pipeLine\""
                       return 1
                   fi
                else
                   echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
                fi
             done
         else # No pipelines defined, get all the pipelines
             while read -r line; do
                echo -e "    Processing pipeline $line\n"
                spin -k pipeline get --application $sourceApp --name "$line" > "$line.json"
                if [ "$?" != "0" ]; then
                  echo "ERROR: spin spin pipeline get --application $sourceApp  --name $line"
                  return 1
                fi
             done < live_pipelines_in_application.list
         fi
         cd ..
      done
      return 0
    }

    delete_odd_pipelines() {
      #Delete the additional pielines that are in spinnaker and not in git
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
        sourceApp=${spinnaker_app_array[$m]}
        if [ -f "$projectdir/live_backup/$sourceApp/odd_pipeline.txt" ]; then
          if [ ! -s "$projectdir/live_backup/$sourceApp/odd_pipeline.txt" ]; then
            echo "no new pipelines to delete"
          else
            echo "============ Delete pipeline in $sourceApp Application ============="
            while IFS= read -r pipelinename; do
              echo "Deleting the pipeline $pipelinename"
              spin -k pipeline delete --name $pipelinename --application $sourceApp
            done < $projectdir/live_backup/$sourceApp/odd_pipeline.txt
            rm -rf $projectdir/live_backup/$sourceApp/odd_pipeline.txt
          fi
        fi
      done
    }
    #Create default parameterconfig-files
    create_default_params() {
      targetDir=${1:-default-config}
      echo "Processing pipelines and creating output in $targetDir"
      mkdir -p $targetDir
      for json in *.json ; do
        [[ -f "$json" ]] || continue
          echo "processing $json"
          cat "$json" | jq '.parameterConfig | reduce .[] as $p  ({};.Parameters += {($p.name): $p.default})'  >  $targetDir/tmp-param.json 2>/dev/null
          cat "$json" | jq '.triggers[0] '  >  $targetDir/tmp-trig.json 2>/dev/null
          if [[ `cat $targetDir/tmp-trig.json | wc -c` -gt 5 ]]
          then
            cat $targetDir/tmp-param.json | jq '.triggerValues=$pp' --argfile pp $targetDir/tmp-trig.json > $targetDir/"$json" 2>/dev/null
          else
            cp  $targetDir/tmp-param.json $targetDir/"$json"
          fi
        done
        rm -f $targetDir/tmp-param.json
        rm -f $targetDir/tmp-trig.json
        #Remove all files with zero size
        echo "Removing files that do not have any parameters defined"
        find $targetDir -type f -size -4c -delete # No parameterConfig in the file
        #find $targetDir -type f -size -4c -print -delete # No parameterConfig in the file
    }

    equate_pipelines_in_app() {
     #This function will comapre the applications and pipelines in git and spinnaker and gives the additional pipelines data
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
         sourceApp=${spinnaker_app_array[$m]}
         touch $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt
         echo $projectdir
         echo $git_project_work_dir
         echo $sourceApp
         diff $projectdir/$git_project_work_dir/$sourceApp/pipelines_guid.list $projectdir/live_backup/$sourceApp/live_pipelines_guid.list | awk '{print $2}' | sed 1d > $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt
         #list all existing spinnaker pipelines with app as reference
         spin -k pipeline list --application $sourceApp > $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json
         touch $projectdir/live_backup/$sourceApp/odd_pipeline.txt
         while IFS= read -r id; do
         #Extract the pipeline names using guids as reference
         cat $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json | jq '.[] | select (.id=="'$id'") | .name' -r >> $projectdir/live_backup/$sourceApp/odd_pipeline.txt
         done < $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt
      done
    }

    syncup_spin() {
      echo "In Download function that updates the spinnaker instance with the contents in repo"
      #Backup of existing spinnaker pipelines with guids
      live_backup_spin
      #Compare guids of existing pipelines and pipelines in git and provide names of additional pipelines
      equate_pipelines_in_app
      #Delete the extra pipelines(pipelines in spinnaker and not in git)
      if [[ $delete_on_sync_spin == "true" ]]; then
        delete_odd_pipelines
      fi
      if [[ $repo_type = "s3" ]]; then
        projectdir=$tempdir/$root_folder
        echo "project dir at synup spin $projectdir"
      else
        projectdir=$tempdir/${git_repo}/$root_folder
      fi
      if [ -d "$projectdir" ]
      then
        echo "given git_project_work_dir is present"
      else
        echo "given git_project_work_dir is not present therefore creating it"
        mkdir -p "$projectdir/$git_project_work_dir"
      fi

      cd $projectdir
      spinnaker_app=$spinnaker_applications
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"

      spinnaker_pipe=$spinnaker_pipelines
      #IFS=',' read -r -a spinnaker_pipe_array <<< "k8s-deploy"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"

      echo $projectdir
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
         sourceApp=${spinnaker_app_array[$m]}
         echo -e "Processing application $sourceApp\n"
         cd $sourceApp              # Get into the correct directory
         if [ "$?" != "0" ]; then
           echo "ERROR: Unable to change to application directory: $sourceApp"
           return 1
         fi
         #Create the application by default, we can have flag to for this later
         spin -k application save -f $sourceApp.json
         retVal=$?
         if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
           echo "ERROR: spin application save $sourceApp"
           return 1
         elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
           echo "ERROR: spin application save $sourceApp, continuing"
           cd ..
           continue
         fi
         #sleep 30 # Give a few seconds after application creation
         if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
             for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
                pipeLine=${spinnaker_pipe_array[$p]}
                echo -e "    Processing pipeline $pipeLine\n"
                # Check if pipeline file  exists
                if [ -f "$pipeLine.json" ]; then
                  #Update parameterConfig
                  if [[ "$pipelineconfig" == "true" ]]; then
                    mkdir -p temp
                    update_params "$pipeLine.json"
                    rm -rf temp
                  fi
                  spin -k pipeline save --file "$pipeLine.json"
                  retVal=$?
                  if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
                    echo "ERROR: spin pipeline save --file $pipeLine.json"
                    return 1
                  elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
                    echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
                    continue
                  fi
                else
                   echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
                fi
             done
         else # No pipelines defined, get all the pipelines
           while read -r line; do
             [[ -f "$line.json" ]] || continue
             pipeLine=$line
             echo -e "    Processing pipeline $pipeLine\n"
             #Update parameterConfig
             if [[ "$pipelineconfig" == "true" ]]; then
               echo "in pipelineconfig else"
               mkdir -p temp
               update_params "$pipeLine.json"
               #rm -rf temp
             fi
             echo `realpath $pipeLine.json`
             if test -f "$pipeLine.json"; then
               spin -k pipeline save --file "$pipeLine.json"
             fi
             retVal=$?
             if [[ "$retVal" != "0" && "$ignore_errors" == "false"  ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json"
               return 1
             elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
               continue
             fi
             sleep 10 # Slow it down
           done < pipelines_in_application.list
         fi
         cd ..
      done
    }
    get_pipelines_data(){
      echo $1
      local  spinnaker_app=$1
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"
      spinnaker_pipe=$spinnaker_pipelines
      #IFS=',' read -r -a spinnaker_pipe_array <<< "k8s-deploy"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"
      if [[ $root_folder == "" ]]; then
        root_folder="."
      fi
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
        sourceApp=${spinnaker_app_array[$m]}
        echo -e "Processing application $sourceApp\n"
        echo "get pipelines data $root_folder"
        mkdir -p $tempdir/$git_repo/${root_folder}/$sourceApp ; cd $tempdir/$git_repo/${root_folder}/$sourceApp              # Get into the correct directory
        get_app_pipelines $sourceApp
        spin application get $sourceApp  > $sourceApp.json
        if [ "$?" != "0" ]; then
          echo "ERROR: spin application get $sourceApp"
          return 1
        fi
        if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
          for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
            pipeLine=${spinnaker_pipe_array[$p]}
            echo -e "    Processing pipeline $pipeLine\n"
            # Check if pipeline exists
            existingPipe=`grep \^${pipeLine}\$ pipelines_in_application.list`
            if [[ "$existingPipe" == "${pipeLine}" ]]; then
              spin pipeline get --application $sourceApp  --name "$pipeLine" > "$pipeLine.json"
              if [ "$?" != "0" ]; then
                 echo "ERROR: spin spin pipeline get --application $sourceApp  --name \"$pipeLine\""
                 return 1
              fi
            else
              echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
            fi
          done
        else # No pipelines defined, get all the pipelines
          while read -r line; do
            echo -e "    Processing pipeline $line\n"
            spin pipeline get --application $sourceApp --name "$line" > "$line.json"
            if [ "$?" != "0" ]; then
               echo "ERROR: spin spin pipeline get --application $sourceApp  --name $line"
               return 1
            fi
          done < pipelines_in_application.list
        fi
        if [[ "$pipelinecreateconf" == "true" ]]; then
          create_default_params
        fi
        cd -
      done
    }

    download_spin() {
      echo "In Download function that updates the spinnaker instance with the contents in git"
      local user_root_folder=$root_folder
      if [ "$git_secret_sshkey" != "" ]; then
        git_clone_ssh_change $user_root_folder $git_repo $git_project
      elif [ "$git_secret_token" != "" ]; then
        git_clone_http $user_root_folder $git_repo $git_project
      else
        echo "git cloning requires either a git_secret_sshkey to be set or git_secret_token"
       exit 5
      fi
      projectdir=$HOME/$git_project
      cd $projectdir
      spinnaker_app=$spinnaker_applications
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"

      spinnaker_pipe=$spinnaker_pipelines
      #IFS=',' read -r -a spinnaker_pipe_array <<< "k8s-deploy"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"

      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
        sourceApp=${spinnaker_app_array[$m]}
        echo -e "Processing application $sourceApp\n"
        cd $sourceApp              # Get into the correct directory
        if [ "$?" != "0" ]; then
          echo "ERROR: Unable to change to application directory: $sourceApp"
          return 1
        fi
        #Create the application by default, we can have flag to for this later
        spin application save -f $sourceApp.json
        retVal=$?
        if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
          echo "ERROR: spin application save $sourceApp"
          return 1
        elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
          echo "ERROR: spin application save $sourceApp, continuing"
          cd ..
          continue
        fi
        sleep 30 # Give a few seconds after application creation
        if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
          for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
            pipeLine=${spinnaker_pipe_array[$p]}
            echo -e "    Processing pipeline $pipeLine\n"
            # Check if pipeline file  exists
            if [ -f "$pipeLine.json" ]; then
              #Update parameterConfig
              if [[ "$pipelineconfig" == "true" ]]; then
                 mkdir -p temp
                 update_params "$pipeLine.json"
                 rm -rf temp
              fi
              spin pipeline save --file "$pipeLine.json"
              retVal=$?
              if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
                 echo "ERROR: spin pipeline save --file $pipeLine.json"
                 return 1
              elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
                 echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
                 continue
              fi
            else
              echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
            fi
          done
         else # No pipelines defined, get all the pipelines
           while read -r line; do
             [[ -f "$line.json" ]] || continue
             pipeLine=$line
             echo -e "    Processing pipeline $pipeLine\n"
             #Update parameterConfig
             if [[ "$pipelineconfig" == "true" ]]; then
                mkdir -p temp
                update_params "$pipeLine.json"
                #rm -rf temp
             fi
             spin pipeline save --file "$pipeLine.json"
             retVal=$?
             if [[ "$retVal" != "0" && "$ignore_errors" == "false"  ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json"
               return 1
             elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
               continue
             fi
             sleep 10 # Slow it down
           done < pipelines_in_application.list
         fi
         cd ..
      done
    }

    update_params() {
      confDir=${pipelineconfigdir}
      if [ ! -d "$confDir" ] ; then
        echo "Directory specified for configuratio ($confDir) not found in application directory"
        return
      fi
      if [ ! -f "$confDir/$json" ] ; then
        echo "INFO: No configuration found for $json in $confDir"
        return
      fi
      json="$1"
      echo "Processing pipeline ($json) and updating pipelines as per configuration in $confDir"
      #Extract .parameterConfig
      cat "$json" | jq '.parameterConfig' > temp/"config-$json"
      #Replace parameters
      cat temp/"config-$json" | jq -f /home/opsmx/scripts/replace-params.jq --argfile pp $confDir/"$json" > temp/"updated-config-$json"
      #Replace .parameterConfig
      cat "$json" | jq  '.parameterConfig=$uc' --argfile uc temp/"updated-config-$json" > temp/"$json"
      ########################################################################
      #Extract 1st trigger
      cat  temp/"$json"| jq '.triggers[0]' > temp/tmp-trig.json
      #Update first trigger
      cat temp/tmp-trig.json | jq 'if $pp.triggerValues != null then . * $pp.triggerValues else . end'  --argfile pp $confDir/"$json"  > temp/updated-tmp-trig.json
      #Update pipeline-json with updated trigger
      if [[ `cat temp/updated-tmp-trig.json | wc -c` -gt 5 ]]
      then
        cat temp/"$json" | jq '.triggers[0]=$pp' --argfile pp temp/updated-tmp-trig.json > temp/final-replaced.json
        cp temp/final-replaced.json "$json"
      else
        cp  temp/"$json" "$json"
      fi
      ########################################################################
    }
  stash.sh: |
    #!/bin/bash
    #this script funtions only work for self hosted bitbucketserver/stash central repository
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #
    # repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol

    # note *** env variables are mandatory to work with the script
    source scripts/git.sh
    git_repo=$repo_name
    pr_id=0
    pr_version=0
    approve_pr_stash(){
      approve_req=$(curl -k -o -I -L -s -w "%{http_code}"  -X POST -H "Content-Type: application/json" -u $git_approve_user:$git_pr_token \
      https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/approve)
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request "
        exit 1
      fi
    }

    merge_pr_stash(){
      merge_req=$(curl -k -o -I -L -s -w "%{http_code}"  -X POST -H "Content-Type: application/json" -u $git_user:$git_secret_token   \
      https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/merge?version=$pr_version)
      echo $merge_req
      if [ $merge_req == "200" ]; then
        echo "merged pr successfully"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }
    create_pr_stash(){
        local output=$(curl -k -X POST -H "Content-Type: application/json" -u $git_user:$git_secret_token   https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests -d '{
        "title": "merging '"$git_branch"' to '"$target_branch"'",
        "description": "changes from spinnaker pipeline jobs are to be merged to master",
        "state": "OPEN",
        "open": true,
        "closed": false,
        "fromRef": {
            "id": "refs/heads/'"${git_branch}"'",
            "repository": {
                "slug": "'"${git_repo}"'",
                "name": null,
                "project": {
                    "key": "'"${git_project}"'"
                }
            }
        },
        "toRef": {
            "id": "refs/heads/'"$target_branch"'",
            "repository": {
                "slug": "'"${git_repo}"'",
                "name": null,
                "project": {
                    "key": "'"${git_project}"'"
                }
            }
        },
        "locked": false
    }')
      echo $output
      echo $output > pr_response.json
      grep  "is already up-to-date with branch" pr_response.json
      if [ "$?" = 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        pr_id=$(cat  pr_response.json| jq '(.id)' | sed 's/\"//g')
        pr_version=$(cat pr_response.json | jq '(.version)' | sed 's/\"//g')
        if [ $? = 0 ]; then
          echo "successfully created pull request "
          #rm -f pr_response.json
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }

    sync_spin_to_stash(){
      #setup git configuration using email and username
      setup_git
      #upload spinnaker configuration to git
      sync_spin_to_git
      #check if custom port is being used for repo
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_api_url=$git_api_url:$git_api_url_port
          create_pr_stash
          if [[ $auto_merge == "true" ]]; then
            approve_pr_stash
            merge_pr_stash
          fi
        else
          create_pr_stash
          if [[ $auto_merge == "true" ]]; then
            approve_pr_stash
            merge_pr_stash
          fi
        fi
      fi
    }
kind: ConfigMap
metadata:
  name: pipe-promot-scripts
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spinnaker-role
rules:
  - apiGroups: ['']
    resources:
      [
        'namespaces',
        'events',
        'replicationcontrollers',
        'serviceaccounts',
        'pods/log',
      ]
    verbs: ['get', 'list']
  - apiGroups: ['']
    resources: ['pods', 'services', 'secrets', 'configmaps']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  - apiGroups: ['autoscaling']
    resources: ['horizontalpodautoscalers']
    verbs: ['list', 'get']
  - apiGroups: ['apps']
    resources: ['controllerrevisions', 'statefulsets']
    verbs: ['list']
  - apiGroups: ['extensions', 'apps']
    resources: ['deployments', 'replicasets', 'ingresses']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['']
    resources: ['services/proxy', 'pods/portforward']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['batch']
    resources: ['jobs']
    verbs:
      [
        'create',
        'delete',
        'get',
        'list',
        'update',
        'watch',
      ]
---
# Source: oes/charts/spinnaker/templates/rbac/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-spinnaker-halyard
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role                 # ClusterRole, if we have access to cluster resources
  name: spinnaker-role       # edit, if we have the access
subjects:
- namespace: default
  kind: ServiceAccount
  name: release-name-spinnaker-halyard
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-sa.yaml
# In the case of a local cluster Spinnaker needs
# to be able to deploy to all namespaces in the cluster.
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding  # ClusterRoleBinding, if we have access accross the cluster
metadata:
  name: release-name-spinnaker-spinnaker
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role             # ClusteRoleBinding if we have access accross the cluster
  name: spinnaker-role   # cluster-admin if we have the access
subjects:
- namespace: default
  kind: ServiceAccount
  # Clouddriver does not currently allow config of its
  # service account.
  name: default
---
# Source: oes/templates/rbac/oes-init-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding # ClusterRole if you have cluster access
metadata:
  name: default-oes-access
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- namespace: default
  kind: ServiceAccount
  name: default
---
# Source: oes/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-headless
  labels:
    app: redis
    chart: redis-10.5.3
    release: release-name
    heritage: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: release-name
---
# Source: oes/charts/redis/templates/redis-master-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: release-name
    heritage: Helm
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: release-name
    role: master
---
# Source: oes/charts/spinnaker/templates/services/halyard.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-spinnaker-halyard
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
    component: halyard
spec:
  ports:
  - port: 8064
    name: daemon
  clusterIP: None
  selector:
    app: release-name-spinnaker
    component: halyard
---
# Source: oes/charts/spinnaker/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: deck
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
  name: spin-deck-lb
spec:
  type: 
  ports:
   - name: "https"
     port: 443
     targetPort: 9000
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 9000
  selector:
    cluster: spin-deck
---
# Source: oes/charts/spinnaker/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: gate
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
  name: spin-gate-lb
spec:
  type: 
  ports:
   - name: https
     port: 443
     targetPort: 8084
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 8084
  selector:
    cluster: spin-gate
---
# Source: oes/templates/sapor-gate/sapor-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    component: sapor-gate
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: sapor-gate
spec:
  type: ClusterIP
  ports:
  - name: "sapor-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  selector:
    app: oes
    component: sapor-gate
---
# Source: oes/templates/services/oes-auditclient-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-audit-client
spec:
  ports:
  - name: auditclient
    port: 8098
    protocol: TCP
    targetPort: 8098
  selector:
    app: oes
    component: auditclient
  type: ClusterIP
---
# Source: oes/templates/services/oes-auditservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-audit-service
spec:
  ports:
  - name: auditservice
    port: 8097
    protocol: TCP
    targetPort: 8097
  - name: opentelemetry
    protocol: TCP
    port: 19090
    targetPort: 19090
  selector:
    app: oes
    component: auditservice
  type: ClusterIP
---
# Source: oes/templates/services/oes-autopilot-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-autopilot
spec:
  type: ClusterIP
  ports:
  - name: "cas-service"
    port: 8090
    targetPort: 8090
  - name: "monitoring-service"
    port: 9090
    targetPort: 9090
  selector:
    app: oes
    component: autopilot
---
# Source: oes/templates/services/oes-dashboard-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-dashboard
spec:
  type: ClusterIP
  ports:
  - name: dashboard
    protocol: TCP
    port: 8094
    targetPort: 8094
  selector:
    app: oes
    component: dashboard
---
# Source: oes/templates/services/oes-datascience-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-datascience
spec:
  ports:
  - name: datascience
    port: 5005
    protocol: TCP
    targetPort: 5005
  selector:
    app: oes
    component: datascience
  type: ClusterIP
---
# Source: oes/templates/services/oes-db-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-db
spec:
  type: ClusterIP
  ports:
  - name: db
    protocol: TCP
    port: 5432
    targetPort: 5432
  selector:
    app: oes
    component: db
---
# Source: oes/templates/services/oes-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-gate
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8084
  - name: "oes-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  - name: "http"
    port: 80
    targetPort: 8084
  selector:
    app: oes
    component: gate
---
# Source: oes/templates/services/oes-platform-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-platform
spec:
  type: ClusterIP
  ports:
  - name: oes-platform
    protocol: TCP
    port: 8095
    targetPort: 8095
  selector:
    app: oes
    component: platform
---
# Source: oes/templates/services/oes-rabbitmq-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: rabbitmq-service
spec:
  ports:
  - name: rabbitmq
    port: 5672
    protocol: TCP
    targetPort: 5672
  - name: rabbitmq-mgmt
    port: 15672
    protocol: TCP
    targetPort: 15672
  selector:
    app: oes
    component: rabbitmq
  type: ClusterIP
---
# Source: oes/templates/services/oes-sapor-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-sapor
spec:
  type: ClusterIP
  ports:
  - name: "sapor"
    port: 8085
    targetPort: 8085
  selector:
    app: oes
    component: sapor
---
# Source: oes/templates/services/oes-ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-ui
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8080
  - name: "http"
    port: 8080
    targetPort: 8080
  selector:
    app: oes
    component: ui
---
# Source: oes/templates/services/oes-visibility-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-visibility
spec:
  type: ClusterIP
  ports:
  - name: visibility
    protocol: TCP
    port: 8096
    targetPort: 8096
  selector:
    app: oes
    component: visibility
---
# Source: oes/templates/services/opa-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: opa
  labels:
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
spec:
  selector:
    app: opa
  ports:
  - protocol: TCP
    port: 8181
    targetPort: 8181
  type: ClusterIP
---
# Source: oes/templates/deployments/oes-audit-client.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-audit-client
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditclient
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8098"
      labels:
        app: oes
        component: auditclient
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-audit-client:v4.0.4.2
        imagePullPolicy: IfNotPresent
        name: oes-audit-client
        env:
        resources:
          limits:
            cpu: 2
            memory: 8Gi
          requests:
            cpu: 1
            memory: 2Gi
        ports:
        - containerPort: 8098
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8098
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8098
        volumeMounts:
        - mountPath: /opsmx/conf/audit-client-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-client-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-audit-service.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-audit-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditservice
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8097"
      labels:
        app: oes
        component: auditservice
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-audit-service:v4.0.4.2
        imagePullPolicy: IfNotPresent
        name: oes-audit
        env:
        resources:
          limits:
            cpu: 2
            memory: 8Gi
          requests:
            cpu: 1
            memory: 2Gi
        ports:
        - containerPort: 8097
          name: backend
          protocol: TCP
        - containerPort: 19090
          name: opentelemetry
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8097
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8097
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /opsmx/conf/audit-service-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-service-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-autopilot-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: oes-autopilot
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: autopilot
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8090"
      labels:
        app: oes
        component: autopilot
    spec:
      volumes:
        - name: autopilot-config-volume
          secret:
            secretName: oes-autopilot-config
        - secret:
            items:
            - key: bootstrap.yml
              path: bootstrap.yml
            secretName: bootstrap
          name: bootstrap-config-volume
        - configMap:
            defaultMode: 420
            items:
            - key: standard-error-codes.csv
              path: standard-error-codes.csv
            name: standard-error-codes-config
          name: standard-error-conf
      containers:
        - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-autopilot:v4.0.4.2
          imagePullPolicy: IfNotPresent
          name: oes-autopilot
          env:
          resources:
            limits:
              cpu: 2
              memory: 8Gi
            requests:
              cpu: 1
              memory: 2Gi
          ports:
            - containerPort: 8090
              name: backend
              protocol: TCP
            - containerPort: 9090
              name: metricfetcher
              protocol: TCP
          volumeMounts:
          - name: autopilot-config-volume
            mountPath: /opsmx/conf/autopilot.properties
            subPath: autopilot.properties
          - mountPath: /opsmx/conf/bootstrap.yml
            name: bootstrap-config-volume
            subPath: bootstrap.yml
          - mountPath: /opsmx/conf/standard-error-code.csv
            name: standard-error-conf
            subPath: standard-error-codes.csv
          readinessProbe:
            tcpSocket:
              port: 8090
            initialDelaySeconds: 60
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /mgmt/health
              port: 8090
            initialDelaySeconds: 120
            periodSeconds: 60
---
# Source: oes/templates/deployments/oes-dashboard-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-dashboard
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: dashboard
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: bfdbbd95b11053a548502713f0ae6f99111cd8f853d814981ca6ecf1c31231be
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8094"
      labels:
        app: oes
        component: dashboard
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-dashboard:v4.0.4.2
        name: oes-dashboard
        env:
        resources:
          limits:
            cpu: 1500m
            memory: 1000Mi
          requests:
            cpu: 500m
            memory: 500Mi
        ports:
        - containerPort: 8094
          protocol: TCP
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/dashboard-local.yml
          name: dashboard-config
          subPath: dashboard-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        readinessProbe:
          tcpSocket:
            port: 8094
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8094
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: dashboard-config
        configMap:
          name: oes-dashboard-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-datascience-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-datascience
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: datascience
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "5005"
      labels:
        app: oes
        component: datascience
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-datascience:v4.0.4.2
        imagePullPolicy: IfNotPresent
        name: oes-datascience
        env:
        resources:
          limits:
            cpu: 2
            memory: 8Gi
          requests:
            cpu: 1
            memory: 2Gi
        ports:
        - containerPort: 5005
          name: backend
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 5005
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /home/ubuntu/.aws/credentials
          name: datascience-config-volume
          subPath: minio-credentials
        - mountPath: /home/ubuntu/datascience/app_config.yaml
          name: datascience-config-volume
          subPath: app-config.yml
      volumes:
      - secret:
          secretName: oes-datascience-config
        name: datascience-config-volume
---
# Source: oes/templates/deployments/oes-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: gate
    workload-rebalancing.compute.zende.sk/enabled: "false"
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-gate
spec:
  replicas: 2
  selector:
    matchLabels:
      app: oes
      component: gate
      workload-rebalancing.compute.zende.sk/enabled: "false"
  template:
    metadata:
      annotations:
        checksum/secret: d48ffdc8edb55346a0640b28181ee686485f42794ba513b57f4d0c54fb422a90
        moniker.spinnaker.io/application: spin
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8084"
      labels:
        app: oes
        component: gate
        workload-rebalancing.compute.zende.sk/enabled: "false"
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-gate:v4.0.4.2
        name: oes-gate
        env:
        - name: spring_profiles_active
          value: vault,local
        resources:
          limits:
            cpu: 2
            memory: 8Gi
          requests:
            cpu: 2
            memory: 8Gi
        ports:
        - containerPort: 8084
          protocol: TCP
        volumeMounts:
        - name: gate-volume
          mountPath: /opt/spinnaker/config/gate.yml
          subPath: gate.yml
        - mountPath: /opt/spinnaker/config/bootstrap.yml
          name: bootstrap-volume
          subPath: bootstrap.yml
        - mountPath: encryptedFile:oessamljks:oessaml.jks
          name: saml-jks
          subPath: oessaml.jks
        - mountPath: encryptedFile:oesmetadataxml:oesmetadata.xml
          name: metadata-xml
          subPath: oesmetadata.xml
        readinessProbe:
          tcpSocket:
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 30
        livenessProbe:
          httpGet:
            path: /health
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 60
      volumes:
      - secret:
          secretName: oessamljks
        name: saml-jks
      - secret:
          secretName: oesmetadataxml
        name: metadata-xml
      - name: gate-volume
        secret:
          secretName: oes-gate-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-volume
---
# Source: oes/templates/deployments/oes-platform-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: platform
  strategy: {}
  template:
    metadata:
      annotations:
        checksum/secret: 7c026ebafafc42f344541d738880971fb14d81a32beb9ad692c174cdec41c42c
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8095"
      labels:
        app: oes
        component: platform
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-platform:v4.0.4.2
        name: oes-platform
        resources:
          limits:
            cpu: 1500m
            memory: 1500Mi
          requests:
            cpu: 500m
            memory: 500Mi
        ports:
        - containerPort: 8095
          protocol: TCP
        env:
        readinessProbe:
          tcpSocket:
            port: 8095
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8095
          initialDelaySeconds: 60
          periodSeconds: 60
        volumeMounts:
        - mountPath: /opsmx/conf/platform-local.yml
          name: platform-config-volume
          subPath: platform-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        - mountPath: /opsmx/conf/feature.yml
          name: isd-feature-flag-conf
          subPath: feature.yml
      volumes:
      - name: platform-config-volume
        secret:
          secretName: oes-platform-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
      - configMap:
          defaultMode: 420
          items:
          - key: feature.yml
            path: feature.yml
          name: isd-feature-flag-config
        name: isd-feature-flag-conf
---
# Source: oes/templates/deployments/oes-rabbitmq-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: rabbitmq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: rabbitmq
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: rabbitmq
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: quay.io/opsmxpublic/rabbitmq:3-management
        imagePullPolicy: IfNotPresent
        name: rabbitmq
        env:
        ports:
        - containerPort: 5672
          protocol: TCP
        resources: {}
      restartPolicy: Always
      securityContext:
        fsGroup: 1000
---
# Source: oes/templates/deployments/oes-sapor-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-sapor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor
  template:
    metadata:
      annotations:
        checksum/configmap: 820333eb52c694c9d4071b21e6b8d85808d604a9e237106a75c298f2a97dd827
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8085"
      labels:
        app: oes
        component: sapor
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-sapor:v4.0.4.2
        name: oes-sapor
        env:
        resources:
          limits:
            cpu: 1500m
            memory: 2000Mi
          requests:
            cpu: 500m
            memory: 100Mi
        ports:
        - containerPort: 8085
          protocol: TCP
        volumeMounts:
        - name: sapor-config-volume
          mountPath: /opt/opsmx/application.yml
          subPath: application.yml
        - mountPath: /opt/opsmx/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        readinessProbe:
          tcpSocket:
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
      volumes:
      - secret:
          secretName: oes-sapor-config
        name: sapor-config-volume
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: sapor-bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-ui-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: ui
    workload-rebalancing.compute.zende.sk/enabled: "false"
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-ui
spec:
  replicas: 2
  selector:
    matchLabels:
      app: oes
      component: ui
      workload-rebalancing.compute.zende.sk/enabled: "false"
  template:
    metadata:
      annotations:
        checksum/configmap: f3ea46792fd5c07ca2e164d7efa3aca1ef1b960507bead42b95af3eab280f01e
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: ui
        workload-rebalancing.compute.zende.sk/enabled: "false"
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-ui:v4.0.4.2
        name: oes-ui
        env:
        resources:
          limits:
            cpu: 2
            memory: 8Gi
          requests:
            cpu: 1
            memory: 2Gi
        ports:
        - containerPort: 8080
          protocol: TCP
        volumeMounts:
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/app-config.json
          subPath: app-config.json
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/help-text.json
          subPath: help-text.json
        - mountPath: /etc/nginx/nginx.conf
          name: nginx-config
          subPath: nginx.conf
        readinessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /ui/indexl.html
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
      volumes:
      - configMap:
          defaultMode: 420
          name: oes-ui-config
        name: config-dir
      - configMap:
          defaultMode: 420
          name: oes-ui-nginxconf
        name: nginx-config
---
# Source: oes/templates/deployments/oes-visibility-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-visibility
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: visibility
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: f738c309ccd896657cb84a67a4b202542f2c6279340e0a9612de14c61e0297e2
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8096"
      labels:
        app: oes
        component: visibility
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-visibility:v4.0.4.2
        name: oes-visibility
        resources:
          limits:
            cpu: 1500m
            memory: 1000Mi
          requests:
            cpu: 500m
            memory: 500Mi
        ports:
        - containerPort: 8096
          protocol: TCP
        env:
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/visibility-local.yml
          name: visibility-config
          subPath: visibility-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        readinessProbe:
          tcpSocket:
            port: 8096
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8096
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: visibility-config
        secret:
          secretName: oes-visibility-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/opa-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: opa
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: opa
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opa
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: opa
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
      name: opa
    spec:
      containers:
        - name: opa
          image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/opa:v0.47.0
          args:
            - "run"
            - "--server"
        - name: opa-persist
          command:
          - /bin/bash
          - /tmp/config/opa-persist.sh
          envFrom:
          - secretRef:
              name: oes-gate-secret
          image: quay.io/opsmxpublic/customterraformstage:v1
          imagePullPolicy: IfNotPresent
          volumeMounts:
          - mountPath: /tmp/config
            name: opa-persist
      restartPolicy: Always
      volumes:
        - configMap:
            defaultMode: 420
            name: opa-persist
          name: opa-persist
---
# Source: oes/templates/sapor-gate/sapor-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor-gate
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: sapor-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor-gate
  template:
    metadata:
      annotations:
        checksum/secret: 68f74bcf539b143147ec93182922a9856aa8eeeaa1a0bf334cdb6b52608f954b
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: sapor-gate
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - image: 713408432298.dkr.ecr.us-west-2.amazonaws.com/dev/zendesk/dockerhub-images/quay.io/opsmxpublic/ubi8-oes-spin-gate:v3.12.0-saporgate
        name: sapor-gate
        env:
        - name: JAVA_OPTS
          value: -XX:MaxRAMPercentage=100.0
        - name: SPRING_PROFILES_ACTIVE
          value: overrides,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
          limits:
            cpu: 1500m
            memory: 1500Mi
          requests:
            cpu: 500m
            memory: 500Mi
        volumeMounts:
        - mountPath: /opt/spinnaker/config
          name: sapor-gate-files
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8084
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
      volumes:
      - name: sapor-gate-files
        secret:
          secretName: sapor-gate-files
---
# Source: oes/charts/redis/templates/redis-master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: release-name-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: redis
      release: release-name
      role: master
  serviceName: release-name-redis-headless
  template:
    metadata:
      labels:
        app: redis
        chart: redis-10.5.3
        release: release-name
        role: master
      annotations:
        checksum/health: 436d806171441d73cdaa6455e362825ff4a9475e0ba000636e0d178fc37c3632
        checksum/configmap: e2e51906d2fcbd95c0f365759696f182ebc3e151e07f6f2e95bdc5cd68047032
        checksum/secret: 00aefbb39d5ca4c927c97171b50e7eb80ac9c5b2658018e68c2d0654b518df12
        moniker.spinnaker.io/application: spin
    spec:      
      securityContext:
        fsGroup: 1001
      serviceAccountName: "default"
      containers:
      - name: release-name-redis
        image: "quay.io/opsmxpublic/bitnami-redis:5.0.7-debian-10-r0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1001
        command:
        - /bin/bash
        - -c
        - |
          if [[ -n $REDIS_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_PASSWORD_FILE}`
            export REDIS_PASSWORD=$password_aux
          fi
          if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
          fi
          if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
          fi
          ARGS=("--port" "${REDIS_PORT}")
          ARGS+=("--requirepass" "${REDIS_PASSWORD}")
          ARGS+=("--masterauth" "${REDIS_PASSWORD}")
          ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
          ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
          /run.sh ${ARGS[@]}
        env:
        - name: REDIS_REPLICATION_MODE
          value: master
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: release-name-redis
              key: redis-password
        - name: REDIS_PORT
          value: "6379"
        ports:
        - name: redis
          containerPort: 6379
        livenessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_liveness_local.sh 5
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_readiness_local.sh 5
        resources:
          limits:
            cpu: "4"
            memory: 6Gi
          requests:
            cpu: "4"
            memory: 6Gi
        volumeMounts:
        - name: health
          mountPath: /health
        - name: redis-data
          mountPath: /data
          subPath: 
        - name: config
          mountPath: /opt/bitnami/redis/mounted-etc
        - name: redis-tmp-conf
          mountPath: /opt/bitnami/redis/etc/
      volumes:
      - name: health
        configMap:
          name: release-name-redis-health
          defaultMode: 0755
      - name: config
        configMap:
          name: release-name-redis
      - name: "redis-data"
        emptyDir: {}
      - name: redis-tmp-conf
        emptyDir: {}
  updateStrategy:
    type: RollingUpdate
---
# Source: oes/charts/spinnaker/templates/statefulsets/halyard.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: spin
  name: release-name-spinnaker-halyard
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
spec:
  serviceName: release-name-spinnaker-halyard
  replicas: 1
  selector:
    matchLabels:
      app: "release-name-spinnaker"
      release: "release-name"
      component: halyard
  template:
    metadata:
      annotations:
        checksum/configmap: db20653fd7c501bfc148fd3273decfa26ea4cc64592df0d313c3599fd7bd5064
        moniker.spinnaker.io/application: spin
      labels:
        app: "release-name-spinnaker"
        heritage: "Helm"
        release: "release-name"
        chart: "spinnaker-2.2.3"
        component: halyard
    spec:
      serviceAccountName: release-name-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      initContainers:
      - name: "create-halyard-local"
        image: quay.io/opsmxpublic/awsgit:v3-js
        command:
        - sh
        - /tmp/initscript/init.sh
        env:
        - name: GIT_CLONE_PARAM
          valueFrom:
            secretKeyRef:
              name: opsmx-gitops-auth
              key: gitcloneparam
        - name: GIT_USER
          valueFrom:
            secretKeyRef:
              name: opsmx-gitops-auth
              key: gituser
        - name: GIT_TOKEN
          valueFrom:
            secretKeyRef:
              name: opsmx-gitops-auth
              key: gittoken
        - name: DYNAMIC_ACCOUNTS_REPO
          valueFrom:
            secretKeyRef:
              name: opsmx-gitops-auth
              key: dynamicaccountsgituri
        - name: SPINNAKER_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
      - name: "halyardconfig-update"
        command:
        - sh
        - /tmp/akv2k8s/run.sh
        image: quay.io/opsmxpublic/k8s-decoder:hal
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: secret-decoder
          mountPath: /tmp/akv2k8s
      - name: "halyard-overrideurl"
        command:
        - sh
        - /tmp/autoconfig/call_overrides.sh
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
        image: quay.io/opsmxpublic/bitnami-kubectl:1.18.5
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
        - mountPath: /tmp/autoconfig
          name: halyard-overrideurl
      volumes:
      - name: halyard-home
        emptyDir: {}
      - name: halyard-overrideurl
        configMap:
          name: release-name-spinnaker-halyard-overrideurl  
      - name: secret-decoder
        configMap:
          name: release-name-spinnaker-spin-secret-decoder
      - name: reg-secrets
        secret:
          secretName: release-name-spinnaker-registry
      - name: additional-profile-config-maps
        configMap:
          name: release-name-spinnaker-additional-profile-config-maps
      - name: halyard-config
        emptyDir: {}
      - name: service-settings
        configMap:
          name: release-name-spinnaker-service-settings
      - name: halyard-initscript
        configMap:
          name: release-name-spinnaker-halyard-init-script
      containers:
      - name: halyard
        image: quay.io/opsmxpublic/ubi8-halyard-cve:f9c4b85-1107
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "until curl http://localhost:8064/health; do sleep 10 ;done;hal deploy apply"]
        ports:
        - containerPort: 8064
          name: daemon
        volumeMounts:
        - name: halyard-home
          mountPath: /home/spinnaker
        - name: halyard-config
          mountPath: /opt/halyard/config
        - name: reg-secrets
          mountPath: /opt/registry/passwords
---
# Source: oes/charts/spinnaker/templates/job/create-sample-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-create-sample-app
spec:
  template:
    spec:
      serviceAccountName: release-name-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - secret:
          secretName: release-name-spinnaker-spin-config
        name: spin-config
      - configMap:
          defaultMode: 420
          name: release-name-spinnaker-spin-pipeline-import
        name: spin-pipeline-import
      - name: spin-pipeline-config
        emptyDir: {}
      containers:
      - command:  
        - bash
        - /tmp/config/spin-pipeline-import.sh
        name: sample-pipeline-install
        image: quay.io/opsmxpublic/spin-sample-pipeline:v1.0.1
        volumeMounts:         
        - name: spin-pipeline-config
          mountPath: /tmp/config/git
        - mountPath: /tmp/config
          name: spin-pipeline-import
        - mountPath: /tmp/config/spin
          name: spin-config
---
# Source: oes/templates/configmaps/github-creation.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "-10"
  name: release-name-oes-github-creation
  labels:
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
data:
  github-create.sh: |-
        #!/bin/sh

        #set -x

        gitusermailid=user@mail.com
        gitusername=zd-svc-spinnaker-staging
        gitpassword=encrypted:gittoken:gittoken
        org=zendesk
        repo_name=spin-staging


        git config --global user.email "$gitusermailid"
        git config --global user.name "$gitusername"
        object='{"name":"'"$repo_name"'","private":"true"}'
        curlResp=$(curl -s -X GET -H "Authorization: token $gitpassword" https://api.github.com/repos/$org/$repo_name)
        message=$(echo $curlResp | jq -r '.name')

        if [ "$repo_name" == "$message" ]
        then
                echo "REPO EXISTS"
                exit 0
        else
                object='{"name":"'"$repo_name"'","private":"true"}'
                if [ "$gitusername" == "$org" ]
                then
                     curl -H "Authorization: token $gitpassword" --data "$object" https://api.github.com/user/repos
                     git clone https://github.com/OpsMx/standard-gitops-repo.git -b v4.0.4.2
                     git clone https://$gitusername:$gitpassword@github.com/$gitusername/$repo_name.git
                else
                     curl -X POST -H "Accept: application/vnd.github.v3+json" -H "Authorization: token $gitpassword" https://api.github.com/orgs/$org/repos -d '{"name":"'$repo_name'"}'
                     git clone https://github.com/OpsMx/standard-gitops-repo.git -b v4.0.4.2
                     git clone https://$gitusername:$gitpassword@github.com/$org/$repo_name.git
                fi

                cp -pr standard-gitops-repo/* $repo_name/
                cd $repo_name/
                git checkout -b main
                git status
                git add .
                git commit -m "cloned standard-gitops-repo content"
                git push origin main
        fi
---
# Source: oes/charts/spinnaker/templates/hooks/cleanup.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "release-name-spinnaker-cleanup-using-hal"
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
    component: halyard
  annotations:
    "helm.sh/hook": "pre-delete"
    "helm.sh/hook-delete-policy": "before-hook-creation"
spec:
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: spin
      labels:
        app: "release-name-spinnaker"
        heritage: "Helm"
        release: "release-name"
        chart: "spinnaker-2.2.3"
        component: halyard
    spec:
      restartPolicy: OnFailure
      volumes:
      - name: halyard-config
        configMap:
          name: release-name-spinnaker-halyard-config
      containers:
      - name: halyard-install
        image: quay.io/opsmxpublic/ubi8-halyard-cve:f9c4b85-1107
        volumeMounts:
        - name: halyard-config
          mountPath: /opt/halyard/scripts
        command:
        - bash
        - -xe
        - "/opt/halyard/scripts/clean.sh"
---
# Source: oes/charts/spinnaker/templates/hooks/install-using-hal.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "release-name-install-using-hal"
  labels:
    app: "release-name-spinnaker"
    heritage: "Helm"
    release: "release-name"
    chart: "spinnaker-2.2.3"
  annotations:
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
spec:
  template:
    metadata:
      annotations:
        checksum/config: bb3d3b7716549bd4e36374fc2acc29fb7062ce4d4c12596fe6220ce3a3aa8389
        moniker.spinnaker.io/application: spin
      labels:
        app: "release-name-spinnaker"
        heritage: "Helm"
        release: "release-name"
        chart: "spinnaker-2.2.3"
    spec:
      serviceAccountName: release-name-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - name: halyard-config
        configMap:
          name: release-name-spinnaker-halyard-config
      containers:
      - name: halyard-install
        image: quay.io/opsmxpublic/ubi8-halyard-cve:f9c4b85-1107
        volumeMounts:
        - name: halyard-config
          mountPath: /opt/halyard/scripts
        command:
        - bash
        - -xe
        - "/opt/halyard/scripts/install.sh"
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
---
# Source: oes/templates/hooks/cleanup.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "oes-cleanup"
  labels:
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  annotations:
    "helm.sh/hook": "pre-delete"
    "helm.sh/hook-delete-policy": "before-hook-creation"
spec:
  template:
    metadata:
      labels:
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      restartPolicy: OnFailure
      containers:
      - name: oes-cleanup
        image: quay.io/opsmxpublic/ubi8-halyard-cve:f9c4b85-1107
        command: ["/bin/bash","-c"]
        args: ["kubectl delete ingress --ignore-not-found oes-gate-ingress oes-ui-ingress release-name-spinnaker-deck; kubectl delete secret --ignore-not-found ca-secret jwt-secret oes-cacerts oes-control-secret"]
---
# Source: oes/templates/hooks/github-create.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "1"
  labels:
    app: oes
    component: github-config
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: github-config
spec:
  backoffLimit: 1
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: github-config
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - command: ["sh", "/tmp/config/github-create.sh" ]
        name: github-creation-api
        image: quay.io/opsmxpublic/awsgit:v2-openssh
        volumeMounts:
        - mountPath: /tmp/config
          name: github-creation
      restartPolicy: Never
      volumes:
      - configMap:
          defaultMode: 420
          name: release-name-oes-github-creation
        name: github-creation
---
# Source: oes/templates/hooks/oes-config-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "5"
  labels:
    app: oes
    component: oes-config
    heritage: "Helm"
    release: "release-name"
    chart: "oes-4.0.18"
  name: oes-config
spec:
  template:
    metadata:
      annotations:
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: oes-config
        heritage: "Helm"
        release: "release-name"
        chart: "oes-4.0.18"
    spec:
      containers:
      - command: ["bash", "/tmp/config/datasource-api.sh" ]
        name: datasource-creation-api
        image: quay.io/opsmxpublic/oes-pre-configure:v2
        volumeMounts:
        - mountPath: /tmp/config
          name: datasource-creation
      restartPolicy: OnFailure
      volumes:
      - configMap:
          defaultMode: 420
          name: release-name-oes-datasource-creation
        name: datasource-creation
